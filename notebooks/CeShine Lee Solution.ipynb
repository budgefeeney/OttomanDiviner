{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This is a clone of the script at https://www.kaggle.com/ceshine/lgbm-starter which is intended to give an idea of how to structure the data for trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelude "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataSetPath = \"/home/bryanfeeney/Dropbox/OttomanDiviner/datasets/favorita/\"\n",
    "\n",
    "StoresPath   = DataSetPath + \"stores.csv.gz\"\n",
    "ItemsPath    = DataSetPath + \"items.csv.gz\"\n",
    "OilPricePath = DataSetPath + \"oil.csv.gz\"\n",
    "HolidaysPath = DataSetPath + \"holidays_events.csv.gz\"\n",
    "Transactions = DataSetPath + \"transactions.csv.gz\"\n",
    "TrainData    = DataSetPath + \"train.csv.gz\"\n",
    "TestData     = DataSetPath + \"test.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    TrainData, \n",
    "    usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909),  # 2016-01-01\n",
    "    compression='gzip'\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    TestData,\n",
    "    usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"],  # , date_parser=parser\n",
    "    compression='gzip'\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    ItemsPath,\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    StoresPath\n",
    ").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59038132, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370464, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4100, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only 2017\n",
    "\n",
    "This is a peculiar one, and it **games the benchmark** in a not great way. Essentially it uses the last 11 weeks of data before the prediction threshold to predict what's happening next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_train[df_train.date.isin(\n",
    "    pd.date_range(\"2017-05-31\", periods=7 * 11))].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50912462</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>96995</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50912463</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>99197</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50912464</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>103520</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50912465</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>103665</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50912466</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>105574</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "50912462 2017-05-31          1     96995    0.693147        False\n",
       "50912463 2017-05-31          1     99197    0.693147        False\n",
       "50912464 2017-05-31          1    103520    1.386294        False\n",
       "50912465 2017-05-31          1    103665    2.197225        False\n",
       "50912466 2017-05-31          1    105574    1.386294        False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2016-01-01 00:00:00'), Timestamp('2017-08-15 00:00:00'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0,0], df_train.iloc[-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2017-05-31 00:00:00'), Timestamp('2017-08-15 00:00:00'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.iloc[0,0], df_2017.iloc[-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8125670, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2497767.123076923"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YearsInTrain = (2017-2013)+1\n",
    "    \n",
    "(df_train.shape[0]/YearsInTrain)*(11/52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Promotion Variables\n",
    "\n",
    "So this is a tricky. If one presumes that on-promotion will lead to a boost in demand, if if we presume we'll know *whats on promotion in advance*, then we can create variables to say that this product will be on promotion 1, 2, 3, ... 16 days from now (16 days in the future is the target)\n",
    "\n",
    "In this case, this is also peculiar, there is a column for every single day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               onpromotion\n",
       "store_nbr item_nbr date                   \n",
       "1         96995    2017-05-31        False\n",
       "          99197    2017-05-31        False\n",
       "          103520   2017-05-31        False\n",
       "          103665   2017-05-31        False\n",
       "          105574   2017-05-31        False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <th>2017-06-01</th>\n",
       "      <th>2017-06-02</th>\n",
       "      <th>2017-06-03</th>\n",
       "      <th>2017-06-04</th>\n",
       "      <th>2017-06-05</th>\n",
       "      <th>2017-06-06</th>\n",
       "      <th>2017-06-07</th>\n",
       "      <th>2017-06-08</th>\n",
       "      <th>2017-06-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06</th>\n",
       "      <th>2017-08-07</th>\n",
       "      <th>2017-08-08</th>\n",
       "      <th>2017-08-09</th>\n",
       "      <th>2017-08-10</th>\n",
       "      <th>2017-08-11</th>\n",
       "      <th>2017-08-12</th>\n",
       "      <th>2017-08-13</th>\n",
       "      <th>2017-08-14</th>\n",
       "      <th>2017-08-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   onpromotion                                              \\\n",
       "date                2017-05-31 2017-06-01 2017-06-02 2017-06-03 2017-06-04   \n",
       "store_nbr item_nbr                                                           \n",
       "1         96995          False      False      False      False      False   \n",
       "          99197          False      False      False      False      False   \n",
       "          103520         False      False      False      False      False   \n",
       "          103665         False      False      False      False      False   \n",
       "          105574         False      False      False      False      False   \n",
       "\n",
       "                                                                           \\\n",
       "date               2017-06-05 2017-06-06 2017-06-07 2017-06-08 2017-06-09   \n",
       "store_nbr item_nbr                                                          \n",
       "1         96995         False      False      False      False      False   \n",
       "          99197         False      False      False      False      False   \n",
       "          103520        False      False      False      False      False   \n",
       "          103665        False      False      False      False      False   \n",
       "          105574        False      False      False      False      False   \n",
       "\n",
       "                      ...                                                  \\\n",
       "date                  ...     2017-08-06 2017-08-07 2017-08-08 2017-08-09   \n",
       "store_nbr item_nbr    ...                                                   \n",
       "1         96995       ...          False      False      False      False   \n",
       "          99197       ...          False      False      False      False   \n",
       "          103520      ...          False      False      False      False   \n",
       "          103665      ...          False      False      False      False   \n",
       "          105574      ...          False      False      False      False   \n",
       "\n",
       "                                                                           \\\n",
       "date               2017-08-10 2017-08-11 2017-08-12 2017-08-13 2017-08-14   \n",
       "store_nbr item_nbr                                                          \n",
       "1         96995         False      False      False      False      False   \n",
       "          99197         False      False      False      False      False   \n",
       "          103520        False      False      False      False      False   \n",
       "          103665        False      False      False      False      False   \n",
       "          105574        False      False      False      False      False   \n",
       "\n",
       "                               \n",
       "date               2017-08-15  \n",
       "store_nbr item_nbr             \n",
       "1         96995         False  \n",
       "          99197         False  \n",
       "          103520        False  \n",
       "          103665        False  \n",
       "          105574        False  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156790, 93), 221400)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017.shape, items.shape[0] * stores.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-05-31 00:00:00</th>\n",
       "      <th>2017-06-01 00:00:00</th>\n",
       "      <th>2017-06-02 00:00:00</th>\n",
       "      <th>2017-06-03 00:00:00</th>\n",
       "      <th>2017-06-04 00:00:00</th>\n",
       "      <th>2017-06-05 00:00:00</th>\n",
       "      <th>2017-06-06 00:00:00</th>\n",
       "      <th>2017-06-07 00:00:00</th>\n",
       "      <th>2017-06-08 00:00:00</th>\n",
       "      <th>2017-06-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22 00:00:00</th>\n",
       "      <th>2017-08-23 00:00:00</th>\n",
       "      <th>2017-08-24 00:00:00</th>\n",
       "      <th>2017-08-25 00:00:00</th>\n",
       "      <th>2017-08-26 00:00:00</th>\n",
       "      <th>2017-08-27 00:00:00</th>\n",
       "      <th>2017-08-28 00:00:00</th>\n",
       "      <th>2017-08-29 00:00:00</th>\n",
       "      <th>2017-08-30 00:00:00</th>\n",
       "      <th>2017-08-31 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-05-31  2017-06-01  2017-06-02  2017-06-03  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False       False       False   \n",
       "\n",
       "date                2017-06-04  2017-06-05  2017-06-06  2017-06-07  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False       False       False   \n",
       "\n",
       "date                2017-06-08  2017-06-09     ...      2017-08-22  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995          False       False     ...           False   \n",
       "          99197          False       False     ...           False   \n",
       "          103520         False       False     ...           False   \n",
       "          103665         False       False     ...           False   \n",
       "          105574         False       False     ...           False   \n",
       "\n",
       "date                2017-08-23  2017-08-24  2017-08-25  2017-08-26  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False       False       False   \n",
       "\n",
       "date                2017-08-27  2017-08-28  2017-08-29  2017-08-30  2017-08-31  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995          False       False       False       False       False  \n",
       "          99197          False       False       False       False       False  \n",
       "          103520         False       False       False       False       False  \n",
       "          103665         False       False       False       False       False  \n",
       "          105574         False       False       False       False       False  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del promo_2017_test, promo_2017_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Unstack unit sales - do it across all days in a sliding window\n",
    "\n",
    "Ah... they're creating a multi-task learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156790, 77)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "df_2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-05-31 00:00:00</th>\n",
       "      <th>2017-06-01 00:00:00</th>\n",
       "      <th>2017-06-02 00:00:00</th>\n",
       "      <th>2017-06-03 00:00:00</th>\n",
       "      <th>2017-06-04 00:00:00</th>\n",
       "      <th>2017-06-05 00:00:00</th>\n",
       "      <th>2017-06-06 00:00:00</th>\n",
       "      <th>2017-06-07 00:00:00</th>\n",
       "      <th>2017-06-08 00:00:00</th>\n",
       "      <th>2017-06-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-05-31  2017-06-01  2017-06-02  2017-06-03  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.693147    0.000000    0.000000    0.000000   \n",
       "          99197       0.693147    1.386294    1.098612    1.945910   \n",
       "          103520      1.386294    1.098612    1.098612    0.693147   \n",
       "          103665      2.197225    0.000000    1.791759    1.791759   \n",
       "          105574      1.386294    2.484907    1.791759    1.386294   \n",
       "\n",
       "date                2017-06-04  2017-06-05  2017-06-06  2017-06-07  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       1.098612    1.098612    0.000000    0.000000   \n",
       "          103520      0.000000    0.693147    1.609438    0.693147   \n",
       "          103665      1.098612    1.386294    1.791759    1.386294   \n",
       "          105574      1.386294    1.386294    2.079442    2.397895   \n",
       "\n",
       "date                2017-06-08  2017-06-09     ...      2017-08-06  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995       0.000000    0.693147     ...        1.098612   \n",
       "          99197       0.693147    0.693147     ...        0.000000   \n",
       "          103520      0.693147    1.098612     ...        0.000000   \n",
       "          103665      0.000000    1.098612     ...        0.693147   \n",
       "          105574      1.945910    2.079442     ...        0.000000   \n",
       "\n",
       "date                2017-08-07  2017-08-08  2017-08-09  2017-08-10  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       1.098612    0.000000    0.000000    0.693147   \n",
       "          99197       1.098612    0.000000    1.098612    0.000000   \n",
       "          103520      0.000000    1.386294    0.000000    1.386294   \n",
       "          103665      1.098612    0.000000    2.079442    2.302585   \n",
       "          105574      1.791759    2.079442    1.945910    2.397895   \n",
       "\n",
       "date                2017-08-11  2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          99197       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          103520      0.693147    0.693147    0.693147    0.000000    0.000000  \n",
       "          103665      1.098612    0.000000    0.000000    0.693147    0.693147  \n",
       "          105574      1.791759    1.791759    0.000000    1.386294    1.609438  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make items match other data frames\n",
    "\n",
    "They're sacraficing generability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                family  class  perishable\n",
       "item_nbr                                 \n",
       "96995        GROCERY I   1093           0\n",
       "99197        GROCERY I   1067           0\n",
       "103520       GROCERY I   1028           0\n",
       "103665    BREAD/BAKERY   2712           1\n",
       "105574       GROCERY I   1045           0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156790, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time futzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return that portion of the data frame that corresponds to the time period\n",
    "#   beginning \"minus\" days before \"dt\" and extending for \"periods\" days\n",
    "def get_timespan(df, dt, minus, periods):\n",
    "    return df[\n",
    "        pd.date_range(dt - timedelta(days=minus), periods=periods)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({  # Mean target for different retrospective timespans & total # promotions\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(16):  # Promotions on future days\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[  # Target values for future days\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 6, 21)\n",
    "X_l, y_l = [], []\n",
    "for i in range(4):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_14_2017</th>\n",
       "      <th>mean_3_2017</th>\n",
       "      <th>mean_7_2017</th>\n",
       "      <th>promo_14_2017</th>\n",
       "      <th>promo_0</th>\n",
       "      <th>promo_1</th>\n",
       "      <th>promo_2</th>\n",
       "      <th>promo_3</th>\n",
       "      <th>promo_4</th>\n",
       "      <th>promo_5</th>\n",
       "      <th>promo_6</th>\n",
       "      <th>promo_7</th>\n",
       "      <th>promo_8</th>\n",
       "      <th>promo_9</th>\n",
       "      <th>promo_10</th>\n",
       "      <th>promo_11</th>\n",
       "      <th>promo_12</th>\n",
       "      <th>promo_13</th>\n",
       "      <th>promo_14</th>\n",
       "      <th>promo_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.835944</td>\n",
       "      <td>1.245890</td>\n",
       "      <td>0.987960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.840554</td>\n",
       "      <td>0.462098</td>\n",
       "      <td>0.773092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.141420</td>\n",
       "      <td>1.059351</td>\n",
       "      <td>1.243926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.645124</td>\n",
       "      <td>1.416165</td>\n",
       "      <td>1.505723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.250081</td>\n",
       "      <td>2.507286</td>\n",
       "      <td>2.380866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.688537</td>\n",
       "      <td>0.462098</td>\n",
       "      <td>0.526983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.297063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.070138</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.973349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.818947</td>\n",
       "      <td>2.132310</td>\n",
       "      <td>2.019905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.923954</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.939893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.568968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.375535</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.198042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.906321</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>0.782948</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.264793</td>\n",
       "      <td>1.229626</td>\n",
       "      <td>1.316901</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.623088</td>\n",
       "      <td>0.462098</td>\n",
       "      <td>0.495105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.007036</td>\n",
       "      <td>0.462098</td>\n",
       "      <td>0.891189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.709973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.733438</td>\n",
       "      <td>0.597253</td>\n",
       "      <td>0.814826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.997498</td>\n",
       "      <td>0.462098</td>\n",
       "      <td>0.751071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.010367</td>\n",
       "      <td>1.997155</td>\n",
       "      <td>2.092880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.671474</td>\n",
       "      <td>0.648637</td>\n",
       "      <td>0.831016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.804384</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.020963</td>\n",
       "      <td>0.924196</td>\n",
       "      <td>1.053966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.430070</td>\n",
       "      <td>1.059351</td>\n",
       "      <td>1.258978</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.454008</td>\n",
       "      <td>0.597253</td>\n",
       "      <td>0.354987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.311811</td>\n",
       "      <td>1.341784</td>\n",
       "      <td>1.412712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.041830</td>\n",
       "      <td>0.462098</td>\n",
       "      <td>0.913847</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.861435</td>\n",
       "      <td>1.805367</td>\n",
       "      <td>2.056178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.454022</td>\n",
       "      <td>1.329661</td>\n",
       "      <td>1.436773</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156760</th>\n",
       "      <td>1.185433</td>\n",
       "      <td>0.924196</td>\n",
       "      <td>1.290855</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156761</th>\n",
       "      <td>3.896037</td>\n",
       "      <td>4.056622</td>\n",
       "      <td>3.863889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156762</th>\n",
       "      <td>1.263350</td>\n",
       "      <td>1.329661</td>\n",
       "      <td>1.637760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156763</th>\n",
       "      <td>0.127983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156764</th>\n",
       "      <td>3.012187</td>\n",
       "      <td>3.401789</td>\n",
       "      <td>3.358876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156765</th>\n",
       "      <td>0.378451</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>0.328941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156766</th>\n",
       "      <td>0.362512</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>0.427962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156767</th>\n",
       "      <td>1.148946</td>\n",
       "      <td>0.902683</td>\n",
       "      <td>0.862894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156768</th>\n",
       "      <td>1.927654</td>\n",
       "      <td>2.164080</td>\n",
       "      <td>1.656884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156769</th>\n",
       "      <td>1.010840</td>\n",
       "      <td>1.194506</td>\n",
       "      <td>1.064960</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156770</th>\n",
       "      <td>0.352974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156771</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156772</th>\n",
       "      <td>0.725912</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.997817</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156773</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156774</th>\n",
       "      <td>0.433459</td>\n",
       "      <td>0.963457</td>\n",
       "      <td>0.412910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156775</th>\n",
       "      <td>2.589948</td>\n",
       "      <td>3.160758</td>\n",
       "      <td>3.252043</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156776</th>\n",
       "      <td>2.275859</td>\n",
       "      <td>2.640995</td>\n",
       "      <td>2.294340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156777</th>\n",
       "      <td>1.003899</td>\n",
       "      <td>1.476939</td>\n",
       "      <td>1.333727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156778</th>\n",
       "      <td>1.494076</td>\n",
       "      <td>1.759372</td>\n",
       "      <td>1.406066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156779</th>\n",
       "      <td>0.305476</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.297063</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156780</th>\n",
       "      <td>0.148532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156781</th>\n",
       "      <td>0.383948</td>\n",
       "      <td>0.366204</td>\n",
       "      <td>0.313889</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156782</th>\n",
       "      <td>0.326025</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.495105</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156783</th>\n",
       "      <td>0.589516</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.454008</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156784</th>\n",
       "      <td>0.668876</td>\n",
       "      <td>0.462098</td>\n",
       "      <td>0.866918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156785</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156786</th>\n",
       "      <td>4.460126</td>\n",
       "      <td>2.951888</td>\n",
       "      <td>4.121203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156787</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156788</th>\n",
       "      <td>1.339062</td>\n",
       "      <td>2.957262</td>\n",
       "      <td>1.779329</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156789</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627160 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_14_2017  mean_3_2017  mean_7_2017  promo_14_2017  promo_0  \\\n",
       "0           0.099021     0.000000     0.099021              0        0   \n",
       "1           0.835944     1.245890     0.987960              0        0   \n",
       "2           0.840554     0.462098     0.773092              0        0   \n",
       "3           1.141420     1.059351     1.243926              0        0   \n",
       "4           1.645124     1.416165     1.505723              0        0   \n",
       "5           2.250081     2.507286     2.380866              0        0   \n",
       "6           0.688537     0.462098     0.526983              0        0   \n",
       "7           0.297063     0.000000     0.297063              0        0   \n",
       "8           1.070138     0.231049     0.973349              0        0   \n",
       "9           1.818947     2.132310     2.019905              0        0   \n",
       "10          0.923954     0.828302     0.939893              0        0   \n",
       "11          0.568968     0.000000     0.495105              0        0   \n",
       "12          0.375535     0.231049     0.198042              0        0   \n",
       "13          0.906321     0.998577     0.782948              2        0   \n",
       "14          1.264793     1.229626     1.316901              2        0   \n",
       "15          0.623088     0.462098     0.495105              1        0   \n",
       "16          1.007036     0.462098     0.891189              0        0   \n",
       "17          0.709973     0.000000     0.454008              1        0   \n",
       "18          0.733438     0.597253     0.814826              0        0   \n",
       "19          0.997498     0.462098     0.751071              0        0   \n",
       "20          2.010367     1.997155     2.092880              0        0   \n",
       "21          0.671474     0.648637     0.831016              0        0   \n",
       "22          0.804384     0.828302     0.709973              0        0   \n",
       "23          1.020963     0.924196     1.053966              0        0   \n",
       "24          1.430070     1.059351     1.258978             13        1   \n",
       "25          0.454008     0.597253     0.354987              0        0   \n",
       "26          1.311811     1.341784     1.412712              0        0   \n",
       "27          1.041830     0.462098     0.913847             10        0   \n",
       "28          1.861435     1.805367     2.056178              0        0   \n",
       "29          1.454022     1.329661     1.436773             12        1   \n",
       "...              ...          ...          ...            ...      ...   \n",
       "156760      1.185433     0.924196     1.290855              7        0   \n",
       "156761      3.896037     4.056622     3.863889              0        0   \n",
       "156762      1.263350     1.329661     1.637760              0        0   \n",
       "156763      0.127983     0.000000     0.156945              0        0   \n",
       "156764      3.012187     3.401789     3.358876              0        0   \n",
       "156765      0.378451     0.536479     0.328941              0        0   \n",
       "156766      0.362512     0.536479     0.427962              0        0   \n",
       "156767      1.148946     0.902683     0.862894              0        0   \n",
       "156768      1.927654     2.164080     1.656884              0        0   \n",
       "156769      1.010840     1.194506     1.064960              2        1   \n",
       "156770      0.352974     0.000000     0.000000              1        1   \n",
       "156771      0.000000     0.000000     0.000000              0        0   \n",
       "156772      0.725912     0.828302     0.997817              1        0   \n",
       "156773      0.000000     0.000000     0.000000              0        0   \n",
       "156774      0.433459     0.963457     0.412910              0        0   \n",
       "156775      2.589948     3.160758     3.252043              6        1   \n",
       "156776      2.275859     2.640995     2.294340              0        0   \n",
       "156777      1.003899     1.476939     1.333727              0        0   \n",
       "156778      1.494076     1.759372     1.406066              0        0   \n",
       "156779      0.305476     0.231049     0.297063              4        0   \n",
       "156780      0.148532     0.000000     0.000000              3        0   \n",
       "156781      0.383948     0.366204     0.313889              5        0   \n",
       "156782      0.326025     0.693147     0.495105              3        0   \n",
       "156783      0.589516     0.828302     0.454008              4        0   \n",
       "156784      0.668876     0.462098     0.866918              0        0   \n",
       "156785      0.000000     0.000000     0.000000              0        0   \n",
       "156786      4.460126     2.951888     4.121203              0        0   \n",
       "156787      0.000000     0.000000     0.000000              0        0   \n",
       "156788      1.339062     2.957262     1.779329              2        1   \n",
       "156789      0.000000     0.000000     0.000000              0        0   \n",
       "\n",
       "        promo_1  promo_2  promo_3  promo_4  promo_5  promo_6  promo_7  \\\n",
       "0             0        0        0        0        0        0        0   \n",
       "1             0        0        0        0        0        0        0   \n",
       "2             0        0        0        0        0        0        0   \n",
       "3             0        0        0        0        0        0        0   \n",
       "4             0        0        0        0        0        0        0   \n",
       "5             0        0        0        0        0        0        0   \n",
       "6             0        0        0        0        0        0        0   \n",
       "7             0        0        0        0        0        0        0   \n",
       "8             0        0        0        0        0        0        0   \n",
       "9             0        0        0        0        0        0        0   \n",
       "10            0        0        0        0        0        0        0   \n",
       "11            0        0        0        0        0        0        0   \n",
       "12            0        0        0        0        0        0        0   \n",
       "13            0        1        0        0        0        0        0   \n",
       "14            0        1        0        0        0        0        0   \n",
       "15            0        1        0        0        0        0        0   \n",
       "16            0        0        0        0        0        0        0   \n",
       "17            0        0        0        0        0        0        0   \n",
       "18            0        0        0        0        0        0        0   \n",
       "19            0        0        0        0        0        0        0   \n",
       "20            0        0        0        0        0        0        0   \n",
       "21            0        0        0        0        0        0        0   \n",
       "22            0        0        0        0        0        0        0   \n",
       "23            0        0        0        0        0        0        0   \n",
       "24            0        0        0        0        0        0        0   \n",
       "25            0        0        0        0        0        0        0   \n",
       "26            0        0        0        0        0        0        0   \n",
       "27            1        0        0        0        0        1        1   \n",
       "28            0        0        0        0        0        0        0   \n",
       "29            1        1        1        1        0        0        0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "156760        0        0        0        0        0        0        0   \n",
       "156761        0        0        0        0        0        0        0   \n",
       "156762        0        0        0        0        0        0        0   \n",
       "156763        0        0        0        0        0        0        0   \n",
       "156764        0        0        0        0        0        0        0   \n",
       "156765        0        0        0        0        0        0        0   \n",
       "156766        0        0        0        0        0        0        0   \n",
       "156767        0        0        0        0        0        0        0   \n",
       "156768        0        0        0        0        0        0        0   \n",
       "156769        0        0        0        0        0        0        1   \n",
       "156770        0        0        0        0        0        0        0   \n",
       "156771        0        0        0        0        0        0        0   \n",
       "156772        0        0        0        0        0        0        1   \n",
       "156773        0        0        0        0        0        0        0   \n",
       "156774        0        0        0        0        0        0        0   \n",
       "156775        1        1        1        1        1        1        1   \n",
       "156776        0        0        0        0        0        0        0   \n",
       "156777        0        0        0        0        0        0        0   \n",
       "156778        0        0        0        0        0        0        0   \n",
       "156779        0        0        0        0        0        0        0   \n",
       "156780        0        0        0        0        0        0        0   \n",
       "156781        0        0        0        0        0        0        0   \n",
       "156782        0        0        0        0        0        0        0   \n",
       "156783        0        0        0        0        0        0        0   \n",
       "156784        0        0        0        0        0        0        0   \n",
       "156785        0        0        0        0        0        0        0   \n",
       "156786        0        0        0        0        0        0        0   \n",
       "156787        0        0        0        0        0        0        0   \n",
       "156788        1        1        1        1        1        1        1   \n",
       "156789        0        0        0        0        0        0        0   \n",
       "\n",
       "        promo_8  promo_9  promo_10  promo_11  promo_12  promo_13  promo_14  \\\n",
       "0             0        0         0         0         0         0         0   \n",
       "1             0        0         0         0         0         0         0   \n",
       "2             0        0         0         0         0         0         0   \n",
       "3             0        0         0         0         0         0         0   \n",
       "4             0        0         0         0         0         0         0   \n",
       "5             0        0         0         0         0         0         0   \n",
       "6             0        0         0         0         0         0         0   \n",
       "7             0        0         0         0         0         0         0   \n",
       "8             0        0         0         0         0         0         0   \n",
       "9             0        0         0         0         0         0         0   \n",
       "10            0        0         0         0         0         0         0   \n",
       "11            0        0         0         0         0         0         0   \n",
       "12            0        0         0         0         0         0         0   \n",
       "13            0        1         0         0         0         0         0   \n",
       "14            0        1         0         0         0         0         0   \n",
       "15            0        1         0         0         0         0         0   \n",
       "16            0        0         0         0         0         0         0   \n",
       "17            0        0         0         0         1         0         0   \n",
       "18            0        0         0         0         0         0         0   \n",
       "19            0        0         0         0         0         0         0   \n",
       "20            0        0         0         0         0         0         0   \n",
       "21            0        0         0         0         0         0         1   \n",
       "22            0        0         0         0         0         0         0   \n",
       "23            0        0         0         0         0         0         0   \n",
       "24            0        1         0         0         0         0         1   \n",
       "25            0        0         0         0         0         0         0   \n",
       "26            0        0         0         0         0         0         0   \n",
       "27            1        1         0         0         0         0         0   \n",
       "28            0        0         0         0         0         0         0   \n",
       "29            0        0         0         0         0         0         0   \n",
       "...         ...      ...       ...       ...       ...       ...       ...   \n",
       "156760        0        0         0         0         0         0         0   \n",
       "156761        0        0         0         0         0         0         0   \n",
       "156762        0        0         0         0         0         0         0   \n",
       "156763        0        0         0         0         0         0         0   \n",
       "156764        0        0         0         0         0         0         0   \n",
       "156765        0        1         0         0         0         0         0   \n",
       "156766        0        1         0         0         0         0         0   \n",
       "156767        0        0         0         0         0         0         0   \n",
       "156768        0        0         0         0         0         0         0   \n",
       "156769        0        0         0         0         0         0         1   \n",
       "156770        0        0         0         0         0         0         1   \n",
       "156771        0        0         0         0         0         0         0   \n",
       "156772        0        0         0         0         0         0         0   \n",
       "156773        0        0         0         0         0         0         0   \n",
       "156774        0        0         0         0         0         0         0   \n",
       "156775        1        1         1         1         1         1         1   \n",
       "156776        0        0         0         0         0         0         0   \n",
       "156777        0        0         0         0         0         0         0   \n",
       "156778        0        0         0         0         0         0         0   \n",
       "156779        0        0         0         0         0         0         0   \n",
       "156780        0        0         0         0         0         0         0   \n",
       "156781        0        0         0         0         0         0         0   \n",
       "156782        0        0         0         0         0         0         0   \n",
       "156783        0        0         0         0         0         0         0   \n",
       "156784        0        0         0         0         0         0         0   \n",
       "156785        0        0         0         0         0         0         0   \n",
       "156786        0        0         0         0         0         0         0   \n",
       "156787        0        0         0         0         0         0         0   \n",
       "156788        0        0         1         1         0         1         1   \n",
       "156789        0        0         0         0         0         0         0   \n",
       "\n",
       "        promo_15  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "6              0  \n",
       "7              0  \n",
       "8              0  \n",
       "9              0  \n",
       "10             0  \n",
       "11             0  \n",
       "12             0  \n",
       "13             0  \n",
       "14             0  \n",
       "15             0  \n",
       "16             0  \n",
       "17             0  \n",
       "18             0  \n",
       "19             0  \n",
       "20             0  \n",
       "21             0  \n",
       "22             0  \n",
       "23             0  \n",
       "24             0  \n",
       "25             0  \n",
       "26             0  \n",
       "27             0  \n",
       "28             0  \n",
       "29             0  \n",
       "...          ...  \n",
       "156760         0  \n",
       "156761         0  \n",
       "156762         0  \n",
       "156763         0  \n",
       "156764         0  \n",
       "156765         0  \n",
       "156766         0  \n",
       "156767         0  \n",
       "156768         0  \n",
       "156769         0  \n",
       "156770         0  \n",
       "156771         0  \n",
       "156772         0  \n",
       "156773         0  \n",
       "156774         0  \n",
       "156775         0  \n",
       "156776         0  \n",
       "156777         0  \n",
       "156778         0  \n",
       "156779         0  \n",
       "156780         0  \n",
       "156781         0  \n",
       "156782         0  \n",
       "156783         0  \n",
       "156784         0  \n",
       "156785         0  \n",
       "156786         0  \n",
       "156787         0  \n",
       "156788         1  \n",
       "156789         0  \n",
       "\n",
       "[627160 rows x 20 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((627160, 20), (627160, 16))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is **super gamey**. They're using the means for the week, fortnight, and last three days, and then seeing how to permute it to generate values for the following window of time. It's hardcoded to product IDs, not categories.\n",
    "\n",
    "It does however, permit multi-task learning, and therefore better representation learning\n",
    "\n",
    "It does not incorporate any information about seasonality at all, and so would fall arse over face at Christmas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryanfeeney/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.345147\tvalid_1's l2: 0.341487\n",
      "[100]\ttraining's l2: 0.333379\tvalid_1's l2: 0.330174\n",
      "[150]\ttraining's l2: 0.331405\tvalid_1's l2: 0.328823\n",
      "[200]\ttraining's l2: 0.330344\tvalid_1's l2: 0.328317\n",
      "[250]\ttraining's l2: 0.329476\tvalid_1's l2: 0.327889\n",
      "[300]\ttraining's l2: 0.328793\tvalid_1's l2: 0.327649\n",
      "[350]\ttraining's l2: 0.328187\tvalid_1's l2: 0.327459\n",
      "[400]\ttraining's l2: 0.327652\tvalid_1's l2: 0.327329\n",
      "[450]\ttraining's l2: 0.327151\tvalid_1's l2: 0.327218\n",
      "[500]\ttraining's l2: 0.326681\tvalid_1's l2: 0.327129\n",
      "[550]\ttraining's l2: 0.326264\tvalid_1's l2: 0.327102\n",
      "[600]\ttraining's l2: 0.325878\tvalid_1's l2: 0.327031\n",
      "[650]\ttraining's l2: 0.325453\tvalid_1's l2: 0.326991\n",
      "[700]\ttraining's l2: 0.325065\tvalid_1's l2: 0.326944\n",
      "[750]\ttraining's l2: 0.324698\tvalid_1's l2: 0.326981\n",
      "Early stopping, best iteration is:\n",
      "[712]\ttraining's l2: 0.324969\tvalid_1's l2: 0.326938\n",
      "mean_14_2017: 1984359.03\n",
      "mean_7_2017: 1460047.19\n",
      "mean_3_2017: 315633.02\n",
      "promo_0: 138629.68\n",
      "promo_14_2017: 55752.64\n",
      "promo_7: 21151.43\n",
      "promo_14: 7359.92\n",
      "promo_3: 5651.84\n",
      "promo_15: 3673.71\n",
      "promo_9: 3040.06\n",
      "promo_2: 2182.57\n",
      "promo_13: 2145.98\n",
      "promo_4: 1850.12\n",
      "promo_6: 1666.96\n",
      "promo_1: 1300.76\n",
      "promo_8: 1140.84\n",
      "promo_11: 1099.40\n",
      "promo_10: 1005.44\n",
      "promo_5: 987.11\n",
      "promo_12: 892.11\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.362076\tvalid_1's l2: 0.373873\n",
      "[100]\ttraining's l2: 0.352754\tvalid_1's l2: 0.363655\n",
      "[150]\ttraining's l2: 0.350666\tvalid_1's l2: 0.362006\n",
      "[200]\ttraining's l2: 0.349531\tvalid_1's l2: 0.361224\n",
      "[250]\ttraining's l2: 0.348631\tvalid_1's l2: 0.360787\n",
      "[300]\ttraining's l2: 0.347873\tvalid_1's l2: 0.360452\n",
      "[350]\ttraining's l2: 0.347208\tvalid_1's l2: 0.36028\n",
      "[400]\ttraining's l2: 0.346644\tvalid_1's l2: 0.360162\n",
      "[450]\ttraining's l2: 0.346098\tvalid_1's l2: 0.360094\n",
      "[500]\ttraining's l2: 0.345586\tvalid_1's l2: 0.360001\n",
      "[550]\ttraining's l2: 0.345142\tvalid_1's l2: 0.359979\n",
      "[600]\ttraining's l2: 0.3447\tvalid_1's l2: 0.359935\n",
      "[650]\ttraining's l2: 0.344283\tvalid_1's l2: 0.359878\n",
      "[700]\ttraining's l2: 0.34386\tvalid_1's l2: 0.359895\n",
      "Early stopping, best iteration is:\n",
      "[677]\ttraining's l2: 0.344061\tvalid_1's l2: 0.359856\n",
      "mean_14_2017: 1863420.76\n",
      "mean_7_2017: 1002068.14\n",
      "mean_3_2017: 249076.86\n",
      "promo_1: 99598.59\n",
      "promo_14_2017: 45303.66\n",
      "promo_3: 12426.16\n",
      "promo_0: 7116.38\n",
      "promo_2: 6507.20\n",
      "promo_4: 5307.43\n",
      "promo_5: 4809.32\n",
      "promo_7: 2171.31\n",
      "promo_6: 1987.07\n",
      "promo_9: 1948.41\n",
      "promo_8: 1815.36\n",
      "promo_14: 1663.94\n",
      "promo_15: 1300.56\n",
      "promo_13: 940.38\n",
      "promo_11: 891.77\n",
      "promo_12: 809.27\n",
      "promo_10: 733.40\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.380958\tvalid_1's l2: 0.402325\n",
      "[100]\ttraining's l2: 0.36752\tvalid_1's l2: 0.390119\n",
      "[150]\ttraining's l2: 0.364539\tvalid_1's l2: 0.388836\n",
      "[200]\ttraining's l2: 0.363109\tvalid_1's l2: 0.388261\n",
      "[250]\ttraining's l2: 0.361992\tvalid_1's l2: 0.38778\n",
      "[300]\ttraining's l2: 0.361092\tvalid_1's l2: 0.387636\n",
      "[350]\ttraining's l2: 0.360383\tvalid_1's l2: 0.387466\n",
      "[400]\ttraining's l2: 0.359696\tvalid_1's l2: 0.387286\n",
      "[450]\ttraining's l2: 0.359087\tvalid_1's l2: 0.387174\n",
      "[500]\ttraining's l2: 0.358505\tvalid_1's l2: 0.387097\n",
      "[550]\ttraining's l2: 0.357998\tvalid_1's l2: 0.387024\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's l2: 0.358116\tvalid_1's l2: 0.387023\n",
      "mean_14_2017: 2314537.97\n",
      "mean_7_2017: 970735.19\n",
      "mean_3_2017: 271517.82\n",
      "promo_2: 142199.56\n",
      "promo_14_2017: 60530.43\n",
      "promo_9: 14393.73\n",
      "promo_3: 9973.03\n",
      "promo_0: 5948.03\n",
      "promo_5: 5939.01\n",
      "promo_4: 5323.99\n",
      "promo_1: 4437.70\n",
      "promo_7: 4209.49\n",
      "promo_14: 3350.50\n",
      "promo_10: 2397.69\n",
      "promo_6: 2369.49\n",
      "promo_13: 2301.63\n",
      "promo_11: 1802.19\n",
      "promo_15: 1686.21\n",
      "promo_12: 1132.91\n",
      "promo_8: 1036.03\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.410859\tvalid_1's l2: 0.414478\n",
      "[100]\ttraining's l2: 0.398544\tvalid_1's l2: 0.402678\n",
      "[150]\ttraining's l2: 0.395316\tvalid_1's l2: 0.400757\n",
      "[200]\ttraining's l2: 0.393693\tvalid_1's l2: 0.399966\n",
      "[250]\ttraining's l2: 0.392531\tvalid_1's l2: 0.399542\n",
      "[300]\ttraining's l2: 0.391597\tvalid_1's l2: 0.399159\n",
      "[350]\ttraining's l2: 0.390846\tvalid_1's l2: 0.398996\n",
      "[400]\ttraining's l2: 0.390139\tvalid_1's l2: 0.398757\n",
      "[450]\ttraining's l2: 0.389497\tvalid_1's l2: 0.398663\n",
      "[500]\ttraining's l2: 0.388863\tvalid_1's l2: 0.39857\n",
      "[550]\ttraining's l2: 0.388348\tvalid_1's l2: 0.39848\n",
      "[600]\ttraining's l2: 0.387831\tvalid_1's l2: 0.398336\n",
      "[650]\ttraining's l2: 0.387343\tvalid_1's l2: 0.398262\n",
      "[700]\ttraining's l2: 0.386858\tvalid_1's l2: 0.398191\n",
      "Early stopping, best iteration is:\n",
      "[689]\ttraining's l2: 0.386968\tvalid_1's l2: 0.398183\n",
      "mean_14_2017: 2697032.96\n",
      "mean_7_2017: 1105475.42\n",
      "mean_3_2017: 316007.62\n",
      "promo_3: 83439.28\n",
      "promo_14_2017: 47082.25\n",
      "promo_2: 12419.23\n",
      "promo_5: 9076.45\n",
      "promo_4: 8472.54\n",
      "promo_0: 8113.76\n",
      "promo_1: 7250.05\n",
      "promo_7: 6305.30\n",
      "promo_14: 3936.92\n",
      "promo_6: 3479.44\n",
      "promo_9: 2874.90\n",
      "promo_8: 2604.46\n",
      "promo_10: 2330.52\n",
      "promo_13: 1567.90\n",
      "promo_15: 1530.82\n",
      "promo_11: 1258.65\n",
      "promo_12: 814.40\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.439686\tvalid_1's l2: 0.437679\n",
      "[100]\ttraining's l2: 0.425843\tvalid_1's l2: 0.425114\n",
      "[150]\ttraining's l2: 0.422312\tvalid_1's l2: 0.422295\n",
      "[200]\ttraining's l2: 0.420541\tvalid_1's l2: 0.421264\n",
      "[250]\ttraining's l2: 0.419215\tvalid_1's l2: 0.420517\n",
      "[300]\ttraining's l2: 0.418177\tvalid_1's l2: 0.420055\n",
      "[350]\ttraining's l2: 0.417341\tvalid_1's l2: 0.419739\n",
      "[400]\ttraining's l2: 0.416565\tvalid_1's l2: 0.419497\n",
      "[450]\ttraining's l2: 0.415864\tvalid_1's l2: 0.419336\n",
      "[500]\ttraining's l2: 0.415169\tvalid_1's l2: 0.419215\n",
      "[550]\ttraining's l2: 0.414585\tvalid_1's l2: 0.418983\n",
      "[600]\ttraining's l2: 0.414\tvalid_1's l2: 0.418776\n",
      "[650]\ttraining's l2: 0.41346\tvalid_1's l2: 0.418689\n",
      "[700]\ttraining's l2: 0.412937\tvalid_1's l2: 0.418657\n",
      "[750]\ttraining's l2: 0.41247\tvalid_1's l2: 0.41859\n",
      "[800]\ttraining's l2: 0.412005\tvalid_1's l2: 0.418553\n",
      "[850]\ttraining's l2: 0.411583\tvalid_1's l2: 0.418509\n",
      "[900]\ttraining's l2: 0.411122\tvalid_1's l2: 0.41849\n",
      "[950]\ttraining's l2: 0.410661\tvalid_1's l2: 0.418441\n",
      "Early stopping, best iteration is:\n",
      "[933]\ttraining's l2: 0.410827\tvalid_1's l2: 0.418415\n",
      "mean_14_2017: 2914640.44\n",
      "mean_7_2017: 924894.39\n",
      "mean_3_2017: 566781.56\n",
      "promo_4: 86610.06\n",
      "promo_14_2017: 46068.66\n",
      "promo_5: 12201.68\n",
      "promo_3: 10571.08\n",
      "promo_7: 9095.47\n",
      "promo_2: 7886.59\n",
      "promo_0: 6682.90\n",
      "promo_6: 6318.31\n",
      "promo_1: 6101.91\n",
      "promo_14: 5228.28\n",
      "promo_9: 4469.97\n",
      "promo_11: 4104.98\n",
      "promo_8: 3289.03\n",
      "promo_10: 2272.15\n",
      "promo_13: 2193.23\n",
      "promo_15: 2131.23\n",
      "promo_12: 2123.78\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.409653\tvalid_1's l2: 0.42408\n",
      "[100]\ttraining's l2: 0.398279\tvalid_1's l2: 0.410289\n",
      "[150]\ttraining's l2: 0.395357\tvalid_1's l2: 0.407857\n",
      "[200]\ttraining's l2: 0.393817\tvalid_1's l2: 0.407013\n",
      "[250]\ttraining's l2: 0.392734\tvalid_1's l2: 0.406522\n",
      "[300]\ttraining's l2: 0.391829\tvalid_1's l2: 0.406158\n",
      "[350]\ttraining's l2: 0.391019\tvalid_1's l2: 0.405963\n",
      "[400]\ttraining's l2: 0.390315\tvalid_1's l2: 0.405788\n",
      "[450]\ttraining's l2: 0.389698\tvalid_1's l2: 0.405628\n",
      "[500]\ttraining's l2: 0.389118\tvalid_1's l2: 0.405574\n",
      "[550]\ttraining's l2: 0.388531\tvalid_1's l2: 0.4055\n",
      "[600]\ttraining's l2: 0.388037\tvalid_1's l2: 0.405475\n",
      "[650]\ttraining's l2: 0.387519\tvalid_1's l2: 0.405453\n",
      "[700]\ttraining's l2: 0.387018\tvalid_1's l2: 0.405434\n",
      "[750]\ttraining's l2: 0.386571\tvalid_1's l2: 0.405328\n",
      "[800]\ttraining's l2: 0.386125\tvalid_1's l2: 0.4053\n",
      "[850]\ttraining's l2: 0.385686\tvalid_1's l2: 0.405277\n",
      "Early stopping, best iteration is:\n",
      "[839]\ttraining's l2: 0.385774\tvalid_1's l2: 0.405261\n",
      "mean_14_2017: 2386896.02\n",
      "mean_7_2017: 836091.12\n",
      "mean_3_2017: 374706.28\n",
      "promo_5: 91722.63\n",
      "promo_14_2017: 45313.16\n",
      "promo_3: 15732.84\n",
      "promo_6: 12353.01\n",
      "promo_7: 10550.52\n",
      "promo_2: 5638.10\n",
      "promo_4: 5392.82\n",
      "promo_1: 4730.41\n",
      "promo_0: 4705.81\n",
      "promo_9: 3979.45\n",
      "promo_8: 3446.66\n",
      "promo_14: 3163.01\n",
      "promo_12: 2382.70\n",
      "promo_11: 2199.53\n",
      "promo_13: 1879.77\n",
      "promo_10: 1861.10\n",
      "promo_15: 1508.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.399249\tvalid_1's l2: 0.499368\n",
      "[100]\ttraining's l2: 0.387491\tvalid_1's l2: 0.484385\n",
      "[150]\ttraining's l2: 0.384487\tvalid_1's l2: 0.483271\n",
      "[200]\ttraining's l2: 0.382909\tvalid_1's l2: 0.482962\n",
      "[250]\ttraining's l2: 0.381732\tvalid_1's l2: 0.482566\n",
      "[300]\ttraining's l2: 0.380894\tvalid_1's l2: 0.482571\n",
      "Early stopping, best iteration is:\n",
      "[265]\ttraining's l2: 0.381465\tvalid_1's l2: 0.482494\n",
      "mean_14_2017: 2176120.92\n",
      "mean_7_2017: 788873.90\n",
      "mean_3_2017: 309822.71\n",
      "promo_6: 154213.49\n",
      "promo_14_2017: 50427.60\n",
      "promo_3: 14230.01\n",
      "promo_7: 10208.19\n",
      "promo_13: 8896.97\n",
      "promo_5: 7975.26\n",
      "promo_0: 4785.81\n",
      "promo_1: 4559.44\n",
      "promo_4: 4185.97\n",
      "promo_9: 3828.04\n",
      "promo_2: 3637.22\n",
      "promo_14: 3187.51\n",
      "promo_8: 2329.80\n",
      "promo_11: 1460.21\n",
      "promo_15: 1382.96\n",
      "promo_12: 1252.57\n",
      "promo_10: 1153.89\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.387984\tvalid_1's l2: 0.460446\n",
      "[100]\ttraining's l2: 0.375614\tvalid_1's l2: 0.442317\n",
      "[150]\ttraining's l2: 0.372869\tvalid_1's l2: 0.439638\n",
      "[200]\ttraining's l2: 0.371506\tvalid_1's l2: 0.438919\n",
      "[250]\ttraining's l2: 0.370348\tvalid_1's l2: 0.438294\n",
      "[300]\ttraining's l2: 0.369382\tvalid_1's l2: 0.437761\n",
      "[350]\ttraining's l2: 0.368648\tvalid_1's l2: 0.437692\n",
      "[400]\ttraining's l2: 0.367991\tvalid_1's l2: 0.437483\n",
      "[450]\ttraining's l2: 0.367415\tvalid_1's l2: 0.437284\n",
      "[500]\ttraining's l2: 0.36681\tvalid_1's l2: 0.436947\n",
      "[550]\ttraining's l2: 0.366269\tvalid_1's l2: 0.436806\n",
      "[600]\ttraining's l2: 0.365757\tvalid_1's l2: 0.436685\n",
      "[650]\ttraining's l2: 0.365266\tvalid_1's l2: 0.436622\n",
      "[700]\ttraining's l2: 0.364806\tvalid_1's l2: 0.436448\n",
      "[750]\ttraining's l2: 0.364372\tvalid_1's l2: 0.436336\n",
      "Early stopping, best iteration is:\n",
      "[742]\ttraining's l2: 0.364435\tvalid_1's l2: 0.43632\n",
      "mean_14_2017: 2384240.95\n",
      "mean_7_2017: 801670.59\n",
      "mean_3_2017: 264155.96\n",
      "promo_7: 198774.35\n",
      "promo_14_2017: 42542.97\n",
      "promo_0: 40765.34\n",
      "promo_14: 25196.80\n",
      "promo_5: 8292.56\n",
      "promo_9: 7164.19\n",
      "promo_3: 7084.16\n",
      "promo_6: 5672.33\n",
      "promo_8: 5019.97\n",
      "promo_2: 3879.19\n",
      "promo_1: 3548.74\n",
      "promo_4: 3497.21\n",
      "promo_15: 3247.70\n",
      "promo_13: 2244.96\n",
      "promo_10: 1998.42\n",
      "promo_11: 1449.73\n",
      "promo_12: 977.34\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.395037\tvalid_1's l2: 0.439454\n",
      "[100]\ttraining's l2: 0.384584\tvalid_1's l2: 0.426972\n",
      "[150]\ttraining's l2: 0.381732\tvalid_1's l2: 0.425432\n",
      "[200]\ttraining's l2: 0.380296\tvalid_1's l2: 0.425281\n",
      "[250]\ttraining's l2: 0.379213\tvalid_1's l2: 0.425006\n",
      "[300]\ttraining's l2: 0.378344\tvalid_1's l2: 0.424918\n",
      "[350]\ttraining's l2: 0.377609\tvalid_1's l2: 0.424904\n",
      "[400]\ttraining's l2: 0.376952\tvalid_1's l2: 0.424708\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's l2: 0.377141\tvalid_1's l2: 0.424637\n",
      "mean_14_2017: 2077119.49\n",
      "mean_7_2017: 656491.04\n",
      "mean_3_2017: 224372.51\n",
      "promo_8: 131914.07\n",
      "promo_14_2017: 50054.02\n",
      "promo_10: 16482.92\n",
      "promo_9: 8808.18\n",
      "promo_7: 8458.18\n",
      "promo_3: 5666.37\n",
      "promo_11: 4931.93\n",
      "promo_12: 4697.29\n",
      "promo_0: 4013.58\n",
      "promo_13: 3924.70\n",
      "promo_5: 3893.99\n",
      "promo_14: 3236.70\n",
      "promo_1: 2888.35\n",
      "promo_2: 2232.78\n",
      "promo_6: 2094.34\n",
      "promo_15: 1993.37\n",
      "promo_4: 1415.84\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.411026\tvalid_1's l2: 0.442639\n",
      "[100]\ttraining's l2: 0.397615\tvalid_1's l2: 0.429143\n",
      "[150]\ttraining's l2: 0.394128\tvalid_1's l2: 0.427653\n",
      "[200]\ttraining's l2: 0.392371\tvalid_1's l2: 0.427125\n",
      "[250]\ttraining's l2: 0.391087\tvalid_1's l2: 0.426783\n",
      "[300]\ttraining's l2: 0.39013\tvalid_1's l2: 0.426697\n",
      "[350]\ttraining's l2: 0.389285\tvalid_1's l2: 0.426582\n",
      "[400]\ttraining's l2: 0.388524\tvalid_1's l2: 0.426592\n",
      "Early stopping, best iteration is:\n",
      "[352]\ttraining's l2: 0.389257\tvalid_1's l2: 0.426548\n",
      "mean_14_2017: 2346026.51\n",
      "mean_7_2017: 761032.49\n",
      "mean_3_2017: 250063.23\n",
      "promo_9: 182626.26\n",
      "promo_14_2017: 65436.94\n",
      "promo_2: 20515.41\n",
      "promo_10: 11163.22\n",
      "promo_7: 8953.55\n",
      "promo_8: 6393.92\n",
      "promo_14: 5977.96\n",
      "promo_12: 5281.36\n",
      "promo_11: 4654.14\n",
      "promo_13: 3080.82\n",
      "promo_1: 2600.92\n",
      "promo_0: 2509.35\n",
      "promo_6: 2245.80\n",
      "promo_15: 1777.74\n",
      "promo_4: 1538.89\n",
      "promo_5: 1453.62\n",
      "promo_3: 986.94\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.446628\tvalid_1's l2: 0.449294\n",
      "[100]\ttraining's l2: 0.433935\tvalid_1's l2: 0.439457\n",
      "[150]\ttraining's l2: 0.430043\tvalid_1's l2: 0.438353\n",
      "[200]\ttraining's l2: 0.428227\tvalid_1's l2: 0.438198\n",
      "[250]\ttraining's l2: 0.426948\tvalid_1's l2: 0.43811\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's l2: 0.427787\tvalid_1's l2: 0.438017\n",
      "mean_14_2017: 2671867.29\n",
      "mean_7_2017: 869882.97\n",
      "mean_3_2017: 282448.19\n",
      "promo_10: 115969.71\n",
      "promo_14_2017: 51984.48\n",
      "promo_9: 15341.94\n",
      "promo_12: 11561.37\n",
      "promo_14: 9928.24\n",
      "promo_7: 9317.06\n",
      "promo_11: 9259.17\n",
      "promo_8: 7426.97\n",
      "promo_13: 4942.61\n",
      "promo_3: 4886.61\n",
      "promo_15: 3787.28\n",
      "promo_0: 2647.59\n",
      "promo_2: 2531.43\n",
      "promo_6: 2371.78\n",
      "promo_5: 1971.52\n",
      "promo_1: 1793.20\n",
      "promo_4: 1552.65\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.473633\tvalid_1's l2: 0.478351\n",
      "[100]\ttraining's l2: 0.459869\tvalid_1's l2: 0.46719\n",
      "[150]\ttraining's l2: 0.455735\tvalid_1's l2: 0.465738\n",
      "[200]\ttraining's l2: 0.453809\tvalid_1's l2: 0.465062\n",
      "[250]\ttraining's l2: 0.452357\tvalid_1's l2: 0.464715\n",
      "[300]\ttraining's l2: 0.451255\tvalid_1's l2: 0.464459\n",
      "[350]\ttraining's l2: 0.450352\tvalid_1's l2: 0.46411\n",
      "[400]\ttraining's l2: 0.449506\tvalid_1's l2: 0.463974\n",
      "[450]\ttraining's l2: 0.448738\tvalid_1's l2: 0.46379\n",
      "Early stopping, best iteration is:\n",
      "[445]\ttraining's l2: 0.448809\tvalid_1's l2: 0.463786\n",
      "mean_14_2017: 2861612.74\n",
      "mean_7_2017: 800780.07\n",
      "mean_3_2017: 442969.15\n",
      "promo_11: 121260.28\n",
      "promo_14_2017: 51230.04\n",
      "promo_10: 12686.76\n",
      "promo_14: 12591.65\n",
      "promo_12: 12315.98\n",
      "promo_9: 11873.38\n",
      "promo_4: 10946.24\n",
      "promo_13: 8811.57\n",
      "promo_7: 8106.75\n",
      "promo_8: 6954.74\n",
      "promo_15: 4047.03\n",
      "promo_0: 3765.31\n",
      "promo_6: 3056.30\n",
      "promo_2: 2407.47\n",
      "promo_1: 2386.24\n",
      "promo_5: 2364.50\n",
      "promo_3: 1759.24\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.439596\tvalid_1's l2: 0.442076\n",
      "[100]\ttraining's l2: 0.427552\tvalid_1's l2: 0.43146\n",
      "[150]\ttraining's l2: 0.424334\tvalid_1's l2: 0.429868\n",
      "[200]\ttraining's l2: 0.422715\tvalid_1's l2: 0.429513\n",
      "[250]\ttraining's l2: 0.421404\tvalid_1's l2: 0.429096\n",
      "[300]\ttraining's l2: 0.42036\tvalid_1's l2: 0.429036\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's l2: 0.421256\tvalid_1's l2: 0.429019\n",
      "mean_14_2017: 2371138.77\n",
      "mean_7_2017: 698072.40\n",
      "mean_3_2017: 343280.62\n",
      "promo_12: 106604.26\n",
      "promo_14_2017: 46029.13\n",
      "promo_13: 27437.76\n",
      "promo_10: 13324.76\n",
      "promo_14: 12125.67\n",
      "promo_9: 8284.28\n",
      "promo_15: 5669.04\n",
      "promo_5: 5634.23\n",
      "promo_11: 5407.64\n",
      "promo_7: 5233.36\n",
      "promo_8: 3702.25\n",
      "promo_0: 2764.41\n",
      "promo_3: 2389.24\n",
      "promo_6: 2297.64\n",
      "promo_1: 1439.98\n",
      "promo_2: 1314.36\n",
      "promo_4: 1070.48\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.424686\tvalid_1's l2: 0.424893\n",
      "[100]\ttraining's l2: 0.412486\tvalid_1's l2: 0.41538\n",
      "[150]\ttraining's l2: 0.409\tvalid_1's l2: 0.414168\n",
      "[200]\ttraining's l2: 0.407385\tvalid_1's l2: 0.413722\n",
      "[250]\ttraining's l2: 0.406155\tvalid_1's l2: 0.413439\n",
      "[300]\ttraining's l2: 0.40523\tvalid_1's l2: 0.413366\n",
      "[350]\ttraining's l2: 0.404405\tvalid_1's l2: 0.413319\n",
      "[400]\ttraining's l2: 0.403644\tvalid_1's l2: 0.413183\n",
      "Early stopping, best iteration is:\n",
      "[391]\ttraining's l2: 0.403794\tvalid_1's l2: 0.413157\n",
      "mean_14_2017: 2197954.55\n",
      "mean_7_2017: 648844.42\n",
      "mean_3_2017: 294139.48\n",
      "promo_13: 188581.98\n",
      "promo_14_2017: 49218.27\n",
      "promo_12: 15148.05\n",
      "promo_14: 14515.74\n",
      "promo_6: 14267.64\n",
      "promo_10: 10334.23\n",
      "promo_7: 6407.14\n",
      "promo_9: 6162.31\n",
      "promo_0: 5878.17\n",
      "promo_8: 4762.65\n",
      "promo_11: 4136.61\n",
      "promo_15: 4086.48\n",
      "promo_2: 2456.07\n",
      "promo_1: 1936.21\n",
      "promo_4: 1720.93\n",
      "promo_5: 1561.92\n",
      "promo_3: 1243.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.410998\tvalid_1's l2: 0.410436\n",
      "[100]\ttraining's l2: 0.397157\tvalid_1's l2: 0.398619\n",
      "[150]\ttraining's l2: 0.394315\tvalid_1's l2: 0.397761\n",
      "[200]\ttraining's l2: 0.392755\tvalid_1's l2: 0.397444\n",
      "[250]\ttraining's l2: 0.391625\tvalid_1's l2: 0.397205\n",
      "[300]\ttraining's l2: 0.390647\tvalid_1's l2: 0.397032\n",
      "[350]\ttraining's l2: 0.389848\tvalid_1's l2: 0.396838\n",
      "[400]\ttraining's l2: 0.38916\tvalid_1's l2: 0.396693\n",
      "[450]\ttraining's l2: 0.388521\tvalid_1's l2: 0.396705\n",
      "Early stopping, best iteration is:\n",
      "[418]\ttraining's l2: 0.388918\tvalid_1's l2: 0.396637\n",
      "mean_14_2017: 2326294.16\n",
      "mean_7_2017: 697294.28\n",
      "mean_3_2017: 242807.08\n",
      "promo_14: 232132.33\n",
      "promo_14_2017: 49620.78\n",
      "promo_7: 31713.90\n",
      "promo_0: 29744.91\n",
      "promo_15: 19946.17\n",
      "promo_13: 11068.67\n",
      "promo_9: 9069.83\n",
      "promo_12: 8493.43\n",
      "promo_10: 6377.01\n",
      "promo_2: 4226.62\n",
      "promo_6: 4122.19\n",
      "promo_8: 3039.53\n",
      "promo_11: 3002.61\n",
      "promo_4: 2528.08\n",
      "promo_1: 1724.67\n",
      "promo_3: 1156.68\n",
      "promo_5: 1084.95\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.419186\tvalid_1's l2: 0.432432\n",
      "[100]\ttraining's l2: 0.408497\tvalid_1's l2: 0.423824\n",
      "[150]\ttraining's l2: 0.405564\tvalid_1's l2: 0.422495\n",
      "[200]\ttraining's l2: 0.403982\tvalid_1's l2: 0.422027\n",
      "[250]\ttraining's l2: 0.402776\tvalid_1's l2: 0.421674\n",
      "[300]\ttraining's l2: 0.401741\tvalid_1's l2: 0.421631\n",
      "[350]\ttraining's l2: 0.400889\tvalid_1's l2: 0.421475\n",
      "[400]\ttraining's l2: 0.400046\tvalid_1's l2: 0.421381\n",
      "[450]\ttraining's l2: 0.39941\tvalid_1's l2: 0.421229\n",
      "[500]\ttraining's l2: 0.398826\tvalid_1's l2: 0.421114\n",
      "Early stopping, best iteration is:\n",
      "[484]\ttraining's l2: 0.398993\tvalid_1's l2: 0.421093\n",
      "mean_14_2017: 2022529.92\n",
      "mean_7_2017: 601740.87\n",
      "mean_3_2017: 213387.36\n",
      "promo_15: 184125.89\n",
      "promo_14_2017: 51237.69\n",
      "promo_14: 10084.43\n",
      "promo_7: 5849.95\n",
      "promo_9: 4852.21\n",
      "promo_10: 4486.45\n",
      "promo_0: 4422.50\n",
      "promo_13: 3956.91\n",
      "promo_12: 3710.38\n",
      "promo_8: 3415.79\n",
      "promo_11: 2732.34\n",
      "promo_1: 2314.99\n",
      "promo_2: 2312.65\n",
      "promo_3: 2167.87\n",
      "promo_6: 2003.93\n",
      "promo_5: 1334.89\n",
      "promo_4: 1291.08\n"
     ]
    }
   ],
   "source": [
    "MAX_ROUNDS = 1000\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 4) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=50\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 275.7862813287469\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    np.expm1(y_val), np.expm1(np.array(val_pred)).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.2071499 , 0.48488404, 0.73822611, ..., 0.23754703, 2.05418453,\n",
       "        0.03076805]),\n",
       " array([0.20248389, 0.50000804, 0.68828877, ..., 0.2134666 , 1.93274017,\n",
       "        0.04175205]),\n",
       " array([0.23902936, 0.62783665, 0.75723977, ..., 0.23085787, 1.77148465,\n",
       "        0.0464756 ]),\n",
       " array([0.30655785, 0.75207269, 0.99879814, ..., 0.32088842, 2.08985238,\n",
       "        0.07291537]),\n",
       " array([0.27424474, 0.69718693, 1.04320573, ..., 0.36169774, 1.96112359,\n",
       "        0.07797592]),\n",
       " array([0.22258805, 0.59696122, 0.81102486, ..., 0.26593051, 1.76900857,\n",
       "        0.04240829]),\n",
       " array([0.21105402, 0.57495346, 0.74622924, ..., 0.24370768, 0.07047951,\n",
       "        0.09334097]),\n",
       " array([0.19939098, 0.58468629, 0.73820218, ..., 0.22899961, 1.87168311,\n",
       "        0.09038593]),\n",
       " array([0.21100979, 0.57101541, 0.68382262, ..., 0.21276259, 1.69936576,\n",
       "        0.08189474]),\n",
       " array([0.2239681 , 0.66356936, 0.73385747, ..., 0.23369309, 1.77138193,\n",
       "        0.06100372]),\n",
       " array([0.31060667, 0.78366861, 0.98043279, ..., 0.33069278, 0.86459471,\n",
       "        0.08423032]),\n",
       " array([0.29365485, 0.72376923, 1.04258148, ..., 0.33468651, 2.21205449,\n",
       "        0.08346158]),\n",
       " array([0.24072325, 0.62316947, 0.83082921, ..., 0.25469633, 0.8888251 ,\n",
       "        0.89586761]),\n",
       " array([0.22315875, 0.58637649, 0.76417512, ..., 0.2380525 , 1.70693584,\n",
       "        0.04819869]),\n",
       " array([0.20573608, 0.58565907, 0.73749913, ..., 0.21582245, 1.89165606,\n",
       "        0.07015428]),\n",
       " array([0.20077304, 0.59710114, 0.68621505, ..., 0.19911074, 1.92235309,\n",
       "        0.07753619])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497040</td>\n",
       "      <td>0.273266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497041</td>\n",
       "      <td>0.225388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497042</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497043</td>\n",
       "      <td>0.648250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497044</td>\n",
       "      <td>1.352113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497045</td>\n",
       "      <td>3.222305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497046</td>\n",
       "      <td>7.469437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105576</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497047</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105577</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497048</td>\n",
       "      <td>0.294655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105693</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497049</td>\n",
       "      <td>0.319934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105737</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497050</td>\n",
       "      <td>0.763024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105857</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497051</td>\n",
       "      <td>3.247849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106716</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497052</td>\n",
       "      <td>1.781587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108079</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497053</td>\n",
       "      <td>0.346823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108634</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497054</td>\n",
       "      <td>0.033705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108696</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497055</td>\n",
       "      <td>1.357327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108698</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497056</td>\n",
       "      <td>0.585320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108701</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497057</td>\n",
       "      <td>1.804330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108786</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497058</td>\n",
       "      <td>1.744146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108797</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497059</td>\n",
       "      <td>2.840066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108831</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108833</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108862</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497062</td>\n",
       "      <td>0.704088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108952</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497063</td>\n",
       "      <td>1.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111223</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497064</td>\n",
       "      <td>3.262282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111397</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497065</td>\n",
       "      <td>0.431402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112830</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497066</td>\n",
       "      <td>1.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114778</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497067</td>\n",
       "      <td>1.617434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114790</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497068</td>\n",
       "      <td>2.928812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114799</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497069</td>\n",
       "      <td>0.731032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th>2127921</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127992</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867475</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128628</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128799</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867477</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129334</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867478</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129350</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129387</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129515</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867481</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129616</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867482</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129678</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129786</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867484</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129790</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867485</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129892</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129994</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867487</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130131</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130219</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867489</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130265</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867490</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130352</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867491</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130474</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867492</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130521</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130526</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867494</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130553</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131010</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131572</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867497</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131699</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867498</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132163</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132318</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132945</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132957</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867502</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134244</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867503</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3370464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  unit_sales\n",
       "store_nbr item_nbr date                             \n",
       "1         96995    2017-08-16  125497040    0.273266\n",
       "          99197    2017-08-16  125497041    0.225388\n",
       "          103501   2017-08-16  125497042    0.000000\n",
       "          103520   2017-08-16  125497043    0.648250\n",
       "          103665   2017-08-16  125497044    1.352113\n",
       "          105574   2017-08-16  125497045    3.222305\n",
       "          105575   2017-08-16  125497046    7.469437\n",
       "          105576   2017-08-16  125497047    0.000000\n",
       "          105577   2017-08-16  125497048    0.294655\n",
       "          105693   2017-08-16  125497049    0.319934\n",
       "          105737   2017-08-16  125497050    0.763024\n",
       "          105857   2017-08-16  125497051    3.247849\n",
       "          106716   2017-08-16  125497052    1.781587\n",
       "          108079   2017-08-16  125497053    0.346823\n",
       "          108634   2017-08-16  125497054    0.033705\n",
       "          108696   2017-08-16  125497055    1.357327\n",
       "          108698   2017-08-16  125497056    0.585320\n",
       "          108701   2017-08-16  125497057    1.804330\n",
       "          108786   2017-08-16  125497058    1.744146\n",
       "          108797   2017-08-16  125497059    2.840066\n",
       "          108831   2017-08-16  125497060    0.000000\n",
       "          108833   2017-08-16  125497061    0.000000\n",
       "          108862   2017-08-16  125497062    0.704088\n",
       "          108952   2017-08-16  125497063    1.000221\n",
       "          111223   2017-08-16  125497064    3.262282\n",
       "          111397   2017-08-16  125497065    0.431402\n",
       "          112830   2017-08-16  125497066    1.090800\n",
       "          114778   2017-08-16  125497067    1.617434\n",
       "          114790   2017-08-16  125497068    2.928812\n",
       "          114799   2017-08-16  125497069    0.731032\n",
       "...                                  ...         ...\n",
       "54        2127921  2017-08-31  128867474    0.000000\n",
       "          2127992  2017-08-31  128867475    0.000000\n",
       "          2128628  2017-08-31  128867476    0.000000\n",
       "          2128799  2017-08-31  128867477    0.000000\n",
       "          2129334  2017-08-31  128867478    0.000000\n",
       "          2129350  2017-08-31  128867479    0.000000\n",
       "          2129387  2017-08-31  128867480    0.000000\n",
       "          2129515  2017-08-31  128867481    0.000000\n",
       "          2129616  2017-08-31  128867482    0.000000\n",
       "          2129678  2017-08-31  128867483    0.000000\n",
       "          2129786  2017-08-31  128867484    0.000000\n",
       "          2129790  2017-08-31  128867485    0.000000\n",
       "          2129892  2017-08-31  128867486    0.000000\n",
       "          2129994  2017-08-31  128867487    0.000000\n",
       "          2130131  2017-08-31  128867488    0.000000\n",
       "          2130219  2017-08-31  128867489    0.000000\n",
       "          2130265  2017-08-31  128867490    0.000000\n",
       "          2130352  2017-08-31  128867491    0.000000\n",
       "          2130474  2017-08-31  128867492    0.000000\n",
       "          2130521  2017-08-31  128867493    0.000000\n",
       "          2130526  2017-08-31  128867494    0.000000\n",
       "          2130553  2017-08-31  128867495    0.000000\n",
       "          2131010  2017-08-31  128867496    0.000000\n",
       "          2131572  2017-08-31  128867497    0.000000\n",
       "          2131699  2017-08-31  128867498    0.000000\n",
       "          2132163  2017-08-31  128867499    0.000000\n",
       "          2132318  2017-08-31  128867500    0.000000\n",
       "          2132945  2017-08-31  128867501    0.000000\n",
       "          2132957  2017-08-31  128867502    0.000000\n",
       "          2134244  2017-08-31  128867503    0.000000\n",
       "\n",
       "[3370464 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on the work in this file: https://www.kaggle.com/vrtjso/lgbm-one-step-ahead\n",
    "\n",
    "This was apparently in the top 10% at one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Training and predicting models...\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryanfeeney/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.30191\tvalid_1's l2: 0.29409\n",
      "[200]\ttraining's l2: 0.298363\tvalid_1's l2: 0.292741\n",
      "[300]\ttraining's l2: 0.295918\tvalid_1's l2: 0.292337\n",
      "[400]\ttraining's l2: 0.293791\tvalid_1's l2: 0.2921\n",
      "[500]\ttraining's l2: 0.29199\tvalid_1's l2: 0.29195\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.29199\tvalid_1's l2: 0.29195\n",
      "mean_7_2017: 1882639.38\n",
      "mean_14_2017: 1229821.77\n",
      "promo_0: 104143.51\n",
      "day_1_2017: 89857.46\n",
      "mean_20_dow0_2017: 84245.48\n",
      "mean_3_2017: 76646.29\n",
      "mean_30_2017: 76583.57\n",
      "mean_4_dow0_2017: 58919.38\n",
      "mean_60_2017: 33035.18\n",
      "promo_14_2017: 28619.72\n",
      "promo_7: 9432.45\n",
      "mean_4_dow5_2017: 7417.05\n",
      "mean_140_2017: 7406.32\n",
      "promo_60_2017: 6740.72\n",
      "mean_20_dow4_2017: 5611.55\n",
      "promo_140_2017: 5493.72\n",
      "mean_4_dow6_2017: 4633.44\n",
      "mean_4_dow2_2017: 3813.74\n",
      "mean_20_dow2_2017: 3343.78\n",
      "mean_4_dow3_2017: 2824.66\n",
      "promo_9: 2814.25\n",
      "mean_4_dow1_2017: 2707.00\n",
      "mean_20_dow3_2017: 2642.58\n",
      "mean_20_dow1_2017: 2616.99\n",
      "mean_4_dow4_2017: 2601.73\n",
      "promo_14: 2554.27\n",
      "mean_20_dow6_2017: 2328.54\n",
      "mean_20_dow5_2017: 2100.97\n",
      "promo_15: 1496.63\n",
      "promo_1: 1221.01\n",
      "promo_11: 1192.51\n",
      "promo_13: 1006.62\n",
      "promo_2: 935.67\n",
      "promo_3: 893.47\n",
      "promo_4: 889.91\n",
      "promo_10: 383.97\n",
      "promo_6: 322.66\n",
      "promo_12: 298.58\n",
      "promo_5: 285.28\n",
      "promo_8: 141.86\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.326539\tvalid_1's l2: 0.327058\n",
      "[200]\ttraining's l2: 0.322922\tvalid_1's l2: 0.325592\n",
      "[300]\ttraining's l2: 0.320274\tvalid_1's l2: 0.325165\n",
      "[400]\ttraining's l2: 0.318019\tvalid_1's l2: 0.325026\n",
      "[500]\ttraining's l2: 0.316052\tvalid_1's l2: 0.324929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.316052\tvalid_1's l2: 0.324929\n",
      "mean_14_2017: 1448209.85\n",
      "mean_7_2017: 1034578.11\n",
      "mean_30_2017: 246570.90\n",
      "mean_20_dow1_2017: 76170.97\n",
      "mean_60_2017: 75746.98\n",
      "promo_1: 63650.65\n",
      "day_1_2017: 39350.00\n",
      "promo_14_2017: 23420.47\n",
      "mean_3_2017: 21665.46\n",
      "mean_4_dow1_2017: 21049.86\n",
      "mean_20_dow2_2017: 6729.53\n",
      "promo_60_2017: 6611.24\n",
      "mean_20_dow4_2017: 5631.01\n",
      "mean_140_2017: 5613.73\n",
      "mean_4_dow2_2017: 4690.02\n",
      "promo_0: 4369.95\n",
      "promo_140_2017: 4120.99\n",
      "mean_4_dow6_2017: 4081.87\n",
      "mean_4_dow0_2017: 3375.03\n",
      "mean_4_dow4_2017: 3221.22\n",
      "promo_3: 3191.82\n",
      "mean_4_dow5_2017: 2852.68\n",
      "mean_4_dow3_2017: 2762.14\n",
      "mean_20_dow0_2017: 2746.06\n",
      "mean_20_dow5_2017: 2731.84\n",
      "promo_4: 2695.93\n",
      "mean_20_dow6_2017: 2610.67\n",
      "mean_20_dow3_2017: 1957.73\n",
      "promo_2: 1709.55\n",
      "promo_5: 1504.46\n",
      "promo_7: 871.80\n",
      "promo_6: 664.72\n",
      "promo_14: 485.90\n",
      "promo_15: 428.90\n",
      "promo_13: 428.87\n",
      "promo_11: 412.48\n",
      "promo_9: 350.18\n",
      "promo_10: 258.84\n",
      "promo_8: 227.38\n",
      "promo_12: 202.90\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.329214\tvalid_1's l2: 0.341052\n",
      "[200]\ttraining's l2: 0.32491\tvalid_1's l2: 0.339451\n",
      "[300]\ttraining's l2: 0.322012\tvalid_1's l2: 0.33904\n",
      "[400]\ttraining's l2: 0.319586\tvalid_1's l2: 0.338643\n",
      "[500]\ttraining's l2: 0.317454\tvalid_1's l2: 0.338549\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.317454\tvalid_1's l2: 0.338549\n",
      "mean_14_2017: 1844336.16\n",
      "mean_7_2017: 870615.51\n",
      "mean_20_dow2_2017: 250002.09\n",
      "mean_30_2017: 233037.29\n",
      "mean_4_dow2_2017: 193065.36\n",
      "promo_2: 99012.98\n",
      "mean_60_2017: 27003.87\n",
      "promo_14_2017: 24648.98\n",
      "mean_3_2017: 21618.39\n",
      "day_1_2017: 11455.88\n",
      "promo_140_2017: 10046.38\n",
      "promo_60_2017: 9571.91\n",
      "mean_20_dow4_2017: 7756.05\n",
      "promo_9: 6415.80\n",
      "promo_3: 6290.96\n",
      "mean_4_dow0_2017: 5199.39\n",
      "mean_20_dow1_2017: 4937.92\n",
      "mean_4_dow1_2017: 4747.39\n",
      "mean_4_dow3_2017: 4469.99\n",
      "mean_20_dow5_2017: 4268.66\n",
      "promo_0: 4053.77\n",
      "promo_5: 3801.42\n",
      "promo_4: 3494.51\n",
      "promo_7: 3253.06\n",
      "mean_4_dow6_2017: 3084.02\n",
      "mean_4_dow4_2017: 2872.92\n",
      "mean_20_dow0_2017: 2843.14\n",
      "mean_20_dow3_2017: 2753.28\n",
      "mean_4_dow5_2017: 2698.22\n",
      "mean_20_dow6_2017: 2683.80\n",
      "mean_140_2017: 1969.18\n",
      "promo_11: 1916.54\n",
      "promo_1: 1565.68\n",
      "promo_15: 1453.37\n",
      "promo_14: 1262.02\n",
      "promo_10: 1052.03\n",
      "promo_6: 913.07\n",
      "promo_13: 468.25\n",
      "promo_12: 445.72\n",
      "promo_8: 196.02\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.352578\tvalid_1's l2: 0.35456\n",
      "[200]\ttraining's l2: 0.347807\tvalid_1's l2: 0.352866\n",
      "[300]\ttraining's l2: 0.344704\tvalid_1's l2: 0.35252\n",
      "[400]\ttraining's l2: 0.342312\tvalid_1's l2: 0.352494\n",
      "Early stopping, best iteration is:\n",
      "[356]\ttraining's l2: 0.343334\tvalid_1's l2: 0.352445\n",
      "mean_14_2017: 2193691.18\n",
      "mean_7_2017: 618595.48\n",
      "mean_30_2017: 551732.29\n",
      "mean_4_dow3_2017: 297032.53\n",
      "mean_20_dow3_2017: 151857.36\n",
      "mean_60_2017: 143905.27\n",
      "promo_3: 74878.51\n",
      "mean_3_2017: 41209.99\n",
      "mean_4_dow4_2017: 24200.55\n",
      "promo_14_2017: 20086.54\n",
      "day_1_2017: 7849.99\n",
      "promo_60_2017: 7545.86\n",
      "mean_140_2017: 6691.03\n",
      "promo_140_2017: 6578.59\n",
      "promo_5: 5016.34\n",
      "promo_4: 4576.47\n",
      "mean_4_dow2_2017: 4269.24\n",
      "mean_20_dow5_2017: 4133.29\n",
      "mean_20_dow0_2017: 4010.61\n",
      "promo_2: 3671.09\n",
      "promo_7: 3525.20\n",
      "mean_20_dow4_2017: 3435.74\n",
      "mean_20_dow6_2017: 3370.36\n",
      "mean_4_dow0_2017: 3253.79\n",
      "promo_0: 2755.67\n",
      "mean_20_dow2_2017: 2670.18\n",
      "promo_6: 2655.50\n",
      "mean_4_dow6_2017: 2643.84\n",
      "mean_4_dow1_2017: 2137.30\n",
      "promo_1: 1963.74\n",
      "mean_4_dow5_2017: 1929.19\n",
      "mean_20_dow1_2017: 1853.53\n",
      "promo_14: 1328.71\n",
      "promo_9: 1137.47\n",
      "promo_15: 626.27\n",
      "promo_8: 611.44\n",
      "promo_13: 493.24\n",
      "promo_10: 486.88\n",
      "promo_12: 260.55\n",
      "promo_11: 205.27\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.363248\tvalid_1's l2: 0.357485\n",
      "[200]\ttraining's l2: 0.357852\tvalid_1's l2: 0.355829\n",
      "[300]\ttraining's l2: 0.354392\tvalid_1's l2: 0.355065\n",
      "[400]\ttraining's l2: 0.351438\tvalid_1's l2: 0.354843\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's l2: 0.350333\tvalid_1's l2: 0.354789\n",
      "mean_14_2017: 1348136.20\n",
      "mean_4_dow4_2017: 1135127.96\n",
      "mean_7_2017: 628767.41\n",
      "mean_30_2017: 544794.74\n",
      "mean_3_2017: 291791.52\n",
      "mean_20_dow4_2017: 288550.61\n",
      "promo_4: 74505.10\n",
      "mean_60_2017: 44391.35\n",
      "promo_14_2017: 19804.80\n",
      "mean_4_dow3_2017: 18485.98\n",
      "promo_60_2017: 7875.35\n",
      "promo_3: 7643.88\n",
      "promo_5: 7253.32\n",
      "promo_140_2017: 7073.61\n",
      "promo_7: 6861.10\n",
      "day_1_2017: 5987.75\n",
      "mean_20_dow2_2017: 4998.05\n",
      "mean_20_dow1_2017: 4892.12\n",
      "mean_20_dow0_2017: 4735.39\n",
      "promo_6: 4409.29\n",
      "mean_140_2017: 4018.54\n",
      "promo_0: 3825.66\n",
      "promo_2: 3517.27\n",
      "mean_20_dow3_2017: 3413.62\n",
      "mean_4_dow0_2017: 3339.72\n",
      "mean_4_dow5_2017: 2941.74\n",
      "mean_20_dow6_2017: 2861.50\n",
      "mean_4_dow6_2017: 2847.72\n",
      "mean_4_dow2_2017: 2616.75\n",
      "promo_1: 2437.49\n",
      "mean_20_dow5_2017: 2370.19\n",
      "mean_4_dow1_2017: 2346.16\n",
      "promo_11: 2072.60\n",
      "promo_14: 1764.28\n",
      "promo_9: 1456.78\n",
      "promo_15: 918.80\n",
      "promo_10: 786.73\n",
      "promo_13: 699.22\n",
      "promo_8: 599.66\n",
      "promo_12: 548.07\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.356167\tvalid_1's l2: 0.361072\n",
      "[200]\ttraining's l2: 0.35175\tvalid_1's l2: 0.359722\n",
      "[300]\ttraining's l2: 0.348717\tvalid_1's l2: 0.35919\n",
      "[400]\ttraining's l2: 0.346237\tvalid_1's l2: 0.359004\n",
      "[500]\ttraining's l2: 0.343935\tvalid_1's l2: 0.358917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.343935\tvalid_1's l2: 0.358917\n",
      "mean_14_2017: 1303577.54\n",
      "mean_30_2017: 1131578.58\n",
      "mean_7_2017: 302367.52\n",
      "mean_3_2017: 250064.05\n",
      "mean_60_2017: 199236.34\n",
      "mean_20_dow5_2017: 83861.17\n",
      "promo_5: 80457.60\n",
      "mean_4_dow5_2017: 61891.13\n",
      "promo_14_2017: 19933.21\n",
      "promo_3: 11460.40\n",
      "mean_4_dow6_2017: 9766.39\n",
      "day_1_2017: 8574.87\n",
      "promo_60_2017: 8078.56\n",
      "promo_7: 7718.19\n",
      "mean_140_2017: 6770.88\n",
      "mean_20_dow6_2017: 6236.08\n",
      "promo_6: 5804.02\n",
      "promo_140_2017: 4630.49\n",
      "mean_4_dow0_2017: 4040.13\n",
      "mean_20_dow0_2017: 4017.73\n",
      "mean_20_dow3_2017: 3928.91\n",
      "mean_20_dow2_2017: 3831.69\n",
      "mean_4_dow2_2017: 3615.73\n",
      "mean_4_dow1_2017: 3322.85\n",
      "mean_4_dow4_2017: 3293.49\n",
      "mean_4_dow3_2017: 3278.24\n",
      "mean_20_dow4_2017: 3100.54\n",
      "mean_20_dow1_2017: 2860.49\n",
      "promo_0: 2825.76\n",
      "promo_4: 2754.35\n",
      "promo_2: 2413.23\n",
      "promo_9: 1986.25\n",
      "promo_14: 1224.92\n",
      "promo_1: 1187.60\n",
      "promo_13: 1029.54\n",
      "promo_12: 1027.71\n",
      "promo_8: 903.58\n",
      "promo_11: 683.05\n",
      "promo_10: 585.70\n",
      "promo_15: 583.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346219\tvalid_1's l2: 0.421254\n",
      "[200]\ttraining's l2: 0.341874\tvalid_1's l2: 0.420923\n",
      "[300]\ttraining's l2: 0.339035\tvalid_1's l2: 0.420617\n",
      "[400]\ttraining's l2: 0.336652\tvalid_1's l2: 0.420437\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's l2: 0.336799\tvalid_1's l2: 0.420378\n",
      "mean_14_2017: 1274004.42\n",
      "mean_30_2017: 842088.63\n",
      "mean_7_2017: 445757.89\n",
      "mean_20_dow6_2017: 152802.16\n",
      "mean_3_2017: 145241.24\n",
      "promo_6: 128192.88\n",
      "mean_4_dow6_2017: 127503.94\n",
      "mean_60_2017: 123326.90\n",
      "promo_14_2017: 21944.55\n",
      "day_1_2017: 13872.06\n",
      "promo_3: 11205.46\n",
      "promo_7: 9013.03\n",
      "mean_4_dow5_2017: 8533.91\n",
      "mean_20_dow5_2017: 8280.78\n",
      "promo_60_2017: 8112.57\n",
      "promo_140_2017: 6018.04\n",
      "mean_20_dow1_2017: 4884.13\n",
      "promo_5: 4487.41\n",
      "mean_140_2017: 4382.31\n",
      "promo_13: 3877.01\n",
      "mean_4_dow0_2017: 3650.61\n",
      "mean_20_dow0_2017: 3639.82\n",
      "mean_20_dow3_2017: 3507.37\n",
      "mean_4_dow1_2017: 3355.21\n",
      "mean_20_dow4_2017: 2943.12\n",
      "promo_4: 2784.87\n",
      "promo_0: 2663.62\n",
      "mean_20_dow2_2017: 2644.47\n",
      "mean_4_dow2_2017: 2643.06\n",
      "mean_4_dow3_2017: 2399.89\n",
      "promo_9: 2205.45\n",
      "promo_14: 1995.35\n",
      "mean_4_dow4_2017: 1944.32\n",
      "promo_2: 1500.32\n",
      "promo_1: 1481.22\n",
      "promo_15: 1358.07\n",
      "promo_11: 887.39\n",
      "promo_12: 561.75\n",
      "promo_8: 539.82\n",
      "promo_10: 490.10\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.332499\tvalid_1's l2: 0.3901\n",
      "[200]\ttraining's l2: 0.328261\tvalid_1's l2: 0.388965\n",
      "[300]\ttraining's l2: 0.325429\tvalid_1's l2: 0.388761\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttraining's l2: 0.326174\tvalid_1's l2: 0.388646\n",
      "mean_14_2017: 1106650.36\n",
      "mean_30_2017: 1087192.69\n",
      "mean_7_2017: 596975.54\n",
      "mean_20_dow0_2017: 196265.21\n",
      "promo_7: 180889.57\n",
      "mean_60_2017: 149108.93\n",
      "mean_4_dow0_2017: 59661.14\n",
      "promo_0: 24773.90\n",
      "mean_3_2017: 19984.01\n",
      "day_1_2017: 19142.77\n",
      "promo_60_2017: 12051.84\n",
      "promo_14_2017: 11689.01\n",
      "promo_14: 10283.65\n",
      "promo_140_2017: 8424.10\n",
      "mean_140_2017: 6395.53\n",
      "mean_20_dow2_2017: 5494.71\n",
      "promo_3: 5488.24\n",
      "mean_20_dow4_2017: 5169.59\n",
      "promo_5: 3575.89\n",
      "promo_6: 3298.34\n",
      "promo_9: 2789.02\n",
      "mean_20_dow1_2017: 2684.71\n",
      "mean_4_dow6_2017: 2653.59\n",
      "mean_4_dow5_2017: 2642.93\n",
      "mean_20_dow3_2017: 2642.15\n",
      "mean_4_dow2_2017: 2252.18\n",
      "promo_15: 2080.63\n",
      "mean_20_dow6_2017: 2018.39\n",
      "mean_4_dow1_2017: 1985.10\n",
      "mean_20_dow5_2017: 1841.53\n",
      "promo_4: 1812.55\n",
      "mean_4_dow3_2017: 1717.08\n",
      "mean_4_dow4_2017: 1650.89\n",
      "promo_2: 1599.33\n",
      "promo_10: 1283.18\n",
      "promo_13: 1050.84\n",
      "promo_8: 818.48\n",
      "promo_11: 786.91\n",
      "promo_1: 669.08\n",
      "promo_12: 425.68\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.342053\tvalid_1's l2: 0.380461\n",
      "[200]\ttraining's l2: 0.337877\tvalid_1's l2: 0.379403\n",
      "[300]\ttraining's l2: 0.335103\tvalid_1's l2: 0.379123\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's l2: 0.336014\tvalid_1's l2: 0.379038\n",
      "mean_30_2017: 1092411.90\n",
      "mean_14_2017: 753255.06\n",
      "mean_7_2017: 476090.43\n",
      "mean_60_2017: 246076.66\n",
      "mean_20_dow1_2017: 107659.48\n",
      "promo_8: 103259.44\n",
      "mean_4_dow1_2017: 19937.01\n",
      "promo_10: 18003.13\n",
      "promo_14_2017: 16924.71\n",
      "day_1_2017: 16452.21\n",
      "promo_60_2017: 11142.17\n",
      "mean_3_2017: 10494.91\n",
      "mean_20_dow2_2017: 8645.64\n",
      "promo_7: 8064.94\n",
      "mean_20_dow4_2017: 5020.41\n",
      "promo_140_2017: 4773.47\n",
      "promo_11: 4275.66\n",
      "promo_12: 3589.55\n",
      "mean_20_dow0_2017: 3160.99\n",
      "promo_13: 2958.70\n",
      "mean_140_2017: 2897.43\n",
      "mean_4_dow0_2017: 2787.90\n",
      "promo_9: 2689.16\n",
      "mean_4_dow2_2017: 2528.49\n",
      "mean_4_dow6_2017: 2503.01\n",
      "promo_0: 2205.36\n",
      "mean_20_dow6_2017: 2051.10\n",
      "mean_4_dow4_2017: 1838.41\n",
      "mean_4_dow5_2017: 1770.93\n",
      "mean_20_dow5_2017: 1756.49\n",
      "promo_3: 1621.72\n",
      "mean_4_dow3_2017: 1592.52\n",
      "promo_14: 1571.90\n",
      "mean_20_dow3_2017: 1467.83\n",
      "promo_6: 1083.55\n",
      "promo_4: 1073.11\n",
      "promo_2: 681.96\n",
      "promo_5: 494.89\n",
      "promo_15: 463.49\n",
      "promo_1: 419.76\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346249\tvalid_1's l2: 0.369277\n",
      "[200]\ttraining's l2: 0.341552\tvalid_1's l2: 0.368489\n",
      "[300]\ttraining's l2: 0.338254\tvalid_1's l2: 0.367977\n",
      "[400]\ttraining's l2: 0.335535\tvalid_1's l2: 0.367602\n",
      "Early stopping, best iteration is:\n",
      "[426]\ttraining's l2: 0.334919\tvalid_1's l2: 0.367499\n",
      "mean_30_2017: 1109135.07\n",
      "mean_14_2017: 898740.33\n",
      "mean_7_2017: 455556.40\n",
      "mean_20_dow2_2017: 370696.90\n",
      "mean_4_dow2_2017: 305486.76\n",
      "promo_9: 126542.69\n",
      "mean_60_2017: 69547.55\n",
      "promo_14_2017: 22015.36\n",
      "promo_10: 14619.81\n",
      "promo_140_2017: 12875.57\n",
      "promo_2: 11529.68\n",
      "promo_60_2017: 10979.04\n",
      "mean_3_2017: 10953.05\n",
      "promo_7: 9486.41\n",
      "day_1_2017: 7823.74\n",
      "mean_20_dow4_2017: 7736.48\n",
      "promo_8: 6789.34\n",
      "mean_20_dow1_2017: 6282.70\n",
      "mean_4_dow1_2017: 5402.74\n",
      "promo_14: 5226.53\n",
      "mean_20_dow5_2017: 4596.57\n",
      "mean_4_dow0_2017: 4021.87\n",
      "mean_4_dow3_2017: 3921.97\n",
      "promo_12: 3788.84\n",
      "mean_20_dow0_2017: 3780.37\n",
      "promo_11: 3143.47\n",
      "mean_20_dow3_2017: 3112.16\n",
      "mean_4_dow6_2017: 3027.64\n",
      "mean_140_2017: 3010.47\n",
      "mean_4_dow4_2017: 2729.70\n",
      "promo_13: 2729.64\n",
      "mean_20_dow6_2017: 2720.09\n",
      "mean_4_dow5_2017: 2430.24\n",
      "promo_6: 1390.16\n",
      "promo_4: 1204.69\n",
      "promo_0: 1123.38\n",
      "promo_1: 934.92\n",
      "promo_15: 901.80\n",
      "promo_3: 468.56\n",
      "promo_5: 299.24\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.374554\tvalid_1's l2: 0.37475\n",
      "[200]\ttraining's l2: 0.369094\tvalid_1's l2: 0.373093\n",
      "[300]\ttraining's l2: 0.3657\tvalid_1's l2: 0.372889\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's l2: 0.367225\tvalid_1's l2: 0.372871\n",
      "mean_30_2017: 1557331.99\n",
      "mean_14_2017: 731428.08\n",
      "mean_7_2017: 608635.02\n",
      "mean_60_2017: 369698.24\n",
      "mean_4_dow3_2017: 278647.67\n",
      "mean_20_dow3_2017: 194588.29\n",
      "promo_10: 106197.71\n",
      "mean_3_2017: 16427.10\n",
      "promo_14_2017: 15868.17\n",
      "mean_4_dow4_2017: 14618.03\n",
      "mean_4_dow2_2017: 10881.47\n",
      "promo_60_2017: 10271.67\n",
      "mean_140_2017: 7499.64\n",
      "promo_140_2017: 7024.09\n",
      "promo_14: 6975.73\n",
      "promo_9: 5837.04\n",
      "promo_7: 5810.41\n",
      "day_1_2017: 5059.51\n",
      "promo_12: 4976.80\n",
      "promo_11: 4931.67\n",
      "mean_20_dow0_2017: 4411.60\n",
      "mean_20_dow5_2017: 4364.08\n",
      "promo_13: 3983.01\n",
      "mean_20_dow2_2017: 3850.59\n",
      "mean_20_dow4_2017: 3281.31\n",
      "mean_4_dow0_2017: 3146.40\n",
      "mean_20_dow6_2017: 3026.25\n",
      "promo_8: 3004.82\n",
      "mean_20_dow1_2017: 2430.94\n",
      "mean_4_dow1_2017: 2023.36\n",
      "promo_3: 2009.26\n",
      "mean_4_dow6_2017: 1653.60\n",
      "mean_4_dow5_2017: 1564.46\n",
      "promo_6: 1205.97\n",
      "promo_0: 1141.93\n",
      "promo_15: 998.07\n",
      "promo_4: 774.89\n",
      "promo_2: 521.36\n",
      "promo_5: 477.40\n",
      "promo_1: 279.25\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.384726\tvalid_1's l2: 0.386245\n",
      "[200]\ttraining's l2: 0.379048\tvalid_1's l2: 0.384677\n",
      "[300]\ttraining's l2: 0.375455\tvalid_1's l2: 0.384401\n",
      "[400]\ttraining's l2: 0.372435\tvalid_1's l2: 0.384356\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's l2: 0.372056\tvalid_1's l2: 0.384323\n",
      "mean_4_dow4_2017: 1370672.62\n",
      "mean_30_2017: 1347811.60\n",
      "mean_14_2017: 519317.28\n",
      "mean_20_dow4_2017: 286536.47\n",
      "mean_60_2017: 203990.63\n",
      "mean_7_2017: 183990.03\n",
      "mean_3_2017: 105880.57\n",
      "promo_11: 94981.40\n",
      "mean_4_dow3_2017: 17981.50\n",
      "promo_14_2017: 15931.04\n",
      "promo_12: 13676.55\n",
      "promo_14: 11691.97\n",
      "promo_10: 9251.36\n",
      "promo_60_2017: 9175.17\n",
      "promo_140_2017: 8938.17\n",
      "mean_140_2017: 7198.99\n",
      "promo_13: 6796.57\n",
      "promo_9: 6049.79\n",
      "promo_4: 5491.69\n",
      "mean_20_dow0_2017: 5409.09\n",
      "day_1_2017: 4989.87\n",
      "promo_7: 4847.85\n",
      "mean_20_dow3_2017: 4446.33\n",
      "mean_20_dow1_2017: 4233.39\n",
      "mean_20_dow2_2017: 4034.11\n",
      "mean_20_dow6_2017: 3841.08\n",
      "mean_4_dow0_2017: 3452.07\n",
      "promo_8: 3367.92\n",
      "mean_20_dow5_2017: 3116.02\n",
      "mean_4_dow5_2017: 2736.23\n",
      "mean_4_dow6_2017: 2651.79\n",
      "mean_4_dow1_2017: 2500.66\n",
      "mean_4_dow2_2017: 2434.76\n",
      "promo_0: 1786.93\n",
      "promo_15: 1146.94\n",
      "promo_6: 1010.45\n",
      "promo_2: 829.46\n",
      "promo_3: 708.15\n",
      "promo_1: 546.59\n",
      "promo_5: 373.83\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.370343\tvalid_1's l2: 0.377148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's l2: 0.365615\tvalid_1's l2: 0.376333\n",
      "[300]\ttraining's l2: 0.362327\tvalid_1's l2: 0.376258\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's l2: 0.361236\tvalid_1's l2: 0.37609\n",
      "mean_30_2017: 1601076.04\n",
      "mean_14_2017: 588977.50\n",
      "mean_60_2017: 374936.35\n",
      "mean_7_2017: 305452.67\n",
      "mean_3_2017: 148957.18\n",
      "promo_12: 93518.03\n",
      "mean_20_dow5_2017: 85159.77\n",
      "mean_4_dow5_2017: 71638.34\n",
      "promo_13: 19595.91\n",
      "promo_14_2017: 16011.22\n",
      "promo_14: 13355.62\n",
      "promo_10: 11265.36\n",
      "mean_140_2017: 9927.43\n",
      "promo_60_2017: 8798.33\n",
      "day_1_2017: 7950.62\n",
      "mean_20_dow0_2017: 7544.02\n",
      "promo_140_2017: 6088.78\n",
      "mean_20_dow6_2017: 5888.75\n",
      "mean_4_dow6_2017: 4725.31\n",
      "promo_11: 4479.14\n",
      "mean_4_dow0_2017: 3756.38\n",
      "mean_20_dow3_2017: 3664.43\n",
      "promo_9: 3613.91\n",
      "mean_20_dow2_2017: 3341.99\n",
      "mean_4_dow2_2017: 2714.48\n",
      "mean_20_dow1_2017: 2701.22\n",
      "mean_4_dow3_2017: 2566.89\n",
      "mean_20_dow4_2017: 2531.39\n",
      "promo_15: 2495.30\n",
      "mean_4_dow1_2017: 2301.79\n",
      "mean_4_dow4_2017: 2274.90\n",
      "promo_7: 2189.77\n",
      "promo_0: 1734.63\n",
      "promo_8: 1699.81\n",
      "promo_5: 1614.77\n",
      "promo_6: 1073.19\n",
      "promo_3: 698.78\n",
      "promo_2: 632.31\n",
      "promo_4: 552.65\n",
      "promo_1: 360.10\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.359483\tvalid_1's l2: 0.362315\n",
      "[200]\ttraining's l2: 0.355317\tvalid_1's l2: 0.361333\n",
      "[300]\ttraining's l2: 0.352142\tvalid_1's l2: 0.36116\n",
      "Early stopping, best iteration is:\n",
      "[341]\ttraining's l2: 0.351057\tvalid_1's l2: 0.361093\n",
      "mean_30_2017: 1503900.26\n",
      "mean_14_2017: 474406.75\n",
      "mean_60_2017: 314928.82\n",
      "mean_7_2017: 302522.14\n",
      "mean_20_dow6_2017: 195214.67\n",
      "promo_13: 161942.26\n",
      "mean_3_2017: 85260.13\n",
      "mean_4_dow6_2017: 72570.04\n",
      "day_1_2017: 20138.75\n",
      "promo_14_2017: 16401.63\n",
      "mean_4_dow5_2017: 12323.03\n",
      "mean_140_2017: 10016.33\n",
      "promo_60_2017: 9711.48\n",
      "promo_14: 9682.72\n",
      "mean_20_dow5_2017: 9004.62\n",
      "promo_10: 8366.20\n",
      "mean_20_dow1_2017: 8346.93\n",
      "promo_140_2017: 6622.02\n",
      "mean_20_dow0_2017: 6016.06\n",
      "promo_12: 5934.91\n",
      "promo_6: 5761.74\n",
      "mean_4_dow0_2017: 3712.35\n",
      "promo_0: 3489.70\n",
      "mean_20_dow3_2017: 3159.65\n",
      "promo_9: 3117.09\n",
      "mean_4_dow1_2017: 3018.32\n",
      "mean_20_dow4_2017: 3011.37\n",
      "promo_11: 2944.78\n",
      "mean_4_dow3_2017: 2494.32\n",
      "mean_20_dow2_2017: 2399.85\n",
      "promo_15: 2280.65\n",
      "mean_4_dow4_2017: 2222.69\n",
      "mean_4_dow2_2017: 2216.53\n",
      "promo_7: 1696.63\n",
      "promo_8: 1501.73\n",
      "promo_2: 999.87\n",
      "promo_4: 820.73\n",
      "promo_1: 501.61\n",
      "promo_3: 407.76\n",
      "promo_5: 358.07\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346946\tvalid_1's l2: 0.349058\n",
      "[200]\ttraining's l2: 0.342413\tvalid_1's l2: 0.348041\n",
      "[300]\ttraining's l2: 0.339349\tvalid_1's l2: 0.347827\n",
      "[400]\ttraining's l2: 0.336694\tvalid_1's l2: 0.347475\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's l2: 0.33672\tvalid_1's l2: 0.34747\n",
      "mean_30_2017: 1510783.19\n",
      "mean_14_2017: 661347.37\n",
      "mean_7_2017: 392564.07\n",
      "mean_20_dow0_2017: 270349.76\n",
      "promo_14: 195765.80\n",
      "mean_60_2017: 174312.36\n",
      "mean_4_dow0_2017: 66182.47\n",
      "day_1_2017: 16736.14\n",
      "promo_7: 16376.36\n",
      "promo_14_2017: 15451.42\n",
      "promo_0: 13747.98\n",
      "mean_3_2017: 13730.83\n",
      "promo_60_2017: 13529.07\n",
      "promo_140_2017: 11707.14\n",
      "promo_13: 9827.58\n",
      "mean_20_dow2_2017: 9398.45\n",
      "mean_140_2017: 8178.01\n",
      "mean_20_dow4_2017: 6067.88\n",
      "promo_12: 6001.85\n",
      "promo_10: 5328.53\n",
      "mean_4_dow2_2017: 4731.33\n",
      "mean_20_dow1_2017: 3872.20\n",
      "promo_15: 3755.41\n",
      "promo_9: 3747.19\n",
      "mean_4_dow6_2017: 3585.10\n",
      "mean_20_dow6_2017: 3221.57\n",
      "mean_4_dow5_2017: 3192.25\n",
      "mean_4_dow1_2017: 3056.25\n",
      "mean_20_dow3_2017: 2992.33\n",
      "mean_4_dow4_2017: 2629.42\n",
      "promo_2: 2543.41\n",
      "mean_20_dow5_2017: 2500.39\n",
      "mean_4_dow3_2017: 2457.65\n",
      "promo_11: 2145.44\n",
      "promo_6: 1194.59\n",
      "promo_8: 1055.05\n",
      "promo_4: 1027.53\n",
      "promo_3: 616.03\n",
      "promo_1: 480.42\n",
      "promo_5: 274.91\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.357487\tvalid_1's l2: 0.372593\n",
      "[200]\ttraining's l2: 0.353175\tvalid_1's l2: 0.371423\n",
      "[300]\ttraining's l2: 0.350209\tvalid_1's l2: 0.370966\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's l2: 0.349009\tvalid_1's l2: 0.370807\n",
      "mean_30_2017: 1454305.00\n",
      "mean_14_2017: 454926.74\n",
      "mean_60_2017: 383159.89\n",
      "mean_7_2017: 217745.33\n",
      "promo_15: 134065.70\n",
      "mean_20_dow1_2017: 109875.66\n",
      "mean_4_dow1_2017: 17102.93\n",
      "day_1_2017: 15830.99\n",
      "mean_20_dow2_2017: 15117.27\n",
      "promo_14_2017: 12513.41\n",
      "promo_60_2017: 11584.19\n",
      "mean_3_2017: 9211.26\n",
      "promo_14: 7912.86\n",
      "promo_140_2017: 7691.20\n",
      "mean_140_2017: 6309.34\n",
      "mean_20_dow4_2017: 5575.79\n",
      "mean_20_dow0_2017: 5231.27\n",
      "mean_4_dow0_2017: 3421.06\n",
      "promo_10: 3212.28\n",
      "mean_4_dow6_2017: 2855.52\n",
      "mean_4_dow2_2017: 2697.58\n",
      "mean_20_dow6_2017: 2494.24\n",
      "promo_13: 2474.50\n",
      "mean_4_dow3_2017: 2419.15\n",
      "mean_4_dow4_2017: 2402.11\n",
      "mean_20_dow5_2017: 2367.49\n",
      "mean_4_dow5_2017: 2280.71\n",
      "promo_12: 2128.19\n",
      "mean_20_dow3_2017: 2065.58\n",
      "promo_7: 1789.05\n",
      "promo_0: 1498.76\n",
      "promo_11: 1486.70\n",
      "promo_9: 1379.17\n",
      "promo_8: 992.07\n",
      "promo_6: 831.67\n",
      "promo_1: 700.04\n",
      "promo_2: 687.44\n",
      "promo_4: 642.91\n",
      "promo_3: 451.08\n",
      "promo_5: 326.33\n",
      "Validation mse: 0.3623709264044814\n",
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    TrainData, usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    TestData, usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    ItemsPath,\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "\n",
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        \"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        \"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 31)\n",
    "X_l, y_l = [], []\n",
    "for i in range(6):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n",
    "\n",
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 300,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 500\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=100\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n",
    "\n",
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 247.36471602948214\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    np.expm1(y_val), np.expm1(np.array(val_pred)).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.583123951777, 15.716233645501712)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(275), np.sqrt(247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
