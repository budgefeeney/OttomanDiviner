{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This is a clone of the script at https://www.kaggle.com/ceshine/lgbm-starter which is intended to give an idea of how to structure the data for trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelude "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataSetPath = \"/home/bryanfeeney/Workspace/OttomanDiviner/favorita/\"\n",
    "\n",
    "StoresPath   = DataSetPath + \"stores.csv.gz\"\n",
    "ItemsPath    = DataSetPath + \"items.csv.gz\"\n",
    "OilPricePath = DataSetPath + \"oil.csv.gz\"\n",
    "HolidaysPath = DataSetPath + \"holidays_events.csv.gz\"\n",
    "Transactions = DataSetPath + \"transactions.csv.gz\"\n",
    "TrainData    = DataSetPath + \"train-2017.csv.gz\"\n",
    "TestData     = DataSetPath + \"test.csv.gz\"\n",
    "\n",
    "FutureDaysToCalculate=16\n",
    "WeeksOfHistoryForFeature=8\n",
    "WeeksOfHistoryForFeatureOnValidation=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul_sales = pd.read_csv(\n",
    "    TrainData, \n",
    "    usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    compression='gzip'\n",
    ")\n",
    "\n",
    "cumul_sales_query = pd.read_csv(\n",
    "    TestData,\n",
    "    usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"],  # , date_parser=parser\n",
    "    compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-08-16'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumul_sales_query = cumul_sales_query.set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           2017-08-15 00:00:00\n",
       "store_nbr                       54\n",
       "item_nbr                   2116416\n",
       "unit_sales                 1.09861\n",
       "onpromotion                  False\n",
       "Name: 23808259, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             125497040\n",
       "onpromotion        False\n",
       "Name: (1, 96995, 2017-08-16 00:00:00), dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales_query.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    ItemsPath,\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    StoresPath\n",
    ").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497040</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497041</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497042</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497043</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497044</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497046</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105576</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497047</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105577</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497048</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105693</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497049</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105737</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497050</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105857</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497051</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106716</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497052</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108079</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497053</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108634</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497054</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108696</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497055</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108698</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497056</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108701</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497057</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108786</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497058</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108797</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497059</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108831</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497060</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108833</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497061</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108862</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108952</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497063</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111223</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497064</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111397</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497065</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112830</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497066</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114778</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497067</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114790</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497068</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114799</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497069</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th>2127921</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867474</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127992</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867475</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128628</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867476</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128799</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867477</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129334</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867478</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129350</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867479</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129387</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867480</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129515</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867481</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129616</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867482</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129678</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867483</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129786</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867484</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129790</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867485</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129892</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867486</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129994</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867487</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130131</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867488</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130219</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867489</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130265</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867490</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130352</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867491</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130474</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867492</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130521</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867493</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130526</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867494</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130553</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867495</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131010</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867496</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131572</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867497</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131699</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867498</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132163</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867499</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132318</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132945</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132957</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867502</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134244</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867503</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3370464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  onpromotion\n",
       "store_nbr item_nbr date                              \n",
       "1         96995    2017-08-16  125497040        False\n",
       "          99197    2017-08-16  125497041        False\n",
       "          103501   2017-08-16  125497042        False\n",
       "          103520   2017-08-16  125497043        False\n",
       "          103665   2017-08-16  125497044        False\n",
       "          105574   2017-08-16  125497045        False\n",
       "          105575   2017-08-16  125497046        False\n",
       "          105576   2017-08-16  125497047        False\n",
       "          105577   2017-08-16  125497048        False\n",
       "          105693   2017-08-16  125497049        False\n",
       "          105737   2017-08-16  125497050        False\n",
       "          105857   2017-08-16  125497051        False\n",
       "          106716   2017-08-16  125497052        False\n",
       "          108079   2017-08-16  125497053        False\n",
       "          108634   2017-08-16  125497054        False\n",
       "          108696   2017-08-16  125497055        False\n",
       "          108698   2017-08-16  125497056        False\n",
       "          108701   2017-08-16  125497057         True\n",
       "          108786   2017-08-16  125497058        False\n",
       "          108797   2017-08-16  125497059         True\n",
       "          108831   2017-08-16  125497060        False\n",
       "          108833   2017-08-16  125497061        False\n",
       "          108862   2017-08-16  125497062        False\n",
       "          108952   2017-08-16  125497063        False\n",
       "          111223   2017-08-16  125497064        False\n",
       "          111397   2017-08-16  125497065        False\n",
       "          112830   2017-08-16  125497066        False\n",
       "          114778   2017-08-16  125497067        False\n",
       "          114790   2017-08-16  125497068         True\n",
       "          114799   2017-08-16  125497069        False\n",
       "...                                  ...          ...\n",
       "54        2127921  2017-08-31  128867474        False\n",
       "          2127992  2017-08-31  128867475        False\n",
       "          2128628  2017-08-31  128867476        False\n",
       "          2128799  2017-08-31  128867477        False\n",
       "          2129334  2017-08-31  128867478        False\n",
       "          2129350  2017-08-31  128867479        False\n",
       "          2129387  2017-08-31  128867480        False\n",
       "          2129515  2017-08-31  128867481        False\n",
       "          2129616  2017-08-31  128867482        False\n",
       "          2129678  2017-08-31  128867483        False\n",
       "          2129786  2017-08-31  128867484        False\n",
       "          2129790  2017-08-31  128867485        False\n",
       "          2129892  2017-08-31  128867486        False\n",
       "          2129994  2017-08-31  128867487        False\n",
       "          2130131  2017-08-31  128867488        False\n",
       "          2130219  2017-08-31  128867489        False\n",
       "          2130265  2017-08-31  128867490        False\n",
       "          2130352  2017-08-31  128867491        False\n",
       "          2130474  2017-08-31  128867492        False\n",
       "          2130521  2017-08-31  128867493        False\n",
       "          2130526  2017-08-31  128867494        False\n",
       "          2130553  2017-08-31  128867495        False\n",
       "          2131010  2017-08-31  128867496        False\n",
       "          2131572  2017-08-31  128867497        False\n",
       "          2131699  2017-08-31  128867498        False\n",
       "          2132163  2017-08-31  128867499        False\n",
       "          2132318  2017-08-31  128867500        False\n",
       "          2132945  2017-08-31  128867501        False\n",
       "          2132957  2017-08-31  128867502        False\n",
       "          2134244  2017-08-31  128867503        False\n",
       "\n",
       "[3370464 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23808260, 5)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370464, 2)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4100, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only Last Three Months\n",
    "\n",
    "This is a peculiar one, and it **games the benchmark** in a not great way. Essentially it uses the last 11 weeks of data before the prediction threshold to predict what's happening next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = date(2017, 8, 15)\n",
    "\n",
    "# How far back to go to start generating trend features for demand\n",
    "data_start             = now - timedelta(7*11) + timedelta(1)\n",
    "training_history_start = now - timedelta(7*WeeksOfHistoryForFeature) + timedelta(1)\n",
    "validation_start       = now - timedelta(7*WeeksOfHistoryForFeatureOnValidation) + timedelta(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2017, 5, 31),\n",
       " datetime.date(2017, 6, 21),\n",
       " datetime.date(2017, 7, 26))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_start, training_history_start, query_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumul_sales = cumul_sales[cumul_sales.date.isin(\n",
    "    pd.date_range(data_start, periods=7 * 11))].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15682590</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>96995</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682591</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>99197</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682592</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>103520</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682593</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>103665</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682594</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>105574</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "15682590 2017-05-31          1     96995    0.693147        False\n",
       "15682591 2017-05-31          1     99197    0.693147        False\n",
       "15682592 2017-05-31          1    103520    1.386294        False\n",
       "15682593 2017-05-31          1    103665    2.197225        False\n",
       "15682594 2017-05-31          1    105574    1.386294        False"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8125670, 5)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           2017-08-15 00:00:00\n",
       "store_nbr                       54\n",
       "item_nbr                   2116416\n",
       "unit_sales                 1.09861\n",
       "onpromotion                  False\n",
       "Name: 23808259, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Promotion Variables\n",
    "\n",
    "So this is a tricky. If one presumes that on-promotion will lead to a boost in demand, if if we presume we'll know *whats on promotion in advance*, then we can create variables to say that this product will be on promotion 1, 2, 3, ... 16 days from now (16 days in the future is the target)\n",
    "\n",
    "In this case, this is also peculiar, there is a column for every single day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_variables = cumul_sales.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               onpromotion\n",
       "store_nbr item_nbr date                   \n",
       "1         96995    2017-05-31        False\n",
       "          99197    2017-05-31        False\n",
       "          103520   2017-05-31        False\n",
       "          103665   2017-05-31        False\n",
       "          105574   2017-05-31        False"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_variables = cumul_sales.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-05-31</th>\n",
       "      <th>2017-06-01</th>\n",
       "      <th>2017-06-02</th>\n",
       "      <th>2017-06-03</th>\n",
       "      <th>2017-06-04</th>\n",
       "      <th>2017-06-05</th>\n",
       "      <th>2017-06-06</th>\n",
       "      <th>2017-06-07</th>\n",
       "      <th>2017-06-08</th>\n",
       "      <th>2017-06-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06</th>\n",
       "      <th>2017-08-07</th>\n",
       "      <th>2017-08-08</th>\n",
       "      <th>2017-08-09</th>\n",
       "      <th>2017-08-10</th>\n",
       "      <th>2017-08-11</th>\n",
       "      <th>2017-08-12</th>\n",
       "      <th>2017-08-13</th>\n",
       "      <th>2017-08-14</th>\n",
       "      <th>2017-08-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   onpromotion                                              \\\n",
       "date                2017-05-31 2017-06-01 2017-06-02 2017-06-03 2017-06-04   \n",
       "store_nbr item_nbr                                                           \n",
       "1         96995          False      False      False      False      False   \n",
       "          99197          False      False      False      False      False   \n",
       "          103520         False      False      False      False      False   \n",
       "          103665         False      False      False      False      False   \n",
       "          105574         False      False      False      False      False   \n",
       "\n",
       "                                                                           \\\n",
       "date               2017-06-05 2017-06-06 2017-06-07 2017-06-08 2017-06-09   \n",
       "store_nbr item_nbr                                                          \n",
       "1         96995         False      False      False      False      False   \n",
       "          99197         False      False      False      False      False   \n",
       "          103520        False      False      False      False      False   \n",
       "          103665        False      False      False      False      False   \n",
       "          105574        False      False      False      False      False   \n",
       "\n",
       "                      ...                                                  \\\n",
       "date                  ...     2017-08-06 2017-08-07 2017-08-08 2017-08-09   \n",
       "store_nbr item_nbr    ...                                                   \n",
       "1         96995       ...          False      False      False      False   \n",
       "          99197       ...          False      False      False      False   \n",
       "          103520      ...          False      False      False      False   \n",
       "          103665      ...          False      False      False      False   \n",
       "          105574      ...          False      False      False      False   \n",
       "\n",
       "                                                                           \\\n",
       "date               2017-08-10 2017-08-11 2017-08-12 2017-08-13 2017-08-14   \n",
       "store_nbr item_nbr                                                          \n",
       "1         96995         False      False      False      False      False   \n",
       "          99197         False      False      False      False      False   \n",
       "          103520        False      False      False      False      False   \n",
       "          103665        False      False      False      False      False   \n",
       "          105574        False      False      False      False      False   \n",
       "\n",
       "                               \n",
       "date               2017-08-15  \n",
       "store_nbr item_nbr             \n",
       "1         96995         False  \n",
       "          99197         False  \n",
       "          103520        False  \n",
       "          103665        False  \n",
       "          105574        False  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_variables.columns = promo_variables.columns.get_level_values(1)\n",
    "\n",
    "promo_variables_query = cumul_sales_query[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_variables_query.columns = promo_variables_query.columns.get_level_values(1)\n",
    "promo_variables_query = promo_variables_query.reindex(promo_variables.index).fillna(False)\n",
    "\n",
    "promo_variables_train_and_query = pd.concat([promo_variables, promo_variables_query], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156790, 77), 221400)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_variables.shape, items.shape[0] * stores.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8125670, 5), (3370464, 2))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.shape, cumul_sales_query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Unstack unit sales - do it across all days in a sliding window\n",
    "\n",
    "Ah... they're creating a multi-task learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156790, 77)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales = cumul_sales.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "cumul_sales.columns = cumul_sales.columns.get_level_values(1)\n",
    "cumul_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-05-31 00:00:00</th>\n",
       "      <th>2017-06-01 00:00:00</th>\n",
       "      <th>2017-06-02 00:00:00</th>\n",
       "      <th>2017-06-03 00:00:00</th>\n",
       "      <th>2017-06-04 00:00:00</th>\n",
       "      <th>2017-06-05 00:00:00</th>\n",
       "      <th>2017-06-06 00:00:00</th>\n",
       "      <th>2017-06-07 00:00:00</th>\n",
       "      <th>2017-06-08 00:00:00</th>\n",
       "      <th>2017-06-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-05-31  2017-06-01  2017-06-02  2017-06-03  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.693147    0.000000    0.000000    0.000000   \n",
       "          99197       0.693147    1.386294    1.098612    1.945910   \n",
       "          103520      1.386294    1.098612    1.098612    0.693147   \n",
       "          103665      2.197225    0.000000    1.791759    1.791759   \n",
       "          105574      1.386294    2.484907    1.791759    1.386294   \n",
       "\n",
       "date                2017-06-04  2017-06-05  2017-06-06  2017-06-07  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       1.098612    1.098612    0.000000    0.000000   \n",
       "          103520      0.000000    0.693147    1.609438    0.693147   \n",
       "          103665      1.098612    1.386294    1.791759    1.386294   \n",
       "          105574      1.386294    1.386294    2.079442    2.397895   \n",
       "\n",
       "date                2017-06-08  2017-06-09     ...      2017-08-06  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995       0.000000    0.693147     ...        1.098612   \n",
       "          99197       0.693147    0.693147     ...        0.000000   \n",
       "          103520      0.693147    1.098612     ...        0.000000   \n",
       "          103665      0.000000    1.098612     ...        0.693147   \n",
       "          105574      1.945910    2.079442     ...        0.000000   \n",
       "\n",
       "date                2017-08-07  2017-08-08  2017-08-09  2017-08-10  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       1.098612    0.000000    0.000000    0.693147   \n",
       "          99197       1.098612    0.000000    1.098612    0.000000   \n",
       "          103520      0.000000    1.386294    0.000000    1.386294   \n",
       "          103665      1.098612    0.000000    2.079442    2.302585   \n",
       "          105574      1.791759    2.079442    1.945910    2.397895   \n",
       "\n",
       "date                2017-08-11  2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          99197       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          103520      0.693147    0.693147    0.693147    0.000000    0.000000  \n",
       "          103665      1.098612    0.000000    0.000000    0.693147    0.693147  \n",
       "          105574      1.791759    1.791759    0.000000    1.386294    1.609438  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make items match other data frames\n",
    "\n",
    "They're sacraficing generability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                family  class  perishable\n",
       "item_nbr                                 \n",
       "96995        GROCERY I   1093           0\n",
       "99197        GROCERY I   1067           0\n",
       "103520       GROCERY I   1028           0\n",
       "103665    BREAD/BAKERY   2712           1\n",
       "105574       GROCERY I   1045           0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = items.reindex(cumul_sales.index.get_level_values(1))\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156790, 3)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time futzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return that portion of the data frame that corresponds to the time period\n",
    "#   beginning \"minus\" days before \"dt\" and extending for \"periods\" days\n",
    "def get_timespan(df, dt, minus, periods):\n",
    "    return df[\n",
    "        pd.date_range(dt - timedelta(days=minus), periods=periods)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(cumul_sales, promo_variables_train_and_query, start_date, is_train=True):\n",
    "    X = pd.DataFrame({  # Mean target for different retrospective timespans & total # promotions\n",
    "        \"mean_3_2017\": get_timespan(cumul_sales, start_date, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(cumul_sales, start_date, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(cumul_sales, start_date, 14, 14).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_variables_train_and_query, start_date, 14, 14).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(16):  # Promotions on future days\n",
    "        X[\"promo_{}\".format(i)] = promo_variables_train_and_query[\n",
    "            start_date + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = cumul_sales[  # Target values for future days\n",
    "            pd.date_range(start_date, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "X_l, y_l = [], []\n",
    "for i in range(4):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(cumul_sales, promo_variables_train_and_query, training_history_start + delta)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "\n",
    "X_validate, y_validate = prepare_dataset(cumul_sales, promo_variables_train_and_query, validation_start)\n",
    "\n",
    "X_query = prepare_dataset(cumul_sales, promo_variables_train_and_query, now, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((627160, 20), (156790, 20), (156790, 20))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape, X_query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is **super gamey**. They're using the means for the week, fortnight, and last three days, and then seeing how to permute it to generate values for the following window of time. It's hardcoded to product IDs, not categories.\n",
    "\n",
    "It does however, permit multi-task learning, and therefore better representation learning\n",
    "\n",
    "It does not incorporate any information about seasonality at all, and so would fall arse over face at Christmas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryanfeeney/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.345147\tvalid_1's l2: 0.341487\n",
      "[100]\ttraining's l2: 0.333379\tvalid_1's l2: 0.330174\n",
      "[150]\ttraining's l2: 0.331405\tvalid_1's l2: 0.328823\n",
      "[200]\ttraining's l2: 0.330344\tvalid_1's l2: 0.328317\n",
      "[250]\ttraining's l2: 0.329476\tvalid_1's l2: 0.327889\n",
      "[300]\ttraining's l2: 0.328793\tvalid_1's l2: 0.327649\n",
      "[350]\ttraining's l2: 0.328187\tvalid_1's l2: 0.327459\n",
      "[400]\ttraining's l2: 0.327652\tvalid_1's l2: 0.327329\n",
      "[450]\ttraining's l2: 0.327151\tvalid_1's l2: 0.327218\n",
      "[500]\ttraining's l2: 0.326681\tvalid_1's l2: 0.327129\n",
      "[550]\ttraining's l2: 0.326264\tvalid_1's l2: 0.327102\n",
      "[600]\ttraining's l2: 0.325878\tvalid_1's l2: 0.327031\n",
      "[650]\ttraining's l2: 0.325453\tvalid_1's l2: 0.326991\n",
      "[700]\ttraining's l2: 0.325065\tvalid_1's l2: 0.326944\n",
      "[750]\ttraining's l2: 0.324698\tvalid_1's l2: 0.326981\n",
      "Early stopping, best iteration is:\n",
      "[712]\ttraining's l2: 0.324969\tvalid_1's l2: 0.326938\n",
      "mean_14_2017: 1984359.03\n",
      "mean_7_2017: 1460047.19\n",
      "mean_3_2017: 315633.02\n",
      "promo_0: 138629.68\n",
      "promo_14_2017: 55752.64\n",
      "promo_7: 21151.43\n",
      "promo_14: 7359.92\n",
      "promo_3: 5651.84\n",
      "promo_15: 3673.71\n",
      "promo_9: 3040.06\n",
      "promo_2: 2182.57\n",
      "promo_13: 2145.98\n",
      "promo_4: 1850.12\n",
      "promo_6: 1666.96\n",
      "promo_1: 1300.76\n",
      "promo_8: 1140.84\n",
      "promo_11: 1099.40\n",
      "promo_10: 1005.44\n",
      "promo_5: 987.11\n",
      "promo_12: 892.11\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.362076\tvalid_1's l2: 0.373873\n",
      "[100]\ttraining's l2: 0.352754\tvalid_1's l2: 0.363655\n",
      "[150]\ttraining's l2: 0.350666\tvalid_1's l2: 0.362006\n",
      "[200]\ttraining's l2: 0.349531\tvalid_1's l2: 0.361224\n",
      "[250]\ttraining's l2: 0.348631\tvalid_1's l2: 0.360787\n",
      "[300]\ttraining's l2: 0.347873\tvalid_1's l2: 0.360452\n",
      "[350]\ttraining's l2: 0.347208\tvalid_1's l2: 0.36028\n",
      "[400]\ttraining's l2: 0.346644\tvalid_1's l2: 0.360162\n",
      "[450]\ttraining's l2: 0.346098\tvalid_1's l2: 0.360094\n",
      "[500]\ttraining's l2: 0.345586\tvalid_1's l2: 0.360001\n",
      "[550]\ttraining's l2: 0.345142\tvalid_1's l2: 0.359979\n",
      "[600]\ttraining's l2: 0.3447\tvalid_1's l2: 0.359935\n",
      "[650]\ttraining's l2: 0.344283\tvalid_1's l2: 0.359878\n",
      "[700]\ttraining's l2: 0.34386\tvalid_1's l2: 0.359895\n",
      "Early stopping, best iteration is:\n",
      "[677]\ttraining's l2: 0.344061\tvalid_1's l2: 0.359856\n",
      "mean_14_2017: 1863420.76\n",
      "mean_7_2017: 1002068.14\n",
      "mean_3_2017: 249076.86\n",
      "promo_1: 99598.59\n",
      "promo_14_2017: 45303.66\n",
      "promo_3: 12426.16\n",
      "promo_0: 7116.38\n",
      "promo_2: 6507.20\n",
      "promo_4: 5307.43\n",
      "promo_5: 4809.32\n",
      "promo_7: 2171.31\n",
      "promo_6: 1987.07\n",
      "promo_9: 1948.41\n",
      "promo_8: 1815.36\n",
      "promo_14: 1663.94\n",
      "promo_15: 1300.56\n",
      "promo_13: 940.38\n",
      "promo_11: 891.77\n",
      "promo_12: 809.27\n",
      "promo_10: 733.40\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.380958\tvalid_1's l2: 0.402325\n",
      "[100]\ttraining's l2: 0.36752\tvalid_1's l2: 0.390119\n",
      "[150]\ttraining's l2: 0.364539\tvalid_1's l2: 0.388836\n",
      "[200]\ttraining's l2: 0.363109\tvalid_1's l2: 0.388261\n",
      "[250]\ttraining's l2: 0.361992\tvalid_1's l2: 0.38778\n",
      "[300]\ttraining's l2: 0.361092\tvalid_1's l2: 0.387636\n",
      "[350]\ttraining's l2: 0.360383\tvalid_1's l2: 0.387466\n",
      "[400]\ttraining's l2: 0.359696\tvalid_1's l2: 0.387286\n",
      "[450]\ttraining's l2: 0.359087\tvalid_1's l2: 0.387174\n",
      "[500]\ttraining's l2: 0.358505\tvalid_1's l2: 0.387097\n",
      "[550]\ttraining's l2: 0.357998\tvalid_1's l2: 0.387024\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's l2: 0.358116\tvalid_1's l2: 0.387023\n",
      "mean_14_2017: 2314537.97\n",
      "mean_7_2017: 970735.19\n",
      "mean_3_2017: 271517.82\n",
      "promo_2: 142199.56\n",
      "promo_14_2017: 60530.43\n",
      "promo_9: 14393.73\n",
      "promo_3: 9973.03\n",
      "promo_0: 5948.03\n",
      "promo_5: 5939.01\n",
      "promo_4: 5323.99\n",
      "promo_1: 4437.70\n",
      "promo_7: 4209.49\n",
      "promo_14: 3350.50\n",
      "promo_10: 2397.69\n",
      "promo_6: 2369.49\n",
      "promo_13: 2301.63\n",
      "promo_11: 1802.19\n",
      "promo_15: 1686.21\n",
      "promo_12: 1132.91\n",
      "promo_8: 1036.03\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.410859\tvalid_1's l2: 0.414478\n",
      "[100]\ttraining's l2: 0.398544\tvalid_1's l2: 0.402678\n",
      "[150]\ttraining's l2: 0.395316\tvalid_1's l2: 0.400757\n",
      "[200]\ttraining's l2: 0.393693\tvalid_1's l2: 0.399966\n",
      "[250]\ttraining's l2: 0.392531\tvalid_1's l2: 0.399542\n",
      "[300]\ttraining's l2: 0.391597\tvalid_1's l2: 0.399159\n",
      "[350]\ttraining's l2: 0.390846\tvalid_1's l2: 0.398996\n",
      "[400]\ttraining's l2: 0.390139\tvalid_1's l2: 0.398757\n",
      "[450]\ttraining's l2: 0.389497\tvalid_1's l2: 0.398663\n",
      "[500]\ttraining's l2: 0.388863\tvalid_1's l2: 0.39857\n",
      "[550]\ttraining's l2: 0.388348\tvalid_1's l2: 0.39848\n",
      "[600]\ttraining's l2: 0.387831\tvalid_1's l2: 0.398336\n",
      "[650]\ttraining's l2: 0.387343\tvalid_1's l2: 0.398262\n",
      "[700]\ttraining's l2: 0.386858\tvalid_1's l2: 0.398191\n",
      "Early stopping, best iteration is:\n",
      "[689]\ttraining's l2: 0.386968\tvalid_1's l2: 0.398183\n",
      "mean_14_2017: 2697032.96\n",
      "mean_7_2017: 1105475.42\n",
      "mean_3_2017: 316007.62\n",
      "promo_3: 83439.28\n",
      "promo_14_2017: 47082.25\n",
      "promo_2: 12419.23\n",
      "promo_5: 9076.45\n",
      "promo_4: 8472.54\n",
      "promo_0: 8113.76\n",
      "promo_1: 7250.05\n",
      "promo_7: 6305.30\n",
      "promo_14: 3936.92\n",
      "promo_6: 3479.44\n",
      "promo_9: 2874.90\n",
      "promo_8: 2604.46\n",
      "promo_10: 2330.52\n",
      "promo_13: 1567.90\n",
      "promo_15: 1530.82\n",
      "promo_11: 1258.65\n",
      "promo_12: 814.40\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.439686\tvalid_1's l2: 0.437679\n",
      "[100]\ttraining's l2: 0.425843\tvalid_1's l2: 0.425114\n",
      "[150]\ttraining's l2: 0.422312\tvalid_1's l2: 0.422295\n",
      "[200]\ttraining's l2: 0.420541\tvalid_1's l2: 0.421264\n",
      "[250]\ttraining's l2: 0.419215\tvalid_1's l2: 0.420517\n",
      "[300]\ttraining's l2: 0.418177\tvalid_1's l2: 0.420055\n",
      "[350]\ttraining's l2: 0.417341\tvalid_1's l2: 0.419739\n",
      "[400]\ttraining's l2: 0.416565\tvalid_1's l2: 0.419497\n",
      "[450]\ttraining's l2: 0.415864\tvalid_1's l2: 0.419336\n",
      "[500]\ttraining's l2: 0.415169\tvalid_1's l2: 0.419215\n",
      "[550]\ttraining's l2: 0.414585\tvalid_1's l2: 0.418983\n",
      "[600]\ttraining's l2: 0.414\tvalid_1's l2: 0.418776\n",
      "[650]\ttraining's l2: 0.41346\tvalid_1's l2: 0.418689\n",
      "[700]\ttraining's l2: 0.412937\tvalid_1's l2: 0.418657\n",
      "[750]\ttraining's l2: 0.41247\tvalid_1's l2: 0.41859\n",
      "[800]\ttraining's l2: 0.412005\tvalid_1's l2: 0.418553\n",
      "[850]\ttraining's l2: 0.411583\tvalid_1's l2: 0.418509\n",
      "[900]\ttraining's l2: 0.411122\tvalid_1's l2: 0.41849\n",
      "[950]\ttraining's l2: 0.410661\tvalid_1's l2: 0.418441\n",
      "Early stopping, best iteration is:\n",
      "[933]\ttraining's l2: 0.410827\tvalid_1's l2: 0.418415\n",
      "mean_14_2017: 2914640.44\n",
      "mean_7_2017: 924894.39\n",
      "mean_3_2017: 566781.56\n",
      "promo_4: 86610.06\n",
      "promo_14_2017: 46068.66\n",
      "promo_5: 12201.68\n",
      "promo_3: 10571.08\n",
      "promo_7: 9095.47\n",
      "promo_2: 7886.59\n",
      "promo_0: 6682.90\n",
      "promo_6: 6318.31\n",
      "promo_1: 6101.91\n",
      "promo_14: 5228.28\n",
      "promo_9: 4469.97\n",
      "promo_11: 4104.98\n",
      "promo_8: 3289.03\n",
      "promo_10: 2272.15\n",
      "promo_13: 2193.23\n",
      "promo_15: 2131.23\n",
      "promo_12: 2123.78\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.409653\tvalid_1's l2: 0.42408\n",
      "[100]\ttraining's l2: 0.398279\tvalid_1's l2: 0.410289\n",
      "[150]\ttraining's l2: 0.395357\tvalid_1's l2: 0.407857\n",
      "[200]\ttraining's l2: 0.393817\tvalid_1's l2: 0.407013\n",
      "[250]\ttraining's l2: 0.392734\tvalid_1's l2: 0.406522\n",
      "[300]\ttraining's l2: 0.391829\tvalid_1's l2: 0.406158\n",
      "[350]\ttraining's l2: 0.391019\tvalid_1's l2: 0.405963\n",
      "[400]\ttraining's l2: 0.390315\tvalid_1's l2: 0.405788\n",
      "[450]\ttraining's l2: 0.389698\tvalid_1's l2: 0.405628\n",
      "[500]\ttraining's l2: 0.389118\tvalid_1's l2: 0.405574\n",
      "[550]\ttraining's l2: 0.388531\tvalid_1's l2: 0.4055\n",
      "[600]\ttraining's l2: 0.388037\tvalid_1's l2: 0.405475\n",
      "[650]\ttraining's l2: 0.387519\tvalid_1's l2: 0.405453\n",
      "[700]\ttraining's l2: 0.387018\tvalid_1's l2: 0.405434\n",
      "[750]\ttraining's l2: 0.386571\tvalid_1's l2: 0.405328\n",
      "[800]\ttraining's l2: 0.386125\tvalid_1's l2: 0.4053\n",
      "[850]\ttraining's l2: 0.385686\tvalid_1's l2: 0.405277\n",
      "Early stopping, best iteration is:\n",
      "[839]\ttraining's l2: 0.385774\tvalid_1's l2: 0.405261\n",
      "mean_14_2017: 2386896.02\n",
      "mean_7_2017: 836091.12\n",
      "mean_3_2017: 374706.28\n",
      "promo_5: 91722.63\n",
      "promo_14_2017: 45313.16\n",
      "promo_3: 15732.84\n",
      "promo_6: 12353.01\n",
      "promo_7: 10550.52\n",
      "promo_2: 5638.10\n",
      "promo_4: 5392.82\n",
      "promo_1: 4730.41\n",
      "promo_0: 4705.81\n",
      "promo_9: 3979.45\n",
      "promo_8: 3446.66\n",
      "promo_14: 3163.01\n",
      "promo_12: 2382.70\n",
      "promo_11: 2199.53\n",
      "promo_13: 1879.77\n",
      "promo_10: 1861.10\n",
      "promo_15: 1508.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.399249\tvalid_1's l2: 0.499368\n",
      "[100]\ttraining's l2: 0.387491\tvalid_1's l2: 0.484385\n",
      "[150]\ttraining's l2: 0.384487\tvalid_1's l2: 0.483271\n",
      "[200]\ttraining's l2: 0.382909\tvalid_1's l2: 0.482962\n",
      "[250]\ttraining's l2: 0.381732\tvalid_1's l2: 0.482566\n",
      "[300]\ttraining's l2: 0.380894\tvalid_1's l2: 0.482571\n",
      "Early stopping, best iteration is:\n",
      "[265]\ttraining's l2: 0.381465\tvalid_1's l2: 0.482494\n",
      "mean_14_2017: 2176120.92\n",
      "mean_7_2017: 788873.90\n",
      "mean_3_2017: 309822.71\n",
      "promo_6: 154213.49\n",
      "promo_14_2017: 50427.60\n",
      "promo_3: 14230.01\n",
      "promo_7: 10208.19\n",
      "promo_13: 8896.97\n",
      "promo_5: 7975.26\n",
      "promo_0: 4785.81\n",
      "promo_1: 4559.44\n",
      "promo_4: 4185.97\n",
      "promo_9: 3828.04\n",
      "promo_2: 3637.22\n",
      "promo_14: 3187.51\n",
      "promo_8: 2329.80\n",
      "promo_11: 1460.21\n",
      "promo_15: 1382.96\n",
      "promo_12: 1252.57\n",
      "promo_10: 1153.89\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.387984\tvalid_1's l2: 0.460446\n",
      "[100]\ttraining's l2: 0.375614\tvalid_1's l2: 0.442317\n",
      "[150]\ttraining's l2: 0.372869\tvalid_1's l2: 0.439638\n",
      "[200]\ttraining's l2: 0.371506\tvalid_1's l2: 0.438919\n",
      "[250]\ttraining's l2: 0.370348\tvalid_1's l2: 0.438294\n",
      "[300]\ttraining's l2: 0.369382\tvalid_1's l2: 0.437761\n",
      "[350]\ttraining's l2: 0.368648\tvalid_1's l2: 0.437692\n",
      "[400]\ttraining's l2: 0.367991\tvalid_1's l2: 0.437483\n",
      "[450]\ttraining's l2: 0.367415\tvalid_1's l2: 0.437284\n",
      "[500]\ttraining's l2: 0.36681\tvalid_1's l2: 0.436947\n",
      "[550]\ttraining's l2: 0.366269\tvalid_1's l2: 0.436806\n",
      "[600]\ttraining's l2: 0.365757\tvalid_1's l2: 0.436685\n",
      "[650]\ttraining's l2: 0.365266\tvalid_1's l2: 0.436622\n",
      "[700]\ttraining's l2: 0.364806\tvalid_1's l2: 0.436448\n",
      "[750]\ttraining's l2: 0.364372\tvalid_1's l2: 0.436336\n",
      "Early stopping, best iteration is:\n",
      "[742]\ttraining's l2: 0.364435\tvalid_1's l2: 0.43632\n",
      "mean_14_2017: 2384240.95\n",
      "mean_7_2017: 801670.59\n",
      "mean_3_2017: 264155.96\n",
      "promo_7: 198774.35\n",
      "promo_14_2017: 42542.97\n",
      "promo_0: 40765.34\n",
      "promo_14: 25196.80\n",
      "promo_5: 8292.56\n",
      "promo_9: 7164.19\n",
      "promo_3: 7084.16\n",
      "promo_6: 5672.33\n",
      "promo_8: 5019.97\n",
      "promo_2: 3879.19\n",
      "promo_1: 3548.74\n",
      "promo_4: 3497.21\n",
      "promo_15: 3247.70\n",
      "promo_13: 2244.96\n",
      "promo_10: 1998.42\n",
      "promo_11: 1449.73\n",
      "promo_12: 977.34\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.395037\tvalid_1's l2: 0.439454\n",
      "[100]\ttraining's l2: 0.384584\tvalid_1's l2: 0.426972\n",
      "[150]\ttraining's l2: 0.381732\tvalid_1's l2: 0.425432\n",
      "[200]\ttraining's l2: 0.380296\tvalid_1's l2: 0.425281\n",
      "[250]\ttraining's l2: 0.379213\tvalid_1's l2: 0.425006\n",
      "[300]\ttraining's l2: 0.378344\tvalid_1's l2: 0.424918\n",
      "[350]\ttraining's l2: 0.377609\tvalid_1's l2: 0.424904\n",
      "[400]\ttraining's l2: 0.376952\tvalid_1's l2: 0.424708\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's l2: 0.377141\tvalid_1's l2: 0.424637\n",
      "mean_14_2017: 2077119.49\n",
      "mean_7_2017: 656491.04\n",
      "mean_3_2017: 224372.51\n",
      "promo_8: 131914.07\n",
      "promo_14_2017: 50054.02\n",
      "promo_10: 16482.92\n",
      "promo_9: 8808.18\n",
      "promo_7: 8458.18\n",
      "promo_3: 5666.37\n",
      "promo_11: 4931.93\n",
      "promo_12: 4697.29\n",
      "promo_0: 4013.58\n",
      "promo_13: 3924.70\n",
      "promo_5: 3893.99\n",
      "promo_14: 3236.70\n",
      "promo_1: 2888.35\n",
      "promo_2: 2232.78\n",
      "promo_6: 2094.34\n",
      "promo_15: 1993.37\n",
      "promo_4: 1415.84\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.411026\tvalid_1's l2: 0.442639\n",
      "[100]\ttraining's l2: 0.397615\tvalid_1's l2: 0.429143\n",
      "[150]\ttraining's l2: 0.394128\tvalid_1's l2: 0.427653\n",
      "[200]\ttraining's l2: 0.392371\tvalid_1's l2: 0.427125\n",
      "[250]\ttraining's l2: 0.391087\tvalid_1's l2: 0.426783\n",
      "[300]\ttraining's l2: 0.39013\tvalid_1's l2: 0.426697\n",
      "[350]\ttraining's l2: 0.389285\tvalid_1's l2: 0.426582\n",
      "[400]\ttraining's l2: 0.388524\tvalid_1's l2: 0.426592\n",
      "Early stopping, best iteration is:\n",
      "[352]\ttraining's l2: 0.389257\tvalid_1's l2: 0.426548\n",
      "mean_14_2017: 2346026.51\n",
      "mean_7_2017: 761032.49\n",
      "mean_3_2017: 250063.23\n",
      "promo_9: 182626.26\n",
      "promo_14_2017: 65436.94\n",
      "promo_2: 20515.41\n",
      "promo_10: 11163.22\n",
      "promo_7: 8953.55\n",
      "promo_8: 6393.92\n",
      "promo_14: 5977.96\n",
      "promo_12: 5281.36\n",
      "promo_11: 4654.14\n",
      "promo_13: 3080.82\n",
      "promo_1: 2600.92\n",
      "promo_0: 2509.35\n",
      "promo_6: 2245.80\n",
      "promo_15: 1777.74\n",
      "promo_4: 1538.89\n",
      "promo_5: 1453.62\n",
      "promo_3: 986.94\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.446628\tvalid_1's l2: 0.449294\n",
      "[100]\ttraining's l2: 0.433935\tvalid_1's l2: 0.439457\n",
      "[150]\ttraining's l2: 0.430043\tvalid_1's l2: 0.438353\n",
      "[200]\ttraining's l2: 0.428227\tvalid_1's l2: 0.438198\n",
      "[250]\ttraining's l2: 0.426948\tvalid_1's l2: 0.43811\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's l2: 0.427787\tvalid_1's l2: 0.438017\n",
      "mean_14_2017: 2671867.29\n",
      "mean_7_2017: 869882.97\n",
      "mean_3_2017: 282448.19\n",
      "promo_10: 115969.71\n",
      "promo_14_2017: 51984.48\n",
      "promo_9: 15341.94\n",
      "promo_12: 11561.37\n",
      "promo_14: 9928.24\n",
      "promo_7: 9317.06\n",
      "promo_11: 9259.17\n",
      "promo_8: 7426.97\n",
      "promo_13: 4942.61\n",
      "promo_3: 4886.61\n",
      "promo_15: 3787.28\n",
      "promo_0: 2647.59\n",
      "promo_2: 2531.43\n",
      "promo_6: 2371.78\n",
      "promo_5: 1971.52\n",
      "promo_1: 1793.20\n",
      "promo_4: 1552.65\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.473633\tvalid_1's l2: 0.478351\n",
      "[100]\ttraining's l2: 0.459869\tvalid_1's l2: 0.46719\n",
      "[150]\ttraining's l2: 0.455735\tvalid_1's l2: 0.465738\n",
      "[200]\ttraining's l2: 0.453809\tvalid_1's l2: 0.465062\n",
      "[250]\ttraining's l2: 0.452357\tvalid_1's l2: 0.464715\n",
      "[300]\ttraining's l2: 0.451255\tvalid_1's l2: 0.464459\n",
      "[350]\ttraining's l2: 0.450352\tvalid_1's l2: 0.46411\n",
      "[400]\ttraining's l2: 0.449506\tvalid_1's l2: 0.463974\n",
      "[450]\ttraining's l2: 0.448738\tvalid_1's l2: 0.46379\n",
      "Early stopping, best iteration is:\n",
      "[445]\ttraining's l2: 0.448809\tvalid_1's l2: 0.463786\n",
      "mean_14_2017: 2861612.74\n",
      "mean_7_2017: 800780.07\n",
      "mean_3_2017: 442969.15\n",
      "promo_11: 121260.28\n",
      "promo_14_2017: 51230.04\n",
      "promo_10: 12686.76\n",
      "promo_14: 12591.65\n",
      "promo_12: 12315.98\n",
      "promo_9: 11873.38\n",
      "promo_4: 10946.24\n",
      "promo_13: 8811.57\n",
      "promo_7: 8106.75\n",
      "promo_8: 6954.74\n",
      "promo_15: 4047.03\n",
      "promo_0: 3765.31\n",
      "promo_6: 3056.30\n",
      "promo_2: 2407.47\n",
      "promo_1: 2386.24\n",
      "promo_5: 2364.50\n",
      "promo_3: 1759.24\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.439596\tvalid_1's l2: 0.442076\n",
      "[100]\ttraining's l2: 0.427552\tvalid_1's l2: 0.43146\n",
      "[150]\ttraining's l2: 0.424334\tvalid_1's l2: 0.429868\n",
      "[200]\ttraining's l2: 0.422715\tvalid_1's l2: 0.429513\n",
      "[250]\ttraining's l2: 0.421404\tvalid_1's l2: 0.429096\n",
      "[300]\ttraining's l2: 0.42036\tvalid_1's l2: 0.429036\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's l2: 0.421256\tvalid_1's l2: 0.429019\n",
      "mean_14_2017: 2371138.77\n",
      "mean_7_2017: 698072.40\n",
      "mean_3_2017: 343280.62\n",
      "promo_12: 106604.26\n",
      "promo_14_2017: 46029.13\n",
      "promo_13: 27437.76\n",
      "promo_10: 13324.76\n",
      "promo_14: 12125.67\n",
      "promo_9: 8284.28\n",
      "promo_15: 5669.04\n",
      "promo_5: 5634.23\n",
      "promo_11: 5407.64\n",
      "promo_7: 5233.36\n",
      "promo_8: 3702.25\n",
      "promo_0: 2764.41\n",
      "promo_3: 2389.24\n",
      "promo_6: 2297.64\n",
      "promo_1: 1439.98\n",
      "promo_2: 1314.36\n",
      "promo_4: 1070.48\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.424686\tvalid_1's l2: 0.424893\n",
      "[100]\ttraining's l2: 0.412486\tvalid_1's l2: 0.41538\n",
      "[150]\ttraining's l2: 0.409\tvalid_1's l2: 0.414168\n",
      "[200]\ttraining's l2: 0.407385\tvalid_1's l2: 0.413722\n",
      "[250]\ttraining's l2: 0.406155\tvalid_1's l2: 0.413439\n",
      "[300]\ttraining's l2: 0.40523\tvalid_1's l2: 0.413366\n",
      "[350]\ttraining's l2: 0.404405\tvalid_1's l2: 0.413319\n",
      "[400]\ttraining's l2: 0.403644\tvalid_1's l2: 0.413183\n",
      "Early stopping, best iteration is:\n",
      "[391]\ttraining's l2: 0.403794\tvalid_1's l2: 0.413157\n",
      "mean_14_2017: 2197954.55\n",
      "mean_7_2017: 648844.42\n",
      "mean_3_2017: 294139.48\n",
      "promo_13: 188581.98\n",
      "promo_14_2017: 49218.27\n",
      "promo_12: 15148.05\n",
      "promo_14: 14515.74\n",
      "promo_6: 14267.64\n",
      "promo_10: 10334.23\n",
      "promo_7: 6407.14\n",
      "promo_9: 6162.31\n",
      "promo_0: 5878.17\n",
      "promo_8: 4762.65\n",
      "promo_11: 4136.61\n",
      "promo_15: 4086.48\n",
      "promo_2: 2456.07\n",
      "promo_1: 1936.21\n",
      "promo_4: 1720.93\n",
      "promo_5: 1561.92\n",
      "promo_3: 1243.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.410998\tvalid_1's l2: 0.410436\n",
      "[100]\ttraining's l2: 0.397157\tvalid_1's l2: 0.398619\n",
      "[150]\ttraining's l2: 0.394315\tvalid_1's l2: 0.397761\n",
      "[200]\ttraining's l2: 0.392755\tvalid_1's l2: 0.397444\n",
      "[250]\ttraining's l2: 0.391625\tvalid_1's l2: 0.397205\n",
      "[300]\ttraining's l2: 0.390647\tvalid_1's l2: 0.397032\n",
      "[350]\ttraining's l2: 0.389848\tvalid_1's l2: 0.396838\n",
      "[400]\ttraining's l2: 0.38916\tvalid_1's l2: 0.396693\n",
      "[450]\ttraining's l2: 0.388521\tvalid_1's l2: 0.396705\n",
      "Early stopping, best iteration is:\n",
      "[418]\ttraining's l2: 0.388918\tvalid_1's l2: 0.396637\n",
      "mean_14_2017: 2326294.16\n",
      "mean_7_2017: 697294.28\n",
      "mean_3_2017: 242807.08\n",
      "promo_14: 232132.33\n",
      "promo_14_2017: 49620.78\n",
      "promo_7: 31713.90\n",
      "promo_0: 29744.91\n",
      "promo_15: 19946.17\n",
      "promo_13: 11068.67\n",
      "promo_9: 9069.83\n",
      "promo_12: 8493.43\n",
      "promo_10: 6377.01\n",
      "promo_2: 4226.62\n",
      "promo_6: 4122.19\n",
      "promo_8: 3039.53\n",
      "promo_11: 3002.61\n",
      "promo_4: 2528.08\n",
      "promo_1: 1724.67\n",
      "promo_3: 1156.68\n",
      "promo_5: 1084.95\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.419186\tvalid_1's l2: 0.432432\n",
      "[100]\ttraining's l2: 0.408497\tvalid_1's l2: 0.423824\n",
      "[150]\ttraining's l2: 0.405564\tvalid_1's l2: 0.422495\n",
      "[200]\ttraining's l2: 0.403982\tvalid_1's l2: 0.422027\n",
      "[250]\ttraining's l2: 0.402776\tvalid_1's l2: 0.421674\n",
      "[300]\ttraining's l2: 0.401741\tvalid_1's l2: 0.421631\n",
      "[350]\ttraining's l2: 0.400889\tvalid_1's l2: 0.421475\n",
      "[400]\ttraining's l2: 0.400046\tvalid_1's l2: 0.421381\n",
      "[450]\ttraining's l2: 0.39941\tvalid_1's l2: 0.421229\n",
      "[500]\ttraining's l2: 0.398826\tvalid_1's l2: 0.421114\n",
      "Early stopping, best iteration is:\n",
      "[484]\ttraining's l2: 0.398993\tvalid_1's l2: 0.421093\n",
      "mean_14_2017: 2022529.92\n",
      "mean_7_2017: 601740.87\n",
      "mean_3_2017: 213387.36\n",
      "promo_15: 184125.89\n",
      "promo_14_2017: 51237.69\n",
      "promo_14: 10084.43\n",
      "promo_7: 5849.95\n",
      "promo_9: 4852.21\n",
      "promo_10: 4486.45\n",
      "promo_0: 4422.50\n",
      "promo_13: 3956.91\n",
      "promo_12: 3710.38\n",
      "promo_8: 3415.79\n",
      "promo_11: 2732.34\n",
      "promo_1: 2314.99\n",
      "promo_2: 2312.65\n",
      "promo_3: 2167.87\n",
      "promo_6: 2003.93\n",
      "promo_5: 1334.89\n",
      "promo_4: 1291.08\n"
     ]
    }
   ],
   "source": [
    "MAX_ROUNDS = 1000\n",
    "validate_pred = []\n",
    "query_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 4) * 0.25 + 1\n",
    "    )\n",
    "    \n",
    "    dvalidate = lgb.Dataset(\n",
    "        X_validate, label=y_validate[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    \n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dvalidate], early_stopping_rounds=50, verbose_eval=50\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    \n",
    "    \n",
    "    validate_pred.append(bst.predict(\n",
    "        X_validate, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    \n",
    "    query_pred.append(bst.predict(\n",
    "        X_query, num_iteration=bst.best_iteration or MAX_ROUNDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [156790, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-c20556017a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print(\"Validation mse:\", np.sqrt(mean_squared_error(\n\u001b[0;32m----> 2\u001b[0;31m     np.expm1(y_validate), np.expm1(np.array(val_pred)).transpose())))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[1;32m    237\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 238\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    239\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[1;32m    240\u001b[0m                                weights=sample_weight)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [156790, 0]"
     ]
    }
   ],
   "source": [
    "print(\"Validation mse:\", np.sqrt(mean_squared_error(\n",
    "    np.expm1(y_validate), np.expm1(np.array(val_pred)).transpose())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156790, 16),\n",
       " array([[0.24158492, 0.24897964, 0.27285152, ..., 0.29180975, 0.30408553,\n",
       "         0.27975772],\n",
       "        [0.20325735, 0.19115871, 0.2179842 , ..., 0.2247866 , 0.21264327,\n",
       "         0.20899921],\n",
       "        [0.60762603, 0.5517181 , 0.62237221, ..., 0.6044998 , 0.60427741,\n",
       "         0.56521111],\n",
       "        ...,\n",
       "        [0.2351554 , 0.21443665, 0.25158354, ..., 0.23555907, 0.22213154,\n",
       "         0.21211291],\n",
       "        [1.69932833, 1.56939365, 1.70439771, ..., 1.75361082, 1.68996464,\n",
       "         1.71933721],\n",
       "        [0.42327216, 0.39768466, 0.37982758, ..., 0.4117993 , 0.37641541,\n",
       "         0.36814008]]))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_query.shape, y_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "print(\"Making submission...\")\n",
    "y_query = np.array(query_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_query, index=cumul_sales.index,\n",
    "    columns=pd.date_range(query_start_date, periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.to_csv(\"/tmp/df_preds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_csv(\"/tmp/df_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"16\" valign=\"top\">96995</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>0.241585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17</th>\n",
       "      <td>0.248980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>0.272852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>0.400383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>0.399940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>0.315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>0.273534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>0.298480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>0.273323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0.282542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>0.389233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>0.407575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>0.334721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>0.291810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>0.304086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>0.279758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">99197</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>0.203257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17</th>\n",
       "      <td>0.191159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>0.217984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>0.308270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>0.307682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>0.232190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>0.213910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>0.215569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>0.204758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0.233479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>0.317981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>0.337348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>0.242458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>0.224787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">2113914</th>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>1.704398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>1.931238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>2.080978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>1.892543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>1.745028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>1.728047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>1.628953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>1.702164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>2.021705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>2.116263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>1.839200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>1.753611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>1.689965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>1.719337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">2116416</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>0.423272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17</th>\n",
       "      <td>0.397685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>0.379828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>0.576106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>0.617939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>0.484577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>0.460715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>0.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>0.387298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0.354630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>0.554047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>0.615359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>0.511372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>0.411799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>0.376415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>0.368140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2508640 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               unit_sales\n",
       "store_nbr item_nbr date                  \n",
       "1         96995    2017-08-16    0.241585\n",
       "                   2017-08-17    0.248980\n",
       "                   2017-08-18    0.272852\n",
       "                   2017-08-19    0.400383\n",
       "                   2017-08-20    0.399940\n",
       "                   2017-08-21    0.315500\n",
       "                   2017-08-22    0.273534\n",
       "                   2017-08-23    0.298480\n",
       "                   2017-08-24    0.273323\n",
       "                   2017-08-25    0.282542\n",
       "                   2017-08-26    0.389233\n",
       "                   2017-08-27    0.407575\n",
       "                   2017-08-28    0.334721\n",
       "                   2017-08-29    0.291810\n",
       "                   2017-08-30    0.304086\n",
       "                   2017-08-31    0.279758\n",
       "          99197    2017-08-16    0.203257\n",
       "                   2017-08-17    0.191159\n",
       "                   2017-08-18    0.217984\n",
       "                   2017-08-19    0.308270\n",
       "                   2017-08-20    0.307682\n",
       "                   2017-08-21    0.232190\n",
       "                   2017-08-22    0.213910\n",
       "                   2017-08-23    0.215569\n",
       "                   2017-08-24    0.204758\n",
       "                   2017-08-25    0.233479\n",
       "                   2017-08-26    0.317981\n",
       "                   2017-08-27    0.337348\n",
       "                   2017-08-28    0.242458\n",
       "                   2017-08-29    0.224787\n",
       "...                                   ...\n",
       "54        2113914  2017-08-18    1.704398\n",
       "                   2017-08-19    1.931238\n",
       "                   2017-08-20    2.080978\n",
       "                   2017-08-21    1.892543\n",
       "                   2017-08-22    1.745028\n",
       "                   2017-08-23    1.728047\n",
       "                   2017-08-24    1.628953\n",
       "                   2017-08-25    1.702164\n",
       "                   2017-08-26    2.021705\n",
       "                   2017-08-27    2.116263\n",
       "                   2017-08-28    1.839200\n",
       "                   2017-08-29    1.753611\n",
       "                   2017-08-30    1.689965\n",
       "                   2017-08-31    1.719337\n",
       "          2116416  2017-08-16    0.423272\n",
       "                   2017-08-17    0.397685\n",
       "                   2017-08-18    0.379828\n",
       "                   2017-08-19    0.576106\n",
       "                   2017-08-20    0.617939\n",
       "                   2017-08-21    0.484577\n",
       "                   2017-08-22    0.460715\n",
       "                   2017-08-23    0.370500\n",
       "                   2017-08-24    0.387298\n",
       "                   2017-08-25    0.354630\n",
       "                   2017-08-26    0.554047\n",
       "                   2017-08-27    0.615359\n",
       "                   2017-08-28    0.511372\n",
       "                   2017-08-29    0.411799\n",
       "                   2017-08-30    0.376415\n",
       "                   2017-08-31    0.368140\n",
       "\n",
       "[2508640 rows x 1 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-d5b4aef1dc75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unit_sales\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unit_sales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497040</td>\n",
       "      <td>0.273266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497041</td>\n",
       "      <td>0.225388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497042</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497043</td>\n",
       "      <td>0.648250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497044</td>\n",
       "      <td>1.352113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497045</td>\n",
       "      <td>3.222305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497046</td>\n",
       "      <td>7.469437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105576</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497047</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105577</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497048</td>\n",
       "      <td>0.294655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105693</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497049</td>\n",
       "      <td>0.319934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105737</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497050</td>\n",
       "      <td>0.763024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105857</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497051</td>\n",
       "      <td>3.247849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106716</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497052</td>\n",
       "      <td>1.781587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108079</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497053</td>\n",
       "      <td>0.346823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108634</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497054</td>\n",
       "      <td>0.033705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108696</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497055</td>\n",
       "      <td>1.357327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108698</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497056</td>\n",
       "      <td>0.585320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108701</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497057</td>\n",
       "      <td>1.804330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108786</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497058</td>\n",
       "      <td>1.744146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108797</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497059</td>\n",
       "      <td>2.840066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108831</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108833</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108862</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497062</td>\n",
       "      <td>0.704088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108952</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497063</td>\n",
       "      <td>1.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111223</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497064</td>\n",
       "      <td>3.262282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111397</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497065</td>\n",
       "      <td>0.431402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112830</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497066</td>\n",
       "      <td>1.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114778</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497067</td>\n",
       "      <td>1.617434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114790</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497068</td>\n",
       "      <td>2.928812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114799</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497069</td>\n",
       "      <td>0.731032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th>2127921</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127992</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867475</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128628</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128799</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867477</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129334</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867478</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129350</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129387</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129515</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867481</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129616</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867482</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129678</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129786</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867484</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129790</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867485</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129892</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129994</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867487</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130131</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130219</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867489</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130265</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867490</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130352</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867491</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130474</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867492</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130521</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130526</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867494</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130553</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131010</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131572</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867497</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131699</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867498</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132163</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132318</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132945</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132957</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867502</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134244</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867503</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3370464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  unit_sales\n",
       "store_nbr item_nbr date                             \n",
       "1         96995    2017-08-16  125497040    0.273266\n",
       "          99197    2017-08-16  125497041    0.225388\n",
       "          103501   2017-08-16  125497042    0.000000\n",
       "          103520   2017-08-16  125497043    0.648250\n",
       "          103665   2017-08-16  125497044    1.352113\n",
       "          105574   2017-08-16  125497045    3.222305\n",
       "          105575   2017-08-16  125497046    7.469437\n",
       "          105576   2017-08-16  125497047    0.000000\n",
       "          105577   2017-08-16  125497048    0.294655\n",
       "          105693   2017-08-16  125497049    0.319934\n",
       "          105737   2017-08-16  125497050    0.763024\n",
       "          105857   2017-08-16  125497051    3.247849\n",
       "          106716   2017-08-16  125497052    1.781587\n",
       "          108079   2017-08-16  125497053    0.346823\n",
       "          108634   2017-08-16  125497054    0.033705\n",
       "          108696   2017-08-16  125497055    1.357327\n",
       "          108698   2017-08-16  125497056    0.585320\n",
       "          108701   2017-08-16  125497057    1.804330\n",
       "          108786   2017-08-16  125497058    1.744146\n",
       "          108797   2017-08-16  125497059    2.840066\n",
       "          108831   2017-08-16  125497060    0.000000\n",
       "          108833   2017-08-16  125497061    0.000000\n",
       "          108862   2017-08-16  125497062    0.704088\n",
       "          108952   2017-08-16  125497063    1.000221\n",
       "          111223   2017-08-16  125497064    3.262282\n",
       "          111397   2017-08-16  125497065    0.431402\n",
       "          112830   2017-08-16  125497066    1.090800\n",
       "          114778   2017-08-16  125497067    1.617434\n",
       "          114790   2017-08-16  125497068    2.928812\n",
       "          114799   2017-08-16  125497069    0.731032\n",
       "...                                  ...         ...\n",
       "54        2127921  2017-08-31  128867474    0.000000\n",
       "          2127992  2017-08-31  128867475    0.000000\n",
       "          2128628  2017-08-31  128867476    0.000000\n",
       "          2128799  2017-08-31  128867477    0.000000\n",
       "          2129334  2017-08-31  128867478    0.000000\n",
       "          2129350  2017-08-31  128867479    0.000000\n",
       "          2129387  2017-08-31  128867480    0.000000\n",
       "          2129515  2017-08-31  128867481    0.000000\n",
       "          2129616  2017-08-31  128867482    0.000000\n",
       "          2129678  2017-08-31  128867483    0.000000\n",
       "          2129786  2017-08-31  128867484    0.000000\n",
       "          2129790  2017-08-31  128867485    0.000000\n",
       "          2129892  2017-08-31  128867486    0.000000\n",
       "          2129994  2017-08-31  128867487    0.000000\n",
       "          2130131  2017-08-31  128867488    0.000000\n",
       "          2130219  2017-08-31  128867489    0.000000\n",
       "          2130265  2017-08-31  128867490    0.000000\n",
       "          2130352  2017-08-31  128867491    0.000000\n",
       "          2130474  2017-08-31  128867492    0.000000\n",
       "          2130521  2017-08-31  128867493    0.000000\n",
       "          2130526  2017-08-31  128867494    0.000000\n",
       "          2130553  2017-08-31  128867495    0.000000\n",
       "          2131010  2017-08-31  128867496    0.000000\n",
       "          2131572  2017-08-31  128867497    0.000000\n",
       "          2131699  2017-08-31  128867498    0.000000\n",
       "          2132163  2017-08-31  128867499    0.000000\n",
       "          2132318  2017-08-31  128867500    0.000000\n",
       "          2132945  2017-08-31  128867501    0.000000\n",
       "          2132957  2017-08-31  128867502    0.000000\n",
       "          2134244  2017-08-31  128867503    0.000000\n",
       "\n",
       "[3370464 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on the work in this file: https://www.kaggle.com/vrtjso/lgbm-one-step-ahead\n",
    "\n",
    "This was apparently in the top 10% at one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Training and predicting models...\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryanfeeney/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.30191\tvalid_1's l2: 0.29409\n",
      "[200]\ttraining's l2: 0.298363\tvalid_1's l2: 0.292741\n",
      "[300]\ttraining's l2: 0.295918\tvalid_1's l2: 0.292337\n",
      "[400]\ttraining's l2: 0.293791\tvalid_1's l2: 0.2921\n",
      "[500]\ttraining's l2: 0.29199\tvalid_1's l2: 0.29195\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.29199\tvalid_1's l2: 0.29195\n",
      "mean_7_2017: 1882639.38\n",
      "mean_14_2017: 1229821.77\n",
      "promo_0: 104143.51\n",
      "day_1_2017: 89857.46\n",
      "mean_20_dow0_2017: 84245.48\n",
      "mean_3_2017: 76646.29\n",
      "mean_30_2017: 76583.57\n",
      "mean_4_dow0_2017: 58919.38\n",
      "mean_60_2017: 33035.18\n",
      "promo_14_2017: 28619.72\n",
      "promo_7: 9432.45\n",
      "mean_4_dow5_2017: 7417.05\n",
      "mean_140_2017: 7406.32\n",
      "promo_60_2017: 6740.72\n",
      "mean_20_dow4_2017: 5611.55\n",
      "promo_140_2017: 5493.72\n",
      "mean_4_dow6_2017: 4633.44\n",
      "mean_4_dow2_2017: 3813.74\n",
      "mean_20_dow2_2017: 3343.78\n",
      "mean_4_dow3_2017: 2824.66\n",
      "promo_9: 2814.25\n",
      "mean_4_dow1_2017: 2707.00\n",
      "mean_20_dow3_2017: 2642.58\n",
      "mean_20_dow1_2017: 2616.99\n",
      "mean_4_dow4_2017: 2601.73\n",
      "promo_14: 2554.27\n",
      "mean_20_dow6_2017: 2328.54\n",
      "mean_20_dow5_2017: 2100.97\n",
      "promo_15: 1496.63\n",
      "promo_1: 1221.01\n",
      "promo_11: 1192.51\n",
      "promo_13: 1006.62\n",
      "promo_2: 935.67\n",
      "promo_3: 893.47\n",
      "promo_4: 889.91\n",
      "promo_10: 383.97\n",
      "promo_6: 322.66\n",
      "promo_12: 298.58\n",
      "promo_5: 285.28\n",
      "promo_8: 141.86\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.326539\tvalid_1's l2: 0.327058\n",
      "[200]\ttraining's l2: 0.322922\tvalid_1's l2: 0.325592\n",
      "[300]\ttraining's l2: 0.320274\tvalid_1's l2: 0.325165\n",
      "[400]\ttraining's l2: 0.318019\tvalid_1's l2: 0.325026\n",
      "[500]\ttraining's l2: 0.316052\tvalid_1's l2: 0.324929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.316052\tvalid_1's l2: 0.324929\n",
      "mean_14_2017: 1448209.85\n",
      "mean_7_2017: 1034578.11\n",
      "mean_30_2017: 246570.90\n",
      "mean_20_dow1_2017: 76170.97\n",
      "mean_60_2017: 75746.98\n",
      "promo_1: 63650.65\n",
      "day_1_2017: 39350.00\n",
      "promo_14_2017: 23420.47\n",
      "mean_3_2017: 21665.46\n",
      "mean_4_dow1_2017: 21049.86\n",
      "mean_20_dow2_2017: 6729.53\n",
      "promo_60_2017: 6611.24\n",
      "mean_20_dow4_2017: 5631.01\n",
      "mean_140_2017: 5613.73\n",
      "mean_4_dow2_2017: 4690.02\n",
      "promo_0: 4369.95\n",
      "promo_140_2017: 4120.99\n",
      "mean_4_dow6_2017: 4081.87\n",
      "mean_4_dow0_2017: 3375.03\n",
      "mean_4_dow4_2017: 3221.22\n",
      "promo_3: 3191.82\n",
      "mean_4_dow5_2017: 2852.68\n",
      "mean_4_dow3_2017: 2762.14\n",
      "mean_20_dow0_2017: 2746.06\n",
      "mean_20_dow5_2017: 2731.84\n",
      "promo_4: 2695.93\n",
      "mean_20_dow6_2017: 2610.67\n",
      "mean_20_dow3_2017: 1957.73\n",
      "promo_2: 1709.55\n",
      "promo_5: 1504.46\n",
      "promo_7: 871.80\n",
      "promo_6: 664.72\n",
      "promo_14: 485.90\n",
      "promo_15: 428.90\n",
      "promo_13: 428.87\n",
      "promo_11: 412.48\n",
      "promo_9: 350.18\n",
      "promo_10: 258.84\n",
      "promo_8: 227.38\n",
      "promo_12: 202.90\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.329214\tvalid_1's l2: 0.341052\n",
      "[200]\ttraining's l2: 0.32491\tvalid_1's l2: 0.339451\n",
      "[300]\ttraining's l2: 0.322012\tvalid_1's l2: 0.33904\n",
      "[400]\ttraining's l2: 0.319586\tvalid_1's l2: 0.338643\n",
      "[500]\ttraining's l2: 0.317454\tvalid_1's l2: 0.338549\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.317454\tvalid_1's l2: 0.338549\n",
      "mean_14_2017: 1844336.16\n",
      "mean_7_2017: 870615.51\n",
      "mean_20_dow2_2017: 250002.09\n",
      "mean_30_2017: 233037.29\n",
      "mean_4_dow2_2017: 193065.36\n",
      "promo_2: 99012.98\n",
      "mean_60_2017: 27003.87\n",
      "promo_14_2017: 24648.98\n",
      "mean_3_2017: 21618.39\n",
      "day_1_2017: 11455.88\n",
      "promo_140_2017: 10046.38\n",
      "promo_60_2017: 9571.91\n",
      "mean_20_dow4_2017: 7756.05\n",
      "promo_9: 6415.80\n",
      "promo_3: 6290.96\n",
      "mean_4_dow0_2017: 5199.39\n",
      "mean_20_dow1_2017: 4937.92\n",
      "mean_4_dow1_2017: 4747.39\n",
      "mean_4_dow3_2017: 4469.99\n",
      "mean_20_dow5_2017: 4268.66\n",
      "promo_0: 4053.77\n",
      "promo_5: 3801.42\n",
      "promo_4: 3494.51\n",
      "promo_7: 3253.06\n",
      "mean_4_dow6_2017: 3084.02\n",
      "mean_4_dow4_2017: 2872.92\n",
      "mean_20_dow0_2017: 2843.14\n",
      "mean_20_dow3_2017: 2753.28\n",
      "mean_4_dow5_2017: 2698.22\n",
      "mean_20_dow6_2017: 2683.80\n",
      "mean_140_2017: 1969.18\n",
      "promo_11: 1916.54\n",
      "promo_1: 1565.68\n",
      "promo_15: 1453.37\n",
      "promo_14: 1262.02\n",
      "promo_10: 1052.03\n",
      "promo_6: 913.07\n",
      "promo_13: 468.25\n",
      "promo_12: 445.72\n",
      "promo_8: 196.02\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.352578\tvalid_1's l2: 0.35456\n",
      "[200]\ttraining's l2: 0.347807\tvalid_1's l2: 0.352866\n",
      "[300]\ttraining's l2: 0.344704\tvalid_1's l2: 0.35252\n",
      "[400]\ttraining's l2: 0.342312\tvalid_1's l2: 0.352494\n",
      "Early stopping, best iteration is:\n",
      "[356]\ttraining's l2: 0.343334\tvalid_1's l2: 0.352445\n",
      "mean_14_2017: 2193691.18\n",
      "mean_7_2017: 618595.48\n",
      "mean_30_2017: 551732.29\n",
      "mean_4_dow3_2017: 297032.53\n",
      "mean_20_dow3_2017: 151857.36\n",
      "mean_60_2017: 143905.27\n",
      "promo_3: 74878.51\n",
      "mean_3_2017: 41209.99\n",
      "mean_4_dow4_2017: 24200.55\n",
      "promo_14_2017: 20086.54\n",
      "day_1_2017: 7849.99\n",
      "promo_60_2017: 7545.86\n",
      "mean_140_2017: 6691.03\n",
      "promo_140_2017: 6578.59\n",
      "promo_5: 5016.34\n",
      "promo_4: 4576.47\n",
      "mean_4_dow2_2017: 4269.24\n",
      "mean_20_dow5_2017: 4133.29\n",
      "mean_20_dow0_2017: 4010.61\n",
      "promo_2: 3671.09\n",
      "promo_7: 3525.20\n",
      "mean_20_dow4_2017: 3435.74\n",
      "mean_20_dow6_2017: 3370.36\n",
      "mean_4_dow0_2017: 3253.79\n",
      "promo_0: 2755.67\n",
      "mean_20_dow2_2017: 2670.18\n",
      "promo_6: 2655.50\n",
      "mean_4_dow6_2017: 2643.84\n",
      "mean_4_dow1_2017: 2137.30\n",
      "promo_1: 1963.74\n",
      "mean_4_dow5_2017: 1929.19\n",
      "mean_20_dow1_2017: 1853.53\n",
      "promo_14: 1328.71\n",
      "promo_9: 1137.47\n",
      "promo_15: 626.27\n",
      "promo_8: 611.44\n",
      "promo_13: 493.24\n",
      "promo_10: 486.88\n",
      "promo_12: 260.55\n",
      "promo_11: 205.27\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.363248\tvalid_1's l2: 0.357485\n",
      "[200]\ttraining's l2: 0.357852\tvalid_1's l2: 0.355829\n",
      "[300]\ttraining's l2: 0.354392\tvalid_1's l2: 0.355065\n",
      "[400]\ttraining's l2: 0.351438\tvalid_1's l2: 0.354843\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's l2: 0.350333\tvalid_1's l2: 0.354789\n",
      "mean_14_2017: 1348136.20\n",
      "mean_4_dow4_2017: 1135127.96\n",
      "mean_7_2017: 628767.41\n",
      "mean_30_2017: 544794.74\n",
      "mean_3_2017: 291791.52\n",
      "mean_20_dow4_2017: 288550.61\n",
      "promo_4: 74505.10\n",
      "mean_60_2017: 44391.35\n",
      "promo_14_2017: 19804.80\n",
      "mean_4_dow3_2017: 18485.98\n",
      "promo_60_2017: 7875.35\n",
      "promo_3: 7643.88\n",
      "promo_5: 7253.32\n",
      "promo_140_2017: 7073.61\n",
      "promo_7: 6861.10\n",
      "day_1_2017: 5987.75\n",
      "mean_20_dow2_2017: 4998.05\n",
      "mean_20_dow1_2017: 4892.12\n",
      "mean_20_dow0_2017: 4735.39\n",
      "promo_6: 4409.29\n",
      "mean_140_2017: 4018.54\n",
      "promo_0: 3825.66\n",
      "promo_2: 3517.27\n",
      "mean_20_dow3_2017: 3413.62\n",
      "mean_4_dow0_2017: 3339.72\n",
      "mean_4_dow5_2017: 2941.74\n",
      "mean_20_dow6_2017: 2861.50\n",
      "mean_4_dow6_2017: 2847.72\n",
      "mean_4_dow2_2017: 2616.75\n",
      "promo_1: 2437.49\n",
      "mean_20_dow5_2017: 2370.19\n",
      "mean_4_dow1_2017: 2346.16\n",
      "promo_11: 2072.60\n",
      "promo_14: 1764.28\n",
      "promo_9: 1456.78\n",
      "promo_15: 918.80\n",
      "promo_10: 786.73\n",
      "promo_13: 699.22\n",
      "promo_8: 599.66\n",
      "promo_12: 548.07\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.356167\tvalid_1's l2: 0.361072\n",
      "[200]\ttraining's l2: 0.35175\tvalid_1's l2: 0.359722\n",
      "[300]\ttraining's l2: 0.348717\tvalid_1's l2: 0.35919\n",
      "[400]\ttraining's l2: 0.346237\tvalid_1's l2: 0.359004\n",
      "[500]\ttraining's l2: 0.343935\tvalid_1's l2: 0.358917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.343935\tvalid_1's l2: 0.358917\n",
      "mean_14_2017: 1303577.54\n",
      "mean_30_2017: 1131578.58\n",
      "mean_7_2017: 302367.52\n",
      "mean_3_2017: 250064.05\n",
      "mean_60_2017: 199236.34\n",
      "mean_20_dow5_2017: 83861.17\n",
      "promo_5: 80457.60\n",
      "mean_4_dow5_2017: 61891.13\n",
      "promo_14_2017: 19933.21\n",
      "promo_3: 11460.40\n",
      "mean_4_dow6_2017: 9766.39\n",
      "day_1_2017: 8574.87\n",
      "promo_60_2017: 8078.56\n",
      "promo_7: 7718.19\n",
      "mean_140_2017: 6770.88\n",
      "mean_20_dow6_2017: 6236.08\n",
      "promo_6: 5804.02\n",
      "promo_140_2017: 4630.49\n",
      "mean_4_dow0_2017: 4040.13\n",
      "mean_20_dow0_2017: 4017.73\n",
      "mean_20_dow3_2017: 3928.91\n",
      "mean_20_dow2_2017: 3831.69\n",
      "mean_4_dow2_2017: 3615.73\n",
      "mean_4_dow1_2017: 3322.85\n",
      "mean_4_dow4_2017: 3293.49\n",
      "mean_4_dow3_2017: 3278.24\n",
      "mean_20_dow4_2017: 3100.54\n",
      "mean_20_dow1_2017: 2860.49\n",
      "promo_0: 2825.76\n",
      "promo_4: 2754.35\n",
      "promo_2: 2413.23\n",
      "promo_9: 1986.25\n",
      "promo_14: 1224.92\n",
      "promo_1: 1187.60\n",
      "promo_13: 1029.54\n",
      "promo_12: 1027.71\n",
      "promo_8: 903.58\n",
      "promo_11: 683.05\n",
      "promo_10: 585.70\n",
      "promo_15: 583.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346219\tvalid_1's l2: 0.421254\n",
      "[200]\ttraining's l2: 0.341874\tvalid_1's l2: 0.420923\n",
      "[300]\ttraining's l2: 0.339035\tvalid_1's l2: 0.420617\n",
      "[400]\ttraining's l2: 0.336652\tvalid_1's l2: 0.420437\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's l2: 0.336799\tvalid_1's l2: 0.420378\n",
      "mean_14_2017: 1274004.42\n",
      "mean_30_2017: 842088.63\n",
      "mean_7_2017: 445757.89\n",
      "mean_20_dow6_2017: 152802.16\n",
      "mean_3_2017: 145241.24\n",
      "promo_6: 128192.88\n",
      "mean_4_dow6_2017: 127503.94\n",
      "mean_60_2017: 123326.90\n",
      "promo_14_2017: 21944.55\n",
      "day_1_2017: 13872.06\n",
      "promo_3: 11205.46\n",
      "promo_7: 9013.03\n",
      "mean_4_dow5_2017: 8533.91\n",
      "mean_20_dow5_2017: 8280.78\n",
      "promo_60_2017: 8112.57\n",
      "promo_140_2017: 6018.04\n",
      "mean_20_dow1_2017: 4884.13\n",
      "promo_5: 4487.41\n",
      "mean_140_2017: 4382.31\n",
      "promo_13: 3877.01\n",
      "mean_4_dow0_2017: 3650.61\n",
      "mean_20_dow0_2017: 3639.82\n",
      "mean_20_dow3_2017: 3507.37\n",
      "mean_4_dow1_2017: 3355.21\n",
      "mean_20_dow4_2017: 2943.12\n",
      "promo_4: 2784.87\n",
      "promo_0: 2663.62\n",
      "mean_20_dow2_2017: 2644.47\n",
      "mean_4_dow2_2017: 2643.06\n",
      "mean_4_dow3_2017: 2399.89\n",
      "promo_9: 2205.45\n",
      "promo_14: 1995.35\n",
      "mean_4_dow4_2017: 1944.32\n",
      "promo_2: 1500.32\n",
      "promo_1: 1481.22\n",
      "promo_15: 1358.07\n",
      "promo_11: 887.39\n",
      "promo_12: 561.75\n",
      "promo_8: 539.82\n",
      "promo_10: 490.10\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.332499\tvalid_1's l2: 0.3901\n",
      "[200]\ttraining's l2: 0.328261\tvalid_1's l2: 0.388965\n",
      "[300]\ttraining's l2: 0.325429\tvalid_1's l2: 0.388761\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttraining's l2: 0.326174\tvalid_1's l2: 0.388646\n",
      "mean_14_2017: 1106650.36\n",
      "mean_30_2017: 1087192.69\n",
      "mean_7_2017: 596975.54\n",
      "mean_20_dow0_2017: 196265.21\n",
      "promo_7: 180889.57\n",
      "mean_60_2017: 149108.93\n",
      "mean_4_dow0_2017: 59661.14\n",
      "promo_0: 24773.90\n",
      "mean_3_2017: 19984.01\n",
      "day_1_2017: 19142.77\n",
      "promo_60_2017: 12051.84\n",
      "promo_14_2017: 11689.01\n",
      "promo_14: 10283.65\n",
      "promo_140_2017: 8424.10\n",
      "mean_140_2017: 6395.53\n",
      "mean_20_dow2_2017: 5494.71\n",
      "promo_3: 5488.24\n",
      "mean_20_dow4_2017: 5169.59\n",
      "promo_5: 3575.89\n",
      "promo_6: 3298.34\n",
      "promo_9: 2789.02\n",
      "mean_20_dow1_2017: 2684.71\n",
      "mean_4_dow6_2017: 2653.59\n",
      "mean_4_dow5_2017: 2642.93\n",
      "mean_20_dow3_2017: 2642.15\n",
      "mean_4_dow2_2017: 2252.18\n",
      "promo_15: 2080.63\n",
      "mean_20_dow6_2017: 2018.39\n",
      "mean_4_dow1_2017: 1985.10\n",
      "mean_20_dow5_2017: 1841.53\n",
      "promo_4: 1812.55\n",
      "mean_4_dow3_2017: 1717.08\n",
      "mean_4_dow4_2017: 1650.89\n",
      "promo_2: 1599.33\n",
      "promo_10: 1283.18\n",
      "promo_13: 1050.84\n",
      "promo_8: 818.48\n",
      "promo_11: 786.91\n",
      "promo_1: 669.08\n",
      "promo_12: 425.68\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.342053\tvalid_1's l2: 0.380461\n",
      "[200]\ttraining's l2: 0.337877\tvalid_1's l2: 0.379403\n",
      "[300]\ttraining's l2: 0.335103\tvalid_1's l2: 0.379123\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's l2: 0.336014\tvalid_1's l2: 0.379038\n",
      "mean_30_2017: 1092411.90\n",
      "mean_14_2017: 753255.06\n",
      "mean_7_2017: 476090.43\n",
      "mean_60_2017: 246076.66\n",
      "mean_20_dow1_2017: 107659.48\n",
      "promo_8: 103259.44\n",
      "mean_4_dow1_2017: 19937.01\n",
      "promo_10: 18003.13\n",
      "promo_14_2017: 16924.71\n",
      "day_1_2017: 16452.21\n",
      "promo_60_2017: 11142.17\n",
      "mean_3_2017: 10494.91\n",
      "mean_20_dow2_2017: 8645.64\n",
      "promo_7: 8064.94\n",
      "mean_20_dow4_2017: 5020.41\n",
      "promo_140_2017: 4773.47\n",
      "promo_11: 4275.66\n",
      "promo_12: 3589.55\n",
      "mean_20_dow0_2017: 3160.99\n",
      "promo_13: 2958.70\n",
      "mean_140_2017: 2897.43\n",
      "mean_4_dow0_2017: 2787.90\n",
      "promo_9: 2689.16\n",
      "mean_4_dow2_2017: 2528.49\n",
      "mean_4_dow6_2017: 2503.01\n",
      "promo_0: 2205.36\n",
      "mean_20_dow6_2017: 2051.10\n",
      "mean_4_dow4_2017: 1838.41\n",
      "mean_4_dow5_2017: 1770.93\n",
      "mean_20_dow5_2017: 1756.49\n",
      "promo_3: 1621.72\n",
      "mean_4_dow3_2017: 1592.52\n",
      "promo_14: 1571.90\n",
      "mean_20_dow3_2017: 1467.83\n",
      "promo_6: 1083.55\n",
      "promo_4: 1073.11\n",
      "promo_2: 681.96\n",
      "promo_5: 494.89\n",
      "promo_15: 463.49\n",
      "promo_1: 419.76\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346249\tvalid_1's l2: 0.369277\n",
      "[200]\ttraining's l2: 0.341552\tvalid_1's l2: 0.368489\n",
      "[300]\ttraining's l2: 0.338254\tvalid_1's l2: 0.367977\n",
      "[400]\ttraining's l2: 0.335535\tvalid_1's l2: 0.367602\n",
      "Early stopping, best iteration is:\n",
      "[426]\ttraining's l2: 0.334919\tvalid_1's l2: 0.367499\n",
      "mean_30_2017: 1109135.07\n",
      "mean_14_2017: 898740.33\n",
      "mean_7_2017: 455556.40\n",
      "mean_20_dow2_2017: 370696.90\n",
      "mean_4_dow2_2017: 305486.76\n",
      "promo_9: 126542.69\n",
      "mean_60_2017: 69547.55\n",
      "promo_14_2017: 22015.36\n",
      "promo_10: 14619.81\n",
      "promo_140_2017: 12875.57\n",
      "promo_2: 11529.68\n",
      "promo_60_2017: 10979.04\n",
      "mean_3_2017: 10953.05\n",
      "promo_7: 9486.41\n",
      "day_1_2017: 7823.74\n",
      "mean_20_dow4_2017: 7736.48\n",
      "promo_8: 6789.34\n",
      "mean_20_dow1_2017: 6282.70\n",
      "mean_4_dow1_2017: 5402.74\n",
      "promo_14: 5226.53\n",
      "mean_20_dow5_2017: 4596.57\n",
      "mean_4_dow0_2017: 4021.87\n",
      "mean_4_dow3_2017: 3921.97\n",
      "promo_12: 3788.84\n",
      "mean_20_dow0_2017: 3780.37\n",
      "promo_11: 3143.47\n",
      "mean_20_dow3_2017: 3112.16\n",
      "mean_4_dow6_2017: 3027.64\n",
      "mean_140_2017: 3010.47\n",
      "mean_4_dow4_2017: 2729.70\n",
      "promo_13: 2729.64\n",
      "mean_20_dow6_2017: 2720.09\n",
      "mean_4_dow5_2017: 2430.24\n",
      "promo_6: 1390.16\n",
      "promo_4: 1204.69\n",
      "promo_0: 1123.38\n",
      "promo_1: 934.92\n",
      "promo_15: 901.80\n",
      "promo_3: 468.56\n",
      "promo_5: 299.24\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.374554\tvalid_1's l2: 0.37475\n",
      "[200]\ttraining's l2: 0.369094\tvalid_1's l2: 0.373093\n",
      "[300]\ttraining's l2: 0.3657\tvalid_1's l2: 0.372889\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's l2: 0.367225\tvalid_1's l2: 0.372871\n",
      "mean_30_2017: 1557331.99\n",
      "mean_14_2017: 731428.08\n",
      "mean_7_2017: 608635.02\n",
      "mean_60_2017: 369698.24\n",
      "mean_4_dow3_2017: 278647.67\n",
      "mean_20_dow3_2017: 194588.29\n",
      "promo_10: 106197.71\n",
      "mean_3_2017: 16427.10\n",
      "promo_14_2017: 15868.17\n",
      "mean_4_dow4_2017: 14618.03\n",
      "mean_4_dow2_2017: 10881.47\n",
      "promo_60_2017: 10271.67\n",
      "mean_140_2017: 7499.64\n",
      "promo_140_2017: 7024.09\n",
      "promo_14: 6975.73\n",
      "promo_9: 5837.04\n",
      "promo_7: 5810.41\n",
      "day_1_2017: 5059.51\n",
      "promo_12: 4976.80\n",
      "promo_11: 4931.67\n",
      "mean_20_dow0_2017: 4411.60\n",
      "mean_20_dow5_2017: 4364.08\n",
      "promo_13: 3983.01\n",
      "mean_20_dow2_2017: 3850.59\n",
      "mean_20_dow4_2017: 3281.31\n",
      "mean_4_dow0_2017: 3146.40\n",
      "mean_20_dow6_2017: 3026.25\n",
      "promo_8: 3004.82\n",
      "mean_20_dow1_2017: 2430.94\n",
      "mean_4_dow1_2017: 2023.36\n",
      "promo_3: 2009.26\n",
      "mean_4_dow6_2017: 1653.60\n",
      "mean_4_dow5_2017: 1564.46\n",
      "promo_6: 1205.97\n",
      "promo_0: 1141.93\n",
      "promo_15: 998.07\n",
      "promo_4: 774.89\n",
      "promo_2: 521.36\n",
      "promo_5: 477.40\n",
      "promo_1: 279.25\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.384726\tvalid_1's l2: 0.386245\n",
      "[200]\ttraining's l2: 0.379048\tvalid_1's l2: 0.384677\n",
      "[300]\ttraining's l2: 0.375455\tvalid_1's l2: 0.384401\n",
      "[400]\ttraining's l2: 0.372435\tvalid_1's l2: 0.384356\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's l2: 0.372056\tvalid_1's l2: 0.384323\n",
      "mean_4_dow4_2017: 1370672.62\n",
      "mean_30_2017: 1347811.60\n",
      "mean_14_2017: 519317.28\n",
      "mean_20_dow4_2017: 286536.47\n",
      "mean_60_2017: 203990.63\n",
      "mean_7_2017: 183990.03\n",
      "mean_3_2017: 105880.57\n",
      "promo_11: 94981.40\n",
      "mean_4_dow3_2017: 17981.50\n",
      "promo_14_2017: 15931.04\n",
      "promo_12: 13676.55\n",
      "promo_14: 11691.97\n",
      "promo_10: 9251.36\n",
      "promo_60_2017: 9175.17\n",
      "promo_140_2017: 8938.17\n",
      "mean_140_2017: 7198.99\n",
      "promo_13: 6796.57\n",
      "promo_9: 6049.79\n",
      "promo_4: 5491.69\n",
      "mean_20_dow0_2017: 5409.09\n",
      "day_1_2017: 4989.87\n",
      "promo_7: 4847.85\n",
      "mean_20_dow3_2017: 4446.33\n",
      "mean_20_dow1_2017: 4233.39\n",
      "mean_20_dow2_2017: 4034.11\n",
      "mean_20_dow6_2017: 3841.08\n",
      "mean_4_dow0_2017: 3452.07\n",
      "promo_8: 3367.92\n",
      "mean_20_dow5_2017: 3116.02\n",
      "mean_4_dow5_2017: 2736.23\n",
      "mean_4_dow6_2017: 2651.79\n",
      "mean_4_dow1_2017: 2500.66\n",
      "mean_4_dow2_2017: 2434.76\n",
      "promo_0: 1786.93\n",
      "promo_15: 1146.94\n",
      "promo_6: 1010.45\n",
      "promo_2: 829.46\n",
      "promo_3: 708.15\n",
      "promo_1: 546.59\n",
      "promo_5: 373.83\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.370343\tvalid_1's l2: 0.377148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's l2: 0.365615\tvalid_1's l2: 0.376333\n",
      "[300]\ttraining's l2: 0.362327\tvalid_1's l2: 0.376258\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's l2: 0.361236\tvalid_1's l2: 0.37609\n",
      "mean_30_2017: 1601076.04\n",
      "mean_14_2017: 588977.50\n",
      "mean_60_2017: 374936.35\n",
      "mean_7_2017: 305452.67\n",
      "mean_3_2017: 148957.18\n",
      "promo_12: 93518.03\n",
      "mean_20_dow5_2017: 85159.77\n",
      "mean_4_dow5_2017: 71638.34\n",
      "promo_13: 19595.91\n",
      "promo_14_2017: 16011.22\n",
      "promo_14: 13355.62\n",
      "promo_10: 11265.36\n",
      "mean_140_2017: 9927.43\n",
      "promo_60_2017: 8798.33\n",
      "day_1_2017: 7950.62\n",
      "mean_20_dow0_2017: 7544.02\n",
      "promo_140_2017: 6088.78\n",
      "mean_20_dow6_2017: 5888.75\n",
      "mean_4_dow6_2017: 4725.31\n",
      "promo_11: 4479.14\n",
      "mean_4_dow0_2017: 3756.38\n",
      "mean_20_dow3_2017: 3664.43\n",
      "promo_9: 3613.91\n",
      "mean_20_dow2_2017: 3341.99\n",
      "mean_4_dow2_2017: 2714.48\n",
      "mean_20_dow1_2017: 2701.22\n",
      "mean_4_dow3_2017: 2566.89\n",
      "mean_20_dow4_2017: 2531.39\n",
      "promo_15: 2495.30\n",
      "mean_4_dow1_2017: 2301.79\n",
      "mean_4_dow4_2017: 2274.90\n",
      "promo_7: 2189.77\n",
      "promo_0: 1734.63\n",
      "promo_8: 1699.81\n",
      "promo_5: 1614.77\n",
      "promo_6: 1073.19\n",
      "promo_3: 698.78\n",
      "promo_2: 632.31\n",
      "promo_4: 552.65\n",
      "promo_1: 360.10\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.359483\tvalid_1's l2: 0.362315\n",
      "[200]\ttraining's l2: 0.355317\tvalid_1's l2: 0.361333\n",
      "[300]\ttraining's l2: 0.352142\tvalid_1's l2: 0.36116\n",
      "Early stopping, best iteration is:\n",
      "[341]\ttraining's l2: 0.351057\tvalid_1's l2: 0.361093\n",
      "mean_30_2017: 1503900.26\n",
      "mean_14_2017: 474406.75\n",
      "mean_60_2017: 314928.82\n",
      "mean_7_2017: 302522.14\n",
      "mean_20_dow6_2017: 195214.67\n",
      "promo_13: 161942.26\n",
      "mean_3_2017: 85260.13\n",
      "mean_4_dow6_2017: 72570.04\n",
      "day_1_2017: 20138.75\n",
      "promo_14_2017: 16401.63\n",
      "mean_4_dow5_2017: 12323.03\n",
      "mean_140_2017: 10016.33\n",
      "promo_60_2017: 9711.48\n",
      "promo_14: 9682.72\n",
      "mean_20_dow5_2017: 9004.62\n",
      "promo_10: 8366.20\n",
      "mean_20_dow1_2017: 8346.93\n",
      "promo_140_2017: 6622.02\n",
      "mean_20_dow0_2017: 6016.06\n",
      "promo_12: 5934.91\n",
      "promo_6: 5761.74\n",
      "mean_4_dow0_2017: 3712.35\n",
      "promo_0: 3489.70\n",
      "mean_20_dow3_2017: 3159.65\n",
      "promo_9: 3117.09\n",
      "mean_4_dow1_2017: 3018.32\n",
      "mean_20_dow4_2017: 3011.37\n",
      "promo_11: 2944.78\n",
      "mean_4_dow3_2017: 2494.32\n",
      "mean_20_dow2_2017: 2399.85\n",
      "promo_15: 2280.65\n",
      "mean_4_dow4_2017: 2222.69\n",
      "mean_4_dow2_2017: 2216.53\n",
      "promo_7: 1696.63\n",
      "promo_8: 1501.73\n",
      "promo_2: 999.87\n",
      "promo_4: 820.73\n",
      "promo_1: 501.61\n",
      "promo_3: 407.76\n",
      "promo_5: 358.07\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346946\tvalid_1's l2: 0.349058\n",
      "[200]\ttraining's l2: 0.342413\tvalid_1's l2: 0.348041\n",
      "[300]\ttraining's l2: 0.339349\tvalid_1's l2: 0.347827\n",
      "[400]\ttraining's l2: 0.336694\tvalid_1's l2: 0.347475\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's l2: 0.33672\tvalid_1's l2: 0.34747\n",
      "mean_30_2017: 1510783.19\n",
      "mean_14_2017: 661347.37\n",
      "mean_7_2017: 392564.07\n",
      "mean_20_dow0_2017: 270349.76\n",
      "promo_14: 195765.80\n",
      "mean_60_2017: 174312.36\n",
      "mean_4_dow0_2017: 66182.47\n",
      "day_1_2017: 16736.14\n",
      "promo_7: 16376.36\n",
      "promo_14_2017: 15451.42\n",
      "promo_0: 13747.98\n",
      "mean_3_2017: 13730.83\n",
      "promo_60_2017: 13529.07\n",
      "promo_140_2017: 11707.14\n",
      "promo_13: 9827.58\n",
      "mean_20_dow2_2017: 9398.45\n",
      "mean_140_2017: 8178.01\n",
      "mean_20_dow4_2017: 6067.88\n",
      "promo_12: 6001.85\n",
      "promo_10: 5328.53\n",
      "mean_4_dow2_2017: 4731.33\n",
      "mean_20_dow1_2017: 3872.20\n",
      "promo_15: 3755.41\n",
      "promo_9: 3747.19\n",
      "mean_4_dow6_2017: 3585.10\n",
      "mean_20_dow6_2017: 3221.57\n",
      "mean_4_dow5_2017: 3192.25\n",
      "mean_4_dow1_2017: 3056.25\n",
      "mean_20_dow3_2017: 2992.33\n",
      "mean_4_dow4_2017: 2629.42\n",
      "promo_2: 2543.41\n",
      "mean_20_dow5_2017: 2500.39\n",
      "mean_4_dow3_2017: 2457.65\n",
      "promo_11: 2145.44\n",
      "promo_6: 1194.59\n",
      "promo_8: 1055.05\n",
      "promo_4: 1027.53\n",
      "promo_3: 616.03\n",
      "promo_1: 480.42\n",
      "promo_5: 274.91\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.357487\tvalid_1's l2: 0.372593\n",
      "[200]\ttraining's l2: 0.353175\tvalid_1's l2: 0.371423\n",
      "[300]\ttraining's l2: 0.350209\tvalid_1's l2: 0.370966\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's l2: 0.349009\tvalid_1's l2: 0.370807\n",
      "mean_30_2017: 1454305.00\n",
      "mean_14_2017: 454926.74\n",
      "mean_60_2017: 383159.89\n",
      "mean_7_2017: 217745.33\n",
      "promo_15: 134065.70\n",
      "mean_20_dow1_2017: 109875.66\n",
      "mean_4_dow1_2017: 17102.93\n",
      "day_1_2017: 15830.99\n",
      "mean_20_dow2_2017: 15117.27\n",
      "promo_14_2017: 12513.41\n",
      "promo_60_2017: 11584.19\n",
      "mean_3_2017: 9211.26\n",
      "promo_14: 7912.86\n",
      "promo_140_2017: 7691.20\n",
      "mean_140_2017: 6309.34\n",
      "mean_20_dow4_2017: 5575.79\n",
      "mean_20_dow0_2017: 5231.27\n",
      "mean_4_dow0_2017: 3421.06\n",
      "promo_10: 3212.28\n",
      "mean_4_dow6_2017: 2855.52\n",
      "mean_4_dow2_2017: 2697.58\n",
      "mean_20_dow6_2017: 2494.24\n",
      "promo_13: 2474.50\n",
      "mean_4_dow3_2017: 2419.15\n",
      "mean_4_dow4_2017: 2402.11\n",
      "mean_20_dow5_2017: 2367.49\n",
      "mean_4_dow5_2017: 2280.71\n",
      "promo_12: 2128.19\n",
      "mean_20_dow3_2017: 2065.58\n",
      "promo_7: 1789.05\n",
      "promo_0: 1498.76\n",
      "promo_11: 1486.70\n",
      "promo_9: 1379.17\n",
      "promo_8: 992.07\n",
      "promo_6: 831.67\n",
      "promo_1: 700.04\n",
      "promo_2: 687.44\n",
      "promo_4: 642.91\n",
      "promo_3: 451.08\n",
      "promo_5: 326.33\n",
      "Validation mse: 0.3623709264044814\n",
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    TrainData, usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    TestData, usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    ItemsPath,\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "\n",
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        \"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        \"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 31)\n",
    "X_l, y_l = [], []\n",
    "for i in range(6):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n",
    "\n",
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 300,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 500\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=100\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n",
    "\n",
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 275.7862813287468\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    np.expm1(y_validate), np.expm1(np.array(validate_pred)).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.583123951777, 15.716233645501712)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(275), np.sqrt(247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
