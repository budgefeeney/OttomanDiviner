{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This is a clone of the script at https://www.kaggle.com/ceshine/lgbm-starter which is intended to give an idea of how to structure the data for trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelude "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataSetPath = \"/home/bryanfeeney/Workspace/OttomanDiviner/favorita/\"\n",
    "\n",
    "StoresPath   = DataSetPath + \"stores.csv.gz\"\n",
    "ItemsPath    = DataSetPath + \"items.csv.gz\"\n",
    "OilPricePath = DataSetPath + \"oil.csv.gz\"\n",
    "HolidaysPath = DataSetPath + \"holidays_events.csv.gz\"\n",
    "Transactions = DataSetPath + \"transactions.csv.gz\"\n",
    "# TrainData    = DataSetPath + \"train-2017.csv.gz\"\n",
    "# TestData     = DataSetPath + \"test.csv.gz\"\n",
    "TrainData    = DataSetPath + \"train-2018.csv.gz\"\n",
    "TestData     = DataSetPath + \"query-2018.csv\"\n",
    "\n",
    "FutureDaysToCalculate=16\n",
    "WeeksOfHistoryForFeature=8\n",
    "WeeksOfHistoryForFeatureOnValidation=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul_sales = pd.read_csv(\n",
    "    TrainData, \n",
    "    usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    compression='gzip'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cumul_sales_query = pd.read_csv(\n",
    "    TestData,\n",
    "    usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_start_date = str(cumul_sales_query.iloc[0,1]).split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-05-26'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumul_sales_query = cumul_sales_query.set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">DEBUG</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>103520</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829647</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829648</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829649</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829650</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105857</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829651</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108079</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829652</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108696</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108698</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829654</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108701</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829655</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108797</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829656</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111223</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829657</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111397</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829658</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114790</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829659</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115267</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829660</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115720</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829661</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115892</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115893</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829663</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116017</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829664</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116018</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829665</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119026</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829666</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119141</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119624</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829668</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122095</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829669</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129297</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829670</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129635</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829671</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129758</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829672</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153078</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829673</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153239</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829674</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153267</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829675</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155610</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829676</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th>2048471</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439082</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048515</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439083</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048674</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439084</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049778</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439085</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053874</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439086</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054101</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439087</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054291</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439088</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054635</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439089</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056557</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439090</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057033</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439091</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057442</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439092</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058758</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439093</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059342</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439094</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059647</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439095</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060793</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439096</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061404</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439097</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061781</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439098</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067056</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439099</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081056</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081064</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439101</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081095</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439102</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081161</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439103</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084557</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086882</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087374</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087933</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439107</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087978</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439108</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088922</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089339</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439110</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103250</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439111</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609465 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  onpromotion\n",
       "store_nbr item_nbr date                              \n",
       "1         103520   2018-05-26  116829647        False\n",
       "          103665   2018-05-26  116829648        False\n",
       "          105574   2018-05-26  116829649        False\n",
       "          105575   2018-05-26  116829650        False\n",
       "          105857   2018-05-26  116829651        False\n",
       "          108079   2018-05-26  116829652        False\n",
       "          108696   2018-05-26  116829653         True\n",
       "          108698   2018-05-26  116829654         True\n",
       "          108701   2018-05-26  116829655         True\n",
       "          108797   2018-05-26  116829656        False\n",
       "          111223   2018-05-26  116829657        False\n",
       "          111397   2018-05-26  116829658         True\n",
       "          114790   2018-05-26  116829659        False\n",
       "          115267   2018-05-26  116829660        False\n",
       "          115720   2018-05-26  116829661        False\n",
       "          115892   2018-05-26  116829662        False\n",
       "          115893   2018-05-26  116829663        False\n",
       "          116017   2018-05-26  116829664        False\n",
       "          116018   2018-05-26  116829665        False\n",
       "          119026   2018-05-26  116829666        False\n",
       "          119141   2018-05-26  116829667        False\n",
       "          119624   2018-05-26  116829668         True\n",
       "          122095   2018-05-26  116829669         True\n",
       "          129297   2018-05-26  116829670        False\n",
       "          129635   2018-05-26  116829671        False\n",
       "          129758   2018-05-26  116829672        False\n",
       "          153078   2018-05-26  116829673        False\n",
       "          153239   2018-05-26  116829674        False\n",
       "          153267   2018-05-26  116829675        False\n",
       "          155610   2018-05-26  116829676         True\n",
       "...                                  ...          ...\n",
       "54        2048471  2018-06-09  118439082        False\n",
       "          2048515  2018-06-09  118439083        False\n",
       "          2048674  2018-06-09  118439084        False\n",
       "          2049778  2018-06-09  118439085        False\n",
       "          2053874  2018-06-09  118439086        False\n",
       "          2054101  2018-06-09  118439087        False\n",
       "          2054291  2018-06-09  118439088        False\n",
       "          2054635  2018-06-09  118439089        False\n",
       "          2056557  2018-06-09  118439090        False\n",
       "          2057033  2018-06-09  118439091        False\n",
       "          2057442  2018-06-09  118439092        False\n",
       "          2058758  2018-06-09  118439093         True\n",
       "          2059342  2018-06-09  118439094         True\n",
       "          2059647  2018-06-09  118439095        False\n",
       "          2060793  2018-06-09  118439096        False\n",
       "          2061404  2018-06-09  118439097        False\n",
       "          2061781  2018-06-09  118439098        False\n",
       "          2067056  2018-06-09  118439099        False\n",
       "          2081056  2018-06-09  118439100        False\n",
       "          2081064  2018-06-09  118439101        False\n",
       "          2081095  2018-06-09  118439102        False\n",
       "          2081161  2018-06-09  118439103        False\n",
       "          2084557  2018-06-09  118439104         True\n",
       "          2086882  2018-06-09  118439105        False\n",
       "          2087374  2018-06-09  118439106        False\n",
       "          2087933  2018-06-09  118439107        False\n",
       "          2087978  2018-06-09  118439108        False\n",
       "          2088922  2018-06-09  118439109        False\n",
       "          2089339  2018-06-09  118439110        False\n",
       "          2103250  2018-06-09  118439111         True\n",
       "\n",
       "[1609465 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_variables_test = cumul_sales_query[[\"onpromotion\"]].unstack(level=-1).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>DEBUG</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           2018-08-15 00:00:00\n",
       "store_nbr                       54\n",
       "item_nbr                   2116416\n",
       "unit_sales                 1.09861\n",
       "onpromotion                  False\n",
       "Name: 23808259, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             116829647\n",
       "onpromotion        False\n",
       "Name: (1, 103520, 2018-05-26 00:00:00), dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales_query.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    ItemsPath,\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    StoresPath\n",
    ").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>103520</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829647</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829648</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829649</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829650</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105857</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829651</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108079</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829652</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108696</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108698</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829654</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108701</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829655</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108797</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829656</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111223</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829657</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111397</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829658</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114790</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829659</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115267</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829660</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115720</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829661</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115892</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115893</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829663</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116017</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829664</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116018</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829665</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119026</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829666</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119141</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119624</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829668</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122095</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829669</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129297</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829670</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129635</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829671</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129758</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829672</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153078</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829673</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153239</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829674</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153267</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829675</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155610</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>116829676</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th>2048471</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439082</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048515</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439083</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048674</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439084</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049778</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439085</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053874</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439086</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054101</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439087</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054291</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439088</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054635</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439089</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056557</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439090</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057033</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439091</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057442</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439092</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058758</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439093</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059342</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439094</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059647</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439095</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060793</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439096</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061404</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439097</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061781</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439098</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067056</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439099</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081056</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081064</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439101</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081095</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439102</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081161</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439103</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084557</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086882</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087374</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087933</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439107</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087978</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439108</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088922</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089339</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439110</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103250</th>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>118439111</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609465 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  onpromotion\n",
       "store_nbr item_nbr date                              \n",
       "1         103520   2018-05-26  116829647        False\n",
       "          103665   2018-05-26  116829648        False\n",
       "          105574   2018-05-26  116829649        False\n",
       "          105575   2018-05-26  116829650        False\n",
       "          105857   2018-05-26  116829651        False\n",
       "          108079   2018-05-26  116829652        False\n",
       "          108696   2018-05-26  116829653         True\n",
       "          108698   2018-05-26  116829654         True\n",
       "          108701   2018-05-26  116829655         True\n",
       "          108797   2018-05-26  116829656        False\n",
       "          111223   2018-05-26  116829657        False\n",
       "          111397   2018-05-26  116829658         True\n",
       "          114790   2018-05-26  116829659        False\n",
       "          115267   2018-05-26  116829660        False\n",
       "          115720   2018-05-26  116829661        False\n",
       "          115892   2018-05-26  116829662        False\n",
       "          115893   2018-05-26  116829663        False\n",
       "          116017   2018-05-26  116829664        False\n",
       "          116018   2018-05-26  116829665        False\n",
       "          119026   2018-05-26  116829666        False\n",
       "          119141   2018-05-26  116829667        False\n",
       "          119624   2018-05-26  116829668         True\n",
       "          122095   2018-05-26  116829669         True\n",
       "          129297   2018-05-26  116829670        False\n",
       "          129635   2018-05-26  116829671        False\n",
       "          129758   2018-05-26  116829672        False\n",
       "          153078   2018-05-26  116829673        False\n",
       "          153239   2018-05-26  116829674        False\n",
       "          153267   2018-05-26  116829675        False\n",
       "          155610   2018-05-26  116829676         True\n",
       "...                                  ...          ...\n",
       "54        2048471  2018-06-09  118439082        False\n",
       "          2048515  2018-06-09  118439083        False\n",
       "          2048674  2018-06-09  118439084        False\n",
       "          2049778  2018-06-09  118439085        False\n",
       "          2053874  2018-06-09  118439086        False\n",
       "          2054101  2018-06-09  118439087        False\n",
       "          2054291  2018-06-09  118439088        False\n",
       "          2054635  2018-06-09  118439089        False\n",
       "          2056557  2018-06-09  118439090        False\n",
       "          2057033  2018-06-09  118439091        False\n",
       "          2057442  2018-06-09  118439092        False\n",
       "          2058758  2018-06-09  118439093         True\n",
       "          2059342  2018-06-09  118439094         True\n",
       "          2059647  2018-06-09  118439095        False\n",
       "          2060793  2018-06-09  118439096        False\n",
       "          2061404  2018-06-09  118439097        False\n",
       "          2061781  2018-06-09  118439098        False\n",
       "          2067056  2018-06-09  118439099        False\n",
       "          2081056  2018-06-09  118439100        False\n",
       "          2081064  2018-06-09  118439101        False\n",
       "          2081095  2018-06-09  118439102        False\n",
       "          2081161  2018-06-09  118439103        False\n",
       "          2084557  2018-06-09  118439104         True\n",
       "          2086882  2018-06-09  118439105        False\n",
       "          2087374  2018-06-09  118439106        False\n",
       "          2087933  2018-06-09  118439107        False\n",
       "          2087978  2018-06-09  118439108        False\n",
       "          2088922  2018-06-09  118439109        False\n",
       "          2089339  2018-06-09  118439110        False\n",
       "          2103250  2018-06-09  118439111         True\n",
       "\n",
       "[1609465 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23808260, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1609465, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4100, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only Last Three Months\n",
    "\n",
    "This is a peculiar one, and it **games the benchmark** in a not great way. Essentially it uses the last 11 weeks of data before the prediction threshold to predict what's happening next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nowtime = datetime.now()\n",
    "now = date(nowtime.year, nowtime.month, nowtime.day)\n",
    "\n",
    "# How far back to go to start generating trend features for demand\n",
    "data_start             = now - timedelta(7*11) + timedelta(1)\n",
    "training_history_start = now - timedelta(7*WeeksOfHistoryForFeature) + timedelta(1)\n",
    "validation_start       = now - timedelta(7*WeeksOfHistoryForFeatureOnValidation) + timedelta(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2018, 3, 10), datetime.date(2018, 3, 31), '2018-05-26')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_start, training_history_start, query_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumul_sales = cumul_sales[cumul_sales.date.isin(\n",
    "    pd.date_range(data_start, periods=7 * 11))].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7024144</th>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>103520</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024145</th>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>103665</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024146</th>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>105574</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024147</th>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>105575</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024148</th>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>105693</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "7024144 2018-03-10          1    103520    0.693147        False\n",
       "7024145 2018-03-10          1    103665    1.386294        False\n",
       "7024146 2018-03-10          1    105574    2.397895        False\n",
       "7024147 2018-03-10          1    105575    2.079442        False\n",
       "7024148 2018-03-10          1    105693    1.098612        False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8116723, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           2018-05-25 00:00:00\n",
       "store_nbr                       54\n",
       "item_nbr                   2108569\n",
       "unit_sales                0.693147\n",
       "onpromotion                  False\n",
       "Name: 15140866, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Promotion Variables\n",
    "\n",
    "So this is a tricky. If one presumes that on-promotion will lead to a boost in demand, if if we presume we'll know *whats on promotion in advance*, then we can create variables to say that this product will be on promotion 1, 2, 3, ... 16 days from now (16 days in the future is the target)\n",
    "\n",
    "In this case, this is also peculiar, there is a column for every single day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_variables = cumul_sales.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>103520</th>\n",
       "      <th>2018-03-10</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2018-03-10</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2018-03-10</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <th>2018-03-10</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105693</th>\n",
       "      <th>2018-03-10</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               onpromotion\n",
       "store_nbr item_nbr date                   \n",
       "1         103520   2018-03-10        False\n",
       "          103665   2018-03-10        False\n",
       "          105574   2018-03-10        False\n",
       "          105575   2018-03-10        False\n",
       "          105693   2018-03-10        False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_variables = cumul_sales.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2018-03-10</th>\n",
       "      <th>2018-03-11</th>\n",
       "      <th>2018-03-12</th>\n",
       "      <th>2018-03-13</th>\n",
       "      <th>2018-03-14</th>\n",
       "      <th>2018-03-15</th>\n",
       "      <th>2018-03-16</th>\n",
       "      <th>2018-03-17</th>\n",
       "      <th>2018-03-18</th>\n",
       "      <th>2018-03-19</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-05-16</th>\n",
       "      <th>2018-05-17</th>\n",
       "      <th>2018-05-18</th>\n",
       "      <th>2018-05-19</th>\n",
       "      <th>2018-05-20</th>\n",
       "      <th>2018-05-21</th>\n",
       "      <th>2018-05-22</th>\n",
       "      <th>2018-05-23</th>\n",
       "      <th>2018-05-24</th>\n",
       "      <th>2018-05-25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   onpromotion                                              \\\n",
       "date                2018-03-10 2018-03-11 2018-03-12 2018-03-13 2018-03-14   \n",
       "store_nbr item_nbr                                                           \n",
       "1         96995          False      False      False      False      False   \n",
       "          99197          False      False      False      False      False   \n",
       "          103520         False      False      False      False      False   \n",
       "          103665         False      False      False      False      False   \n",
       "          105574         False      False      False      False      False   \n",
       "\n",
       "                                                                           \\\n",
       "date               2018-03-15 2018-03-16 2018-03-17 2018-03-18 2018-03-19   \n",
       "store_nbr item_nbr                                                          \n",
       "1         96995         False      False      False      False      False   \n",
       "          99197         False      False      False      False      False   \n",
       "          103520        False      False      False      False      False   \n",
       "          103665        False      False      False      False      False   \n",
       "          105574        False      False      False      False      False   \n",
       "\n",
       "                      ...                                                  \\\n",
       "date                  ...     2018-05-16 2018-05-17 2018-05-18 2018-05-19   \n",
       "store_nbr item_nbr    ...                                                   \n",
       "1         96995       ...          False      False      False      False   \n",
       "          99197       ...          False      False      False      False   \n",
       "          103520      ...          False      False      False      False   \n",
       "          103665      ...          False      False      False      False   \n",
       "          105574      ...          False      False      False      False   \n",
       "\n",
       "                                                                           \\\n",
       "date               2018-05-20 2018-05-21 2018-05-22 2018-05-23 2018-05-24   \n",
       "store_nbr item_nbr                                                          \n",
       "1         96995         False      False      False      False      False   \n",
       "          99197         False      False      False      False      False   \n",
       "          103520        False      False      False      False      False   \n",
       "          103665        False      False      False      False      False   \n",
       "          105574        False      False      False      False      False   \n",
       "\n",
       "                               \n",
       "date               2018-05-25  \n",
       "store_nbr item_nbr             \n",
       "1         96995         False  \n",
       "          99197         False  \n",
       "          103520        False  \n",
       "          103665        False  \n",
       "          105574        False  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_variables.columns = promo_variables.columns.get_level_values(1)\n",
    "\n",
    "promo_variables_query = cumul_sales_query[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_variables_query.columns = promo_variables_query.columns.get_level_values(1)\n",
    "promo_variables_query = promo_variables_query.reindex(promo_variables.index).fillna(False)\n",
    "\n",
    "promo_variables_train_and_query = pd.concat([promo_variables, promo_variables_query], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159434, 77), 221400)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_variables.shape, items.shape[0] * stores.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8116723, 5), (1609465, 2))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.shape, cumul_sales_query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Unstack unit sales - do it across all days in a sliding window\n",
    "\n",
    "Ah... they're creating a multi-task learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159434, 77)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales = cumul_sales.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "cumul_sales.columns = cumul_sales.columns.get_level_values(1)\n",
    "cumul_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2018-03-10 00:00:00</th>\n",
       "      <th>2018-03-11 00:00:00</th>\n",
       "      <th>2018-03-12 00:00:00</th>\n",
       "      <th>2018-03-13 00:00:00</th>\n",
       "      <th>2018-03-14 00:00:00</th>\n",
       "      <th>2018-03-15 00:00:00</th>\n",
       "      <th>2018-03-16 00:00:00</th>\n",
       "      <th>2018-03-17 00:00:00</th>\n",
       "      <th>2018-03-18 00:00:00</th>\n",
       "      <th>2018-03-19 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-05-16 00:00:00</th>\n",
       "      <th>2018-05-17 00:00:00</th>\n",
       "      <th>2018-05-18 00:00:00</th>\n",
       "      <th>2018-05-19 00:00:00</th>\n",
       "      <th>2018-05-20 00:00:00</th>\n",
       "      <th>2018-05-21 00:00:00</th>\n",
       "      <th>2018-05-22 00:00:00</th>\n",
       "      <th>2018-05-23 00:00:00</th>\n",
       "      <th>2018-05-24 00:00:00</th>\n",
       "      <th>2018-05-25 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2018-03-10  2018-03-11  2018-03-12  2018-03-13  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       0.000000    0.000000    0.000000    0.000000   \n",
       "          103520      0.693147    0.693147    0.000000    0.693147   \n",
       "          103665      1.386294    0.693147    0.000000    0.693147   \n",
       "          105574      2.397895    1.609438    0.693147    1.791759   \n",
       "\n",
       "date                2018-03-14  2018-03-15  2018-03-16  2018-03-17  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995        0.00000    0.000000    0.000000    0.000000   \n",
       "          99197        0.00000    0.000000    0.000000    0.000000   \n",
       "          103520       0.00000    0.693147    0.693147    1.609438   \n",
       "          103665       0.00000    1.945910    0.000000    1.791759   \n",
       "          105574       1.94591    1.609438    2.397895    2.484907   \n",
       "\n",
       "date                2018-03-18  2018-03-19     ...      2018-05-16  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995       0.000000    0.000000     ...        0.000000   \n",
       "          99197       0.000000    0.000000     ...        1.098612   \n",
       "          103520      1.609438    0.000000     ...        1.609438   \n",
       "          103665      1.386294    0.693147     ...        1.791759   \n",
       "          105574      1.609438    0.693147     ...        2.197225   \n",
       "\n",
       "date                2018-05-17  2018-05-18  2018-05-19  2018-05-20  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       1.098612    0.693147    1.098612    0.000000   \n",
       "          103520      0.693147    0.000000    0.000000    1.098612   \n",
       "          103665      0.000000    0.693147    2.197225    1.386294   \n",
       "          105574      2.302585    2.302585    1.945910    0.693147   \n",
       "\n",
       "date                2018-05-21  2018-05-22  2018-05-23  2018-05-24  2018-05-25  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995            0.0    0.000000    0.000000    0.000000    0.693147  \n",
       "          99197            0.0    0.000000    0.000000    1.098612    1.386294  \n",
       "          103520           0.0    0.693147    1.098612    1.609438    2.079442  \n",
       "          103665           0.0    1.098612    1.791759    0.000000    1.098612  \n",
       "          105574           0.0    1.945910    2.772589    1.791759    1.386294  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumul_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make items match other data frames\n",
    "\n",
    "They're sacraficing generability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                family  class  perishable\n",
       "item_nbr                                 \n",
       "96995        GROCERY I   1093           0\n",
       "99197        GROCERY I   1067           0\n",
       "103520       GROCERY I   1028           0\n",
       "103665    BREAD/BAKERY   2712           1\n",
       "105574       GROCERY I   1045           0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = items.reindex(cumul_sales.index.get_level_values(1))\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159434, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time futzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return that portion of the data frame that corresponds to the time period\n",
    "#   beginning \"minus\" days before \"dt\" and extending for \"periods\" days\n",
    "def get_timespan(df, dt, minus, periods):\n",
    "    return df[\n",
    "        pd.date_range(dt - timedelta(days=minus), periods=periods)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(cumul_sales, promo_variables_train_and_query, start_date, is_train=True):\n",
    "    X = pd.DataFrame({  # Mean target for different retrospective timespans & total # promotions\n",
    "        \"mean_3_2017\": get_timespan(cumul_sales, start_date, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(cumul_sales, start_date, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(cumul_sales, start_date, 14, 14).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_variables_train_and_query, start_date, 14, 14).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(16):  # Promotions on future days\n",
    "        X[\"promo_{}\".format(i)] = promo_variables_train_and_query[\n",
    "            start_date + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = cumul_sales[  # Target values for future days\n",
    "            pd.date_range(start_date, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "X_l, y_l = [], []\n",
    "for i in range(4):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(cumul_sales, promo_variables_train_and_query, training_history_start + delta)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "\n",
    "X_validate, y_validate = prepare_dataset(cumul_sales, promo_variables_train_and_query, validation_start)\n",
    "\n",
    "X_query = prepare_dataset(cumul_sales, promo_variables_train_and_query, now, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((637736, 20), (159434, 20), (159434, 20))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape, X_query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is **super gamey**. They're using the means for the week, fortnight, and last three days, and then seeing how to permute it to generate values for the following window of time. It's hardcoded to product IDs, not categories.\n",
    "\n",
    "It does however, permit multi-task learning, and therefore better representation learning\n",
    "\n",
    "It does not incorporate any information about seasonality at all, and so would fall arse over face at Christmas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryanfeeney/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.374993\tvalid_1's l2: 0.373291\n",
      "[100]\ttraining's l2: 0.362088\tvalid_1's l2: 0.365847\n",
      "[150]\ttraining's l2: 0.359539\tvalid_1's l2: 0.364535\n",
      "[200]\ttraining's l2: 0.358059\tvalid_1's l2: 0.363779\n",
      "[250]\ttraining's l2: 0.356911\tvalid_1's l2: 0.363265\n",
      "[300]\ttraining's l2: 0.35594\tvalid_1's l2: 0.362884\n",
      "[350]\ttraining's l2: 0.35518\tvalid_1's l2: 0.362592\n",
      "[400]\ttraining's l2: 0.354505\tvalid_1's l2: 0.362336\n",
      "[450]\ttraining's l2: 0.35387\tvalid_1's l2: 0.362213\n",
      "[500]\ttraining's l2: 0.35335\tvalid_1's l2: 0.362148\n",
      "[550]\ttraining's l2: 0.352837\tvalid_1's l2: 0.36203\n",
      "[600]\ttraining's l2: 0.352353\tvalid_1's l2: 0.361967\n",
      "[650]\ttraining's l2: 0.351841\tvalid_1's l2: 0.361916\n",
      "[700]\ttraining's l2: 0.35142\tvalid_1's l2: 0.361879\n",
      "[750]\ttraining's l2: 0.351006\tvalid_1's l2: 0.361831\n",
      "[800]\ttraining's l2: 0.350598\tvalid_1's l2: 0.361797\n",
      "[850]\ttraining's l2: 0.35019\tvalid_1's l2: 0.361708\n",
      "[900]\ttraining's l2: 0.349804\tvalid_1's l2: 0.361698\n",
      "[950]\ttraining's l2: 0.349455\tvalid_1's l2: 0.36163\n",
      "[1000]\ttraining's l2: 0.349101\tvalid_1's l2: 0.361642\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.349101\tvalid_1's l2: 0.361642\n",
      "mean_14_2017: 1718521.04\n",
      "mean_7_2017: 1548508.86\n",
      "mean_3_2017: 553835.03\n",
      "promo_0: 102560.63\n",
      "promo_14_2017: 57888.57\n",
      "promo_7: 14205.88\n",
      "promo_1: 5602.46\n",
      "promo_14: 5159.44\n",
      "promo_5: 4449.58\n",
      "promo_12: 4261.49\n",
      "promo_3: 3720.11\n",
      "promo_15: 3109.76\n",
      "promo_2: 2647.64\n",
      "promo_4: 2060.73\n",
      "promo_11: 1402.60\n",
      "promo_9: 1380.77\n",
      "promo_6: 1375.89\n",
      "promo_8: 1067.41\n",
      "promo_13: 962.11\n",
      "promo_10: 959.07\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.433427\tvalid_1's l2: 0.386904\n",
      "[100]\ttraining's l2: 0.418908\tvalid_1's l2: 0.37789\n",
      "[150]\ttraining's l2: 0.415464\tvalid_1's l2: 0.376769\n",
      "[200]\ttraining's l2: 0.413699\tvalid_1's l2: 0.376258\n",
      "[250]\ttraining's l2: 0.412228\tvalid_1's l2: 0.375905\n",
      "[300]\ttraining's l2: 0.411125\tvalid_1's l2: 0.375637\n",
      "[350]\ttraining's l2: 0.410161\tvalid_1's l2: 0.375464\n",
      "[400]\ttraining's l2: 0.40932\tvalid_1's l2: 0.375355\n",
      "[450]\ttraining's l2: 0.408595\tvalid_1's l2: 0.375268\n",
      "[500]\ttraining's l2: 0.4079\tvalid_1's l2: 0.375208\n",
      "[550]\ttraining's l2: 0.407292\tvalid_1's l2: 0.375097\n",
      "[600]\ttraining's l2: 0.406711\tvalid_1's l2: 0.375023\n",
      "[650]\ttraining's l2: 0.406118\tvalid_1's l2: 0.374981\n",
      "[700]\ttraining's l2: 0.405549\tvalid_1's l2: 0.375015\n",
      "Early stopping, best iteration is:\n",
      "[655]\ttraining's l2: 0.406051\tvalid_1's l2: 0.374959\n",
      "mean_14_2017: 2793643.54\n",
      "mean_7_2017: 1262318.39\n",
      "mean_3_2017: 386335.12\n",
      "promo_1: 60768.67\n",
      "promo_14_2017: 45926.96\n",
      "promo_0: 9474.16\n",
      "promo_3: 6390.08\n",
      "promo_5: 6381.69\n",
      "promo_2: 5587.00\n",
      "promo_4: 4311.54\n",
      "promo_8: 4164.42\n",
      "promo_12: 3379.06\n",
      "promo_7: 2698.61\n",
      "promo_6: 2131.68\n",
      "promo_14: 1899.65\n",
      "promo_11: 1692.01\n",
      "promo_9: 1573.09\n",
      "promo_15: 1225.13\n",
      "promo_10: 1099.10\n",
      "promo_13: 973.09\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.443101\tvalid_1's l2: 0.43073\n",
      "[100]\ttraining's l2: 0.426734\tvalid_1's l2: 0.416784\n",
      "[150]\ttraining's l2: 0.422638\tvalid_1's l2: 0.41583\n",
      "[200]\ttraining's l2: 0.42058\tvalid_1's l2: 0.415823\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's l2: 0.421017\tvalid_1's l2: 0.415751\n",
      "mean_14_2017: 2816820.94\n",
      "mean_7_2017: 1278841.37\n",
      "mean_3_2017: 361644.13\n",
      "promo_2: 70568.22\n",
      "promo_14_2017: 39510.78\n",
      "promo_5: 9365.45\n",
      "promo_1: 7701.23\n",
      "promo_3: 6385.40\n",
      "promo_9: 5389.07\n",
      "promo_0: 5191.44\n",
      "promo_4: 4697.99\n",
      "promo_12: 3299.92\n",
      "promo_7: 2100.46\n",
      "promo_14: 1991.67\n",
      "promo_8: 1740.60\n",
      "promo_11: 872.00\n",
      "promo_10: 817.57\n",
      "promo_6: 702.12\n",
      "promo_13: 626.92\n",
      "promo_15: 256.70\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.429488\tvalid_1's l2: 0.395094\n",
      "[100]\ttraining's l2: 0.417436\tvalid_1's l2: 0.386091\n",
      "[150]\ttraining's l2: 0.414126\tvalid_1's l2: 0.384863\n",
      "[200]\ttraining's l2: 0.412365\tvalid_1's l2: 0.384206\n",
      "[250]\ttraining's l2: 0.410983\tvalid_1's l2: 0.38392\n",
      "[300]\ttraining's l2: 0.410017\tvalid_1's l2: 0.383636\n",
      "[350]\ttraining's l2: 0.40918\tvalid_1's l2: 0.383546\n",
      "[400]\ttraining's l2: 0.408421\tvalid_1's l2: 0.383436\n",
      "[450]\ttraining's l2: 0.407701\tvalid_1's l2: 0.383429\n",
      "[500]\ttraining's l2: 0.407051\tvalid_1's l2: 0.383384\n",
      "[550]\ttraining's l2: 0.406472\tvalid_1's l2: 0.383308\n",
      "Early stopping, best iteration is:\n",
      "[540]\ttraining's l2: 0.406585\tvalid_1's l2: 0.383266\n",
      "mean_14_2017: 2264180.20\n",
      "mean_7_2017: 855436.31\n",
      "mean_3_2017: 349105.43\n",
      "promo_3: 73937.43\n",
      "promo_14_2017: 36005.58\n",
      "promo_5: 13644.53\n",
      "promo_1: 10636.83\n",
      "promo_4: 6375.81\n",
      "promo_2: 5906.07\n",
      "promo_9: 4284.35\n",
      "promo_0: 4154.78\n",
      "promo_12: 4148.49\n",
      "promo_10: 2305.20\n",
      "promo_7: 2064.04\n",
      "promo_6: 1985.97\n",
      "promo_8: 1981.53\n",
      "promo_14: 1829.15\n",
      "promo_11: 1807.99\n",
      "promo_13: 934.65\n",
      "promo_15: 786.67\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.409423\tvalid_1's l2: 0.386929\n",
      "[100]\ttraining's l2: 0.397002\tvalid_1's l2: 0.380148\n",
      "[150]\ttraining's l2: 0.393143\tvalid_1's l2: 0.378703\n",
      "[200]\ttraining's l2: 0.391193\tvalid_1's l2: 0.378007\n",
      "[250]\ttraining's l2: 0.389853\tvalid_1's l2: 0.377464\n",
      "[300]\ttraining's l2: 0.388867\tvalid_1's l2: 0.377175\n",
      "[350]\ttraining's l2: 0.387973\tvalid_1's l2: 0.376905\n",
      "[400]\ttraining's l2: 0.387221\tvalid_1's l2: 0.376734\n",
      "[450]\ttraining's l2: 0.386542\tvalid_1's l2: 0.376588\n",
      "[500]\ttraining's l2: 0.385899\tvalid_1's l2: 0.376524\n",
      "[550]\ttraining's l2: 0.385327\tvalid_1's l2: 0.376465\n",
      "[600]\ttraining's l2: 0.384786\tvalid_1's l2: 0.376383\n",
      "[650]\ttraining's l2: 0.384221\tvalid_1's l2: 0.376388\n",
      "[700]\ttraining's l2: 0.383747\tvalid_1's l2: 0.376343\n",
      "[750]\ttraining's l2: 0.383294\tvalid_1's l2: 0.376333\n",
      "[800]\ttraining's l2: 0.382843\tvalid_1's l2: 0.376333\n",
      "Early stopping, best iteration is:\n",
      "[776]\ttraining's l2: 0.383052\tvalid_1's l2: 0.376293\n",
      "mean_14_2017: 2216669.46\n",
      "mean_7_2017: 813346.69\n",
      "mean_3_2017: 398820.08\n",
      "promo_4: 120348.53\n",
      "promo_14_2017: 45896.83\n",
      "promo_5: 16050.88\n",
      "promo_11: 11740.99\n",
      "promo_1: 9051.91\n",
      "promo_0: 5288.19\n",
      "promo_12: 5196.04\n",
      "promo_2: 4185.61\n",
      "promo_9: 4143.37\n",
      "promo_3: 3950.98\n",
      "promo_14: 3162.48\n",
      "promo_7: 3117.58\n",
      "promo_8: 2433.24\n",
      "promo_6: 2054.17\n",
      "promo_13: 1706.90\n",
      "promo_10: 1681.95\n",
      "promo_15: 1406.03\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.401417\tvalid_1's l2: 0.385608\n",
      "[100]\ttraining's l2: 0.387996\tvalid_1's l2: 0.377045\n",
      "[150]\ttraining's l2: 0.384307\tvalid_1's l2: 0.375357\n",
      "[200]\ttraining's l2: 0.38251\tvalid_1's l2: 0.374546\n",
      "[250]\ttraining's l2: 0.381077\tvalid_1's l2: 0.374006\n",
      "[300]\ttraining's l2: 0.380037\tvalid_1's l2: 0.373592\n",
      "[350]\ttraining's l2: 0.379109\tvalid_1's l2: 0.373302\n",
      "[400]\ttraining's l2: 0.378333\tvalid_1's l2: 0.373137\n",
      "[450]\ttraining's l2: 0.377661\tvalid_1's l2: 0.373052\n",
      "[500]\ttraining's l2: 0.377005\tvalid_1's l2: 0.3729\n",
      "[550]\ttraining's l2: 0.376428\tvalid_1's l2: 0.372842\n",
      "[600]\ttraining's l2: 0.375862\tvalid_1's l2: 0.372776\n",
      "[650]\ttraining's l2: 0.375351\tvalid_1's l2: 0.372709\n",
      "[700]\ttraining's l2: 0.374883\tvalid_1's l2: 0.372657\n",
      "[750]\ttraining's l2: 0.374459\tvalid_1's l2: 0.372648\n",
      "Early stopping, best iteration is:\n",
      "[732]\ttraining's l2: 0.374623\tvalid_1's l2: 0.372631\n",
      "mean_14_2017: 2371418.22\n",
      "mean_7_2017: 715556.13\n",
      "mean_3_2017: 441962.98\n",
      "promo_5: 194898.12\n",
      "promo_14_2017: 65646.67\n",
      "promo_12: 28551.29\n",
      "promo_4: 6852.31\n",
      "promo_14: 6473.69\n",
      "promo_1: 5862.85\n",
      "promo_9: 5290.68\n",
      "promo_13: 5255.13\n",
      "promo_8: 5081.49\n",
      "promo_7: 4851.86\n",
      "promo_6: 3545.86\n",
      "promo_0: 3421.54\n",
      "promo_2: 3065.65\n",
      "promo_11: 2378.29\n",
      "promo_3: 1905.43\n",
      "promo_10: 1825.09\n",
      "promo_15: 1312.89\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.422838\tvalid_1's l2: 0.410896\n",
      "[100]\ttraining's l2: 0.411302\tvalid_1's l2: 0.405126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttraining's l2: 0.407847\tvalid_1's l2: 0.403595\n",
      "[200]\ttraining's l2: 0.406059\tvalid_1's l2: 0.402703\n",
      "[250]\ttraining's l2: 0.404593\tvalid_1's l2: 0.402181\n",
      "[300]\ttraining's l2: 0.40352\tvalid_1's l2: 0.401689\n",
      "[350]\ttraining's l2: 0.402588\tvalid_1's l2: 0.401459\n",
      "[400]\ttraining's l2: 0.401756\tvalid_1's l2: 0.401272\n",
      "[450]\ttraining's l2: 0.401046\tvalid_1's l2: 0.40118\n",
      "[500]\ttraining's l2: 0.400417\tvalid_1's l2: 0.401106\n",
      "[550]\ttraining's l2: 0.399816\tvalid_1's l2: 0.401044\n",
      "[600]\ttraining's l2: 0.39924\tvalid_1's l2: 0.400945\n",
      "[650]\ttraining's l2: 0.398692\tvalid_1's l2: 0.400974\n",
      "Early stopping, best iteration is:\n",
      "[627]\ttraining's l2: 0.398939\tvalid_1's l2: 0.400922\n",
      "mean_14_2017: 1958442.69\n",
      "mean_7_2017: 714103.30\n",
      "mean_3_2017: 352482.60\n",
      "promo_6: 102438.94\n",
      "promo_14_2017: 50278.70\n",
      "promo_5: 12217.17\n",
      "promo_12: 10625.26\n",
      "promo_7: 8544.62\n",
      "promo_1: 7938.47\n",
      "promo_9: 6824.24\n",
      "promo_8: 6504.56\n",
      "promo_10: 4083.75\n",
      "promo_4: 3733.00\n",
      "promo_11: 3240.62\n",
      "promo_3: 3002.54\n",
      "promo_14: 2983.49\n",
      "promo_2: 2509.49\n",
      "promo_0: 2399.06\n",
      "promo_13: 1995.01\n",
      "promo_15: 1117.26\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.435497\tvalid_1's l2: 0.432937\n",
      "[100]\ttraining's l2: 0.422751\tvalid_1's l2: 0.423028\n",
      "[150]\ttraining's l2: 0.419257\tvalid_1's l2: 0.42075\n",
      "[200]\ttraining's l2: 0.417431\tvalid_1's l2: 0.419843\n",
      "[250]\ttraining's l2: 0.415866\tvalid_1's l2: 0.418999\n",
      "[300]\ttraining's l2: 0.414781\tvalid_1's l2: 0.418573\n",
      "[350]\ttraining's l2: 0.413773\tvalid_1's l2: 0.418255\n",
      "[400]\ttraining's l2: 0.412935\tvalid_1's l2: 0.417971\n",
      "[450]\ttraining's l2: 0.412164\tvalid_1's l2: 0.417766\n",
      "[500]\ttraining's l2: 0.411418\tvalid_1's l2: 0.417528\n",
      "[550]\ttraining's l2: 0.410728\tvalid_1's l2: 0.417316\n",
      "[600]\ttraining's l2: 0.410133\tvalid_1's l2: 0.417237\n",
      "[650]\ttraining's l2: 0.409539\tvalid_1's l2: 0.417085\n",
      "[700]\ttraining's l2: 0.408999\tvalid_1's l2: 0.417027\n",
      "[750]\ttraining's l2: 0.408515\tvalid_1's l2: 0.416993\n",
      "[800]\ttraining's l2: 0.408022\tvalid_1's l2: 0.416954\n",
      "[850]\ttraining's l2: 0.407539\tvalid_1's l2: 0.416887\n",
      "Early stopping, best iteration is:\n",
      "[847]\ttraining's l2: 0.407563\tvalid_1's l2: 0.416886\n",
      "mean_14_2017: 2279223.33\n",
      "mean_7_2017: 728614.80\n",
      "mean_3_2017: 312733.32\n",
      "promo_7: 152057.60\n",
      "promo_14_2017: 63692.18\n",
      "promo_0: 27227.28\n",
      "promo_12: 13938.83\n",
      "promo_14: 13762.80\n",
      "promo_5: 10080.63\n",
      "promo_8: 7636.66\n",
      "promo_6: 5872.74\n",
      "promo_9: 5417.69\n",
      "promo_10: 4612.99\n",
      "promo_11: 4193.24\n",
      "promo_4: 2847.34\n",
      "promo_1: 2293.89\n",
      "promo_15: 2064.75\n",
      "promo_2: 1469.01\n",
      "promo_13: 1431.79\n",
      "promo_3: 1306.06\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.467488\tvalid_1's l2: 0.477711\n",
      "[100]\ttraining's l2: 0.453078\tvalid_1's l2: 0.461961\n",
      "[150]\ttraining's l2: 0.448749\tvalid_1's l2: 0.459474\n",
      "[200]\ttraining's l2: 0.446702\tvalid_1's l2: 0.458776\n",
      "[250]\ttraining's l2: 0.444951\tvalid_1's l2: 0.458061\n",
      "[300]\ttraining's l2: 0.443641\tvalid_1's l2: 0.457605\n",
      "[350]\ttraining's l2: 0.442557\tvalid_1's l2: 0.457355\n",
      "[400]\ttraining's l2: 0.441664\tvalid_1's l2: 0.4572\n",
      "[450]\ttraining's l2: 0.440884\tvalid_1's l2: 0.457112\n",
      "[500]\ttraining's l2: 0.440075\tvalid_1's l2: 0.45696\n",
      "[550]\ttraining's l2: 0.439389\tvalid_1's l2: 0.456773\n",
      "[600]\ttraining's l2: 0.438724\tvalid_1's l2: 0.456666\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's l2: 0.438807\tvalid_1's l2: 0.456638\n",
      "mean_14_2017: 2648080.61\n",
      "mean_7_2017: 855327.21\n",
      "mean_3_2017: 311938.94\n",
      "promo_8: 98213.55\n",
      "promo_14_2017: 55806.51\n",
      "promo_12: 17334.28\n",
      "promo_7: 15615.34\n",
      "promo_1: 10697.19\n",
      "promo_5: 9691.92\n",
      "promo_6: 7625.82\n",
      "promo_9: 7399.24\n",
      "promo_11: 5814.61\n",
      "promo_10: 5415.61\n",
      "promo_14: 4238.87\n",
      "promo_0: 3424.33\n",
      "promo_15: 3232.06\n",
      "promo_4: 3089.25\n",
      "promo_13: 1946.58\n",
      "promo_2: 1759.39\n",
      "promo_3: 1675.44\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.488248\tvalid_1's l2: 0.467128\n",
      "[100]\ttraining's l2: 0.471961\tvalid_1's l2: 0.461764\n",
      "[150]\ttraining's l2: 0.46705\tvalid_1's l2: 0.458639\n",
      "[200]\ttraining's l2: 0.464453\tvalid_1's l2: 0.457404\n",
      "[250]\ttraining's l2: 0.462683\tvalid_1's l2: 0.456864\n",
      "[300]\ttraining's l2: 0.46141\tvalid_1's l2: 0.45657\n",
      "[350]\ttraining's l2: 0.460237\tvalid_1's l2: 0.456184\n",
      "[400]\ttraining's l2: 0.459345\tvalid_1's l2: 0.456079\n",
      "[450]\ttraining's l2: 0.458507\tvalid_1's l2: 0.455911\n",
      "[500]\ttraining's l2: 0.457685\tvalid_1's l2: 0.455773\n",
      "[550]\ttraining's l2: 0.456973\tvalid_1's l2: 0.455718\n",
      "[600]\ttraining's l2: 0.456287\tvalid_1's l2: 0.455755\n",
      "Early stopping, best iteration is:\n",
      "[557]\ttraining's l2: 0.456876\tvalid_1's l2: 0.455684\n",
      "mean_14_2017: 2827590.00\n",
      "mean_7_2017: 925238.85\n",
      "mean_3_2017: 323490.44\n",
      "promo_9: 108996.23\n",
      "promo_14_2017: 50709.86\n",
      "promo_12: 19456.87\n",
      "promo_7: 13959.48\n",
      "promo_2: 13282.23\n",
      "promo_10: 8580.96\n",
      "promo_5: 8031.89\n",
      "promo_11: 7940.24\n",
      "promo_8: 7033.41\n",
      "promo_6: 5556.18\n",
      "promo_14: 5508.94\n",
      "promo_0: 3609.17\n",
      "promo_15: 2787.95\n",
      "promo_1: 2694.45\n",
      "promo_4: 2657.57\n",
      "promo_13: 2074.96\n",
      "promo_3: 1727.84\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.496659\tvalid_1's l2: 0.436378\n",
      "[100]\ttraining's l2: 0.482435\tvalid_1's l2: 0.426281\n",
      "[150]\ttraining's l2: 0.478167\tvalid_1's l2: 0.424254\n",
      "[200]\ttraining's l2: 0.475902\tvalid_1's l2: 0.423165\n",
      "[250]\ttraining's l2: 0.474309\tvalid_1's l2: 0.422862\n",
      "[300]\ttraining's l2: 0.472969\tvalid_1's l2: 0.422518\n",
      "[350]\ttraining's l2: 0.471872\tvalid_1's l2: 0.422268\n",
      "[400]\ttraining's l2: 0.470961\tvalid_1's l2: 0.422174\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's l2: 0.471078\tvalid_1's l2: 0.42215\n",
      "mean_14_2017: 2394926.29\n",
      "mean_7_2017: 801877.96\n",
      "mean_3_2017: 293998.82\n",
      "promo_10: 103003.61\n",
      "promo_14_2017: 51901.04\n",
      "promo_12: 22864.84\n",
      "promo_11: 14501.75\n",
      "promo_7: 11356.11\n",
      "promo_9: 9244.82\n",
      "promo_5: 7017.24\n",
      "promo_8: 6374.65\n",
      "promo_6: 4710.94\n",
      "promo_14: 3980.34\n",
      "promo_15: 3453.94\n",
      "promo_4: 3059.40\n",
      "promo_3: 3054.66\n",
      "promo_1: 2576.17\n",
      "promo_0: 2356.21\n",
      "promo_13: 2299.42\n",
      "promo_2: 1467.72\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.447659\tvalid_1's l2: 0.42443\n",
      "[100]\ttraining's l2: 0.434196\tvalid_1's l2: 0.41022\n",
      "[150]\ttraining's l2: 0.430079\tvalid_1's l2: 0.407465\n",
      "[200]\ttraining's l2: 0.427786\tvalid_1's l2: 0.406232\n",
      "[250]\ttraining's l2: 0.42623\tvalid_1's l2: 0.405678\n",
      "[300]\ttraining's l2: 0.425051\tvalid_1's l2: 0.405279\n",
      "[350]\ttraining's l2: 0.424014\tvalid_1's l2: 0.405072\n",
      "[400]\ttraining's l2: 0.423094\tvalid_1's l2: 0.404868\n",
      "[450]\ttraining's l2: 0.422345\tvalid_1's l2: 0.404779\n",
      "[500]\ttraining's l2: 0.421641\tvalid_1's l2: 0.404639\n",
      "[550]\ttraining's l2: 0.420983\tvalid_1's l2: 0.404527\n",
      "[600]\ttraining's l2: 0.420362\tvalid_1's l2: 0.404463\n",
      "[650]\ttraining's l2: 0.419794\tvalid_1's l2: 0.404441\n",
      "Early stopping, best iteration is:\n",
      "[625]\ttraining's l2: 0.420058\tvalid_1's l2: 0.404418\n",
      "mean_14_2017: 2210895.48\n",
      "mean_7_2017: 636429.37\n",
      "mean_3_2017: 400971.55\n",
      "promo_11: 158862.22\n",
      "promo_14_2017: 51461.76\n",
      "promo_12: 22431.71\n",
      "promo_4: 17072.44\n",
      "promo_7: 9192.88\n",
      "promo_10: 8658.42\n",
      "promo_5: 7593.09\n",
      "promo_9: 6797.74\n",
      "promo_8: 5736.14\n",
      "promo_6: 3687.10\n",
      "promo_14: 3657.03\n",
      "promo_15: 3084.41\n",
      "promo_13: 2594.41\n",
      "promo_0: 2376.68\n",
      "promo_2: 1861.00\n",
      "promo_3: 1659.93\n",
      "promo_1: 1535.09\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.435566\tvalid_1's l2: 0.408911\n",
      "[100]\ttraining's l2: 0.420998\tvalid_1's l2: 0.396015\n",
      "[150]\ttraining's l2: 0.417448\tvalid_1's l2: 0.394131\n",
      "[200]\ttraining's l2: 0.415279\tvalid_1's l2: 0.393245\n",
      "[250]\ttraining's l2: 0.41361\tvalid_1's l2: 0.392632\n",
      "[300]\ttraining's l2: 0.412382\tvalid_1's l2: 0.392428\n",
      "[350]\ttraining's l2: 0.41134\tvalid_1's l2: 0.392164\n",
      "[400]\ttraining's l2: 0.410489\tvalid_1's l2: 0.392125\n",
      "[450]\ttraining's l2: 0.409714\tvalid_1's l2: 0.39194\n",
      "[500]\ttraining's l2: 0.409044\tvalid_1's l2: 0.391886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550]\ttraining's l2: 0.408382\tvalid_1's l2: 0.391766\n",
      "[600]\ttraining's l2: 0.407792\tvalid_1's l2: 0.391675\n",
      "Early stopping, best iteration is:\n",
      "[598]\ttraining's l2: 0.407812\tvalid_1's l2: 0.391658\n",
      "mean_14_2017: 2271912.93\n",
      "mean_7_2017: 638725.93\n",
      "mean_3_2017: 398574.51\n",
      "promo_12: 252621.21\n",
      "promo_14_2017: 61932.71\n",
      "promo_5: 53149.55\n",
      "promo_13: 13132.33\n",
      "promo_11: 10844.69\n",
      "promo_15: 9544.88\n",
      "promo_14: 8554.80\n",
      "promo_7: 7097.88\n",
      "promo_10: 4841.04\n",
      "promo_4: 4485.20\n",
      "promo_0: 4133.15\n",
      "promo_9: 3729.90\n",
      "promo_6: 3319.76\n",
      "promo_2: 2566.20\n",
      "promo_8: 2271.34\n",
      "promo_1: 1552.70\n",
      "promo_3: 1309.66\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.453843\tvalid_1's l2: 0.412024\n",
      "[100]\ttraining's l2: 0.441871\tvalid_1's l2: 0.403915\n",
      "[150]\ttraining's l2: 0.438235\tvalid_1's l2: 0.402105\n",
      "[200]\ttraining's l2: 0.436333\tvalid_1's l2: 0.401265\n",
      "[250]\ttraining's l2: 0.434812\tvalid_1's l2: 0.400748\n",
      "[300]\ttraining's l2: 0.433666\tvalid_1's l2: 0.400371\n",
      "[350]\ttraining's l2: 0.432696\tvalid_1's l2: 0.4001\n",
      "[400]\ttraining's l2: 0.431802\tvalid_1's l2: 0.399753\n",
      "[450]\ttraining's l2: 0.431087\tvalid_1's l2: 0.399534\n",
      "[500]\ttraining's l2: 0.430433\tvalid_1's l2: 0.399481\n",
      "[550]\ttraining's l2: 0.429761\tvalid_1's l2: 0.399382\n",
      "[600]\ttraining's l2: 0.429163\tvalid_1's l2: 0.399329\n",
      "[650]\ttraining's l2: 0.428607\tvalid_1's l2: 0.39928\n",
      "[700]\ttraining's l2: 0.428074\tvalid_1's l2: 0.399222\n",
      "[750]\ttraining's l2: 0.427589\tvalid_1's l2: 0.399234\n",
      "Early stopping, best iteration is:\n",
      "[707]\ttraining's l2: 0.428003\tvalid_1's l2: 0.399196\n",
      "mean_14_2017: 1980789.10\n",
      "mean_7_2017: 559647.23\n",
      "mean_3_2017: 302996.37\n",
      "promo_13: 124004.10\n",
      "promo_14_2017: 54653.39\n",
      "promo_12: 22752.03\n",
      "promo_15: 16675.13\n",
      "promo_14: 14162.58\n",
      "promo_5: 7226.33\n",
      "promo_6: 6808.43\n",
      "promo_11: 5385.87\n",
      "promo_9: 4100.38\n",
      "promo_7: 3813.12\n",
      "promo_10: 3564.51\n",
      "promo_8: 3098.90\n",
      "promo_1: 2929.63\n",
      "promo_0: 2531.67\n",
      "promo_4: 2528.77\n",
      "promo_3: 1591.41\n",
      "promo_2: 1313.26\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.466155\tvalid_1's l2: 0.430807\n",
      "[100]\ttraining's l2: 0.452549\tvalid_1's l2: 0.418797\n",
      "[150]\ttraining's l2: 0.448984\tvalid_1's l2: 0.417174\n",
      "[200]\ttraining's l2: 0.447028\tvalid_1's l2: 0.416353\n",
      "[250]\ttraining's l2: 0.445492\tvalid_1's l2: 0.415744\n",
      "[300]\ttraining's l2: 0.444327\tvalid_1's l2: 0.415429\n",
      "[350]\ttraining's l2: 0.443326\tvalid_1's l2: 0.415193\n",
      "[400]\ttraining's l2: 0.442555\tvalid_1's l2: 0.415021\n",
      "[450]\ttraining's l2: 0.441779\tvalid_1's l2: 0.414834\n",
      "[500]\ttraining's l2: 0.441013\tvalid_1's l2: 0.414597\n",
      "[550]\ttraining's l2: 0.440333\tvalid_1's l2: 0.414554\n",
      "[600]\ttraining's l2: 0.439678\tvalid_1's l2: 0.414465\n",
      "[650]\ttraining's l2: 0.439064\tvalid_1's l2: 0.414386\n",
      "[700]\ttraining's l2: 0.438548\tvalid_1's l2: 0.414376\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's l2: 0.438691\tvalid_1's l2: 0.414345\n",
      "mean_14_2017: 2192253.25\n",
      "mean_7_2017: 645009.35\n",
      "mean_3_2017: 275722.82\n",
      "promo_14: 175495.23\n",
      "promo_14_2017: 66857.63\n",
      "promo_15: 26183.35\n",
      "promo_12: 23016.44\n",
      "promo_7: 19100.31\n",
      "promo_0: 15792.59\n",
      "promo_13: 14089.76\n",
      "promo_5: 4546.56\n",
      "promo_11: 4377.37\n",
      "promo_4: 3046.82\n",
      "promo_9: 2715.43\n",
      "promo_2: 2263.51\n",
      "promo_6: 2114.83\n",
      "promo_8: 1867.23\n",
      "promo_1: 1626.40\n",
      "promo_10: 1503.00\n",
      "promo_3: 1018.98\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.502073\tvalid_1's l2: 0.457332\n",
      "[100]\ttraining's l2: 0.48747\tvalid_1's l2: 0.442556\n",
      "[150]\ttraining's l2: 0.483293\tvalid_1's l2: 0.440232\n",
      "[200]\ttraining's l2: 0.481169\tvalid_1's l2: 0.439452\n",
      "[250]\ttraining's l2: 0.479459\tvalid_1's l2: 0.439199\n",
      "[300]\ttraining's l2: 0.478161\tvalid_1's l2: 0.43887\n",
      "[350]\ttraining's l2: 0.477069\tvalid_1's l2: 0.438727\n",
      "[400]\ttraining's l2: 0.476143\tvalid_1's l2: 0.438672\n",
      "[450]\ttraining's l2: 0.475307\tvalid_1's l2: 0.438567\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's l2: 0.475425\tvalid_1's l2: 0.43853\n",
      "mean_14_2017: 2562372.67\n",
      "mean_7_2017: 753940.55\n",
      "mean_3_2017: 289622.62\n",
      "promo_15: 138018.78\n",
      "promo_14_2017: 57952.23\n",
      "promo_14: 19477.02\n",
      "promo_12: 18334.20\n",
      "promo_13: 9782.89\n",
      "promo_5: 4778.93\n",
      "promo_8: 4476.12\n",
      "promo_7: 4303.40\n",
      "promo_11: 3366.25\n",
      "promo_9: 2985.71\n",
      "promo_4: 2828.73\n",
      "promo_0: 2642.29\n",
      "promo_10: 2073.42\n",
      "promo_6: 2016.75\n",
      "promo_1: 1855.07\n",
      "promo_3: 1433.65\n",
      "promo_2: 942.59\n"
     ]
    }
   ],
   "source": [
    "MAX_ROUNDS = 1000\n",
    "validate_pred = []\n",
    "query_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 4) * 0.25 + 1\n",
    "    )\n",
    "    \n",
    "    dvalidate = lgb.Dataset(\n",
    "        X_validate, label=y_validate[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    \n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dvalidate], early_stopping_rounds=50, verbose_eval=50\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    \n",
    "    \n",
    "    validate_pred.append(bst.predict(\n",
    "        X_validate, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    \n",
    "    query_pred.append(bst.predict(\n",
    "        X_query, num_iteration=bst.best_iteration or MAX_ROUNDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 17.635705675653934\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation mse:\", np.sqrt(mean_squared_error(\n",
    "    np.expm1(y_validate), np.expm1(np.array(validate_pred)).transpose())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.22670771, 0.03805695, 1.14243052, ..., 0.03805695, 0.03045197,\n",
       "        0.03805695]),\n",
       " array([0.33118785, 0.06358992, 1.28310697, ..., 0.06358992, 0.10461153,\n",
       "        0.06358992]),\n",
       " array([0.29328676, 0.08154939, 1.19042486, ..., 0.08154939, 0.13012389,\n",
       "        0.08154939]),\n",
       " array([0.23788341, 0.08246951, 1.03112951, ..., 0.08246951, 0.13245651,\n",
       "        0.08246951]),\n",
       " array([0.24203497, 0.08389569, 1.03652769, ..., 0.08389569, 0.06927573,\n",
       "        0.08389569]),\n",
       " array([0.22278414, 0.09472484, 1.05182358, ..., 0.09472484, 0.13119284,\n",
       "        0.09472484]),\n",
       " array([0.23614268, 0.16395045, 1.04323934, ..., 0.16395045, 0.37621929,\n",
       "        0.16395045]),\n",
       " array([0.25710815, 0.18286433, 1.04976098, ..., 0.18286433, 0.4065457 ,\n",
       "        0.18286433]),\n",
       " array([0.34092375, 0.21697018, 1.20642206, ..., 0.21697018, 0.5132463 ,\n",
       "        0.21697018]),\n",
       " array([0.32994322, 0.22267369, 1.12193   , ..., 0.22267369, 0.49796372,\n",
       "        0.22267369]),\n",
       " array([0.26906826, 0.20580286, 1.12292526, ..., 0.20580286, 0.58741762,\n",
       "        0.20580286]),\n",
       " array([0.23798355, 0.1820482 , 1.02839126, ..., 0.1820482 , 1.37833453,\n",
       "        0.1820482 ]),\n",
       " array([0.24050083, 0.19148164, 1.03652526, ..., 0.19148164, 1.44426681,\n",
       "        0.19148164]),\n",
       " array([0.25223484, 0.26995771, 1.06191382, ..., 0.26995771, 0.31262332,\n",
       "        0.26995771]),\n",
       " array([0.26899375, 0.30200223, 1.05133439, ..., 0.30200223, 1.49887788,\n",
       "        0.30200223]),\n",
       " array([0.35515716, 0.35993344, 1.1984473 , ..., 0.35993344, 1.65901755,\n",
       "        0.35993344])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-01c9bc360d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_query' is not defined"
     ]
    }
   ],
   "source": [
    "y_query.shape, y_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "print(\"Making submission...\")\n",
    "y_query = np.array(query_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_query, index=cumul_sales.index,\n",
    "    columns=pd.date_range(query_start_date, periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.to_csv(\"/tmp/preds-2018.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"16\" valign=\"top\">96995</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>0.082069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-27</th>\n",
       "      <td>0.129561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-28</th>\n",
       "      <td>0.134338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>0.109364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>0.105926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>0.118327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>0.123348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-02</th>\n",
       "      <td>0.139309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-03</th>\n",
       "      <td>0.176478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>0.182017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-05</th>\n",
       "      <td>0.178734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-06</th>\n",
       "      <td>0.148011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07</th>\n",
       "      <td>0.146720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-08</th>\n",
       "      <td>0.142123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>0.153874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-10</th>\n",
       "      <td>0.203114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">99197</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>0.541507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-27</th>\n",
       "      <td>0.703807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-28</th>\n",
       "      <td>0.631628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>0.509214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>0.499247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>0.485284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>0.474797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-02</th>\n",
       "      <td>0.496639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-03</th>\n",
       "      <td>0.645036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>0.665762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-05</th>\n",
       "      <td>0.557713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-06</th>\n",
       "      <td>0.507736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07</th>\n",
       "      <td>0.490162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-08</th>\n",
       "      <td>0.465243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">2105347</th>\n",
       "      <th>2018-05-28</th>\n",
       "      <td>0.145368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>0.943775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>0.042763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>0.951810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>1.097573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-02</th>\n",
       "      <td>1.023473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-03</th>\n",
       "      <td>1.190717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>1.123746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-05</th>\n",
       "      <td>1.288513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-06</th>\n",
       "      <td>1.082992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07</th>\n",
       "      <td>1.018186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-08</th>\n",
       "      <td>0.258027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>0.282478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-10</th>\n",
       "      <td>0.358725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">2108569</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>0.493195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-27</th>\n",
       "      <td>0.653854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-28</th>\n",
       "      <td>0.639274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>0.486283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>0.440502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>0.443946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>0.433219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-02</th>\n",
       "      <td>0.476857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-03</th>\n",
       "      <td>0.608700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>0.632091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-05</th>\n",
       "      <td>0.546408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-06</th>\n",
       "      <td>0.450832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07</th>\n",
       "      <td>0.421822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-08</th>\n",
       "      <td>0.434692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-09</th>\n",
       "      <td>0.461913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-10</th>\n",
       "      <td>0.590212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2550944 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               unit_sales\n",
       "store_nbr item_nbr                       \n",
       "1         96995    2018-05-26    0.082069\n",
       "                   2018-05-27    0.129561\n",
       "                   2018-05-28    0.134338\n",
       "                   2018-05-29    0.109364\n",
       "                   2018-05-30    0.105926\n",
       "                   2018-05-31    0.118327\n",
       "                   2018-06-01    0.123348\n",
       "                   2018-06-02    0.139309\n",
       "                   2018-06-03    0.176478\n",
       "                   2018-06-04    0.182017\n",
       "                   2018-06-05    0.178734\n",
       "                   2018-06-06    0.148011\n",
       "                   2018-06-07    0.146720\n",
       "                   2018-06-08    0.142123\n",
       "                   2018-06-09    0.153874\n",
       "                   2018-06-10    0.203114\n",
       "          99197    2018-05-26    0.541507\n",
       "                   2018-05-27    0.703807\n",
       "                   2018-05-28    0.631628\n",
       "                   2018-05-29    0.509214\n",
       "                   2018-05-30    0.499247\n",
       "                   2018-05-31    0.485284\n",
       "                   2018-06-01    0.474797\n",
       "                   2018-06-02    0.496639\n",
       "                   2018-06-03    0.645036\n",
       "                   2018-06-04    0.665762\n",
       "                   2018-06-05    0.557713\n",
       "                   2018-06-06    0.507736\n",
       "                   2018-06-07    0.490162\n",
       "                   2018-06-08    0.465243\n",
       "...                                   ...\n",
       "54        2105347  2018-05-28    0.145368\n",
       "                   2018-05-29    0.943775\n",
       "                   2018-05-30    0.042763\n",
       "                   2018-05-31    0.951810\n",
       "                   2018-06-01    1.097573\n",
       "                   2018-06-02    1.023473\n",
       "                   2018-06-03    1.190717\n",
       "                   2018-06-04    1.123746\n",
       "                   2018-06-05    1.288513\n",
       "                   2018-06-06    1.082992\n",
       "                   2018-06-07    1.018186\n",
       "                   2018-06-08    0.258027\n",
       "                   2018-06-09    0.282478\n",
       "                   2018-06-10    0.358725\n",
       "          2108569  2018-05-26    0.493195\n",
       "                   2018-05-27    0.653854\n",
       "                   2018-05-28    0.639274\n",
       "                   2018-05-29    0.486283\n",
       "                   2018-05-30    0.440502\n",
       "                   2018-05-31    0.443946\n",
       "                   2018-06-01    0.433219\n",
       "                   2018-06-02    0.476857\n",
       "                   2018-06-03    0.608700\n",
       "                   2018-06-04    0.632091\n",
       "                   2018-06-05    0.546408\n",
       "                   2018-06-06    0.450832\n",
       "                   2018-06-07    0.421822\n",
       "                   2018-06-08    0.434692\n",
       "                   2018-06-09    0.461913\n",
       "                   2018-06-10    0.590212\n",
       "\n",
       "[2550944 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-d5b4aef1dc75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unit_sales\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unit_sales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497040</td>\n",
       "      <td>0.273266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497041</td>\n",
       "      <td>0.225388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497042</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497043</td>\n",
       "      <td>0.648250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497044</td>\n",
       "      <td>1.352113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497045</td>\n",
       "      <td>3.222305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497046</td>\n",
       "      <td>7.469437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105576</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497047</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105577</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497048</td>\n",
       "      <td>0.294655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105693</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497049</td>\n",
       "      <td>0.319934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105737</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497050</td>\n",
       "      <td>0.763024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105857</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497051</td>\n",
       "      <td>3.247849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106716</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497052</td>\n",
       "      <td>1.781587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108079</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497053</td>\n",
       "      <td>0.346823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108634</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497054</td>\n",
       "      <td>0.033705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108696</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497055</td>\n",
       "      <td>1.357327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108698</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497056</td>\n",
       "      <td>0.585320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108701</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497057</td>\n",
       "      <td>1.804330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108786</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497058</td>\n",
       "      <td>1.744146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108797</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497059</td>\n",
       "      <td>2.840066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108831</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108833</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497061</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108862</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497062</td>\n",
       "      <td>0.704088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108952</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497063</td>\n",
       "      <td>1.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111223</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497064</td>\n",
       "      <td>3.262282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111397</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497065</td>\n",
       "      <td>0.431402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112830</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497066</td>\n",
       "      <td>1.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114778</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497067</td>\n",
       "      <td>1.617434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114790</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497068</td>\n",
       "      <td>2.928812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114799</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497069</td>\n",
       "      <td>0.731032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">54</th>\n",
       "      <th>2127921</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127992</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867475</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128628</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128799</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867477</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129334</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867478</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129350</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129387</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129515</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867481</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129616</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867482</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129678</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129786</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867484</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129790</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867485</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129892</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129994</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867487</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130131</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130219</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867489</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130265</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867490</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130352</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867491</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130474</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867492</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130521</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130526</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867494</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130553</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131010</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131572</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867497</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131699</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867498</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132163</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132318</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132945</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132957</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867502</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134244</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867503</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3370464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  unit_sales\n",
       "store_nbr item_nbr date                             \n",
       "1         96995    2017-08-16  125497040    0.273266\n",
       "          99197    2017-08-16  125497041    0.225388\n",
       "          103501   2017-08-16  125497042    0.000000\n",
       "          103520   2017-08-16  125497043    0.648250\n",
       "          103665   2017-08-16  125497044    1.352113\n",
       "          105574   2017-08-16  125497045    3.222305\n",
       "          105575   2017-08-16  125497046    7.469437\n",
       "          105576   2017-08-16  125497047    0.000000\n",
       "          105577   2017-08-16  125497048    0.294655\n",
       "          105693   2017-08-16  125497049    0.319934\n",
       "          105737   2017-08-16  125497050    0.763024\n",
       "          105857   2017-08-16  125497051    3.247849\n",
       "          106716   2017-08-16  125497052    1.781587\n",
       "          108079   2017-08-16  125497053    0.346823\n",
       "          108634   2017-08-16  125497054    0.033705\n",
       "          108696   2017-08-16  125497055    1.357327\n",
       "          108698   2017-08-16  125497056    0.585320\n",
       "          108701   2017-08-16  125497057    1.804330\n",
       "          108786   2017-08-16  125497058    1.744146\n",
       "          108797   2017-08-16  125497059    2.840066\n",
       "          108831   2017-08-16  125497060    0.000000\n",
       "          108833   2017-08-16  125497061    0.000000\n",
       "          108862   2017-08-16  125497062    0.704088\n",
       "          108952   2017-08-16  125497063    1.000221\n",
       "          111223   2017-08-16  125497064    3.262282\n",
       "          111397   2017-08-16  125497065    0.431402\n",
       "          112830   2017-08-16  125497066    1.090800\n",
       "          114778   2017-08-16  125497067    1.617434\n",
       "          114790   2017-08-16  125497068    2.928812\n",
       "          114799   2017-08-16  125497069    0.731032\n",
       "...                                  ...         ...\n",
       "54        2127921  2017-08-31  128867474    0.000000\n",
       "          2127992  2017-08-31  128867475    0.000000\n",
       "          2128628  2017-08-31  128867476    0.000000\n",
       "          2128799  2017-08-31  128867477    0.000000\n",
       "          2129334  2017-08-31  128867478    0.000000\n",
       "          2129350  2017-08-31  128867479    0.000000\n",
       "          2129387  2017-08-31  128867480    0.000000\n",
       "          2129515  2017-08-31  128867481    0.000000\n",
       "          2129616  2017-08-31  128867482    0.000000\n",
       "          2129678  2017-08-31  128867483    0.000000\n",
       "          2129786  2017-08-31  128867484    0.000000\n",
       "          2129790  2017-08-31  128867485    0.000000\n",
       "          2129892  2017-08-31  128867486    0.000000\n",
       "          2129994  2017-08-31  128867487    0.000000\n",
       "          2130131  2017-08-31  128867488    0.000000\n",
       "          2130219  2017-08-31  128867489    0.000000\n",
       "          2130265  2017-08-31  128867490    0.000000\n",
       "          2130352  2017-08-31  128867491    0.000000\n",
       "          2130474  2017-08-31  128867492    0.000000\n",
       "          2130521  2017-08-31  128867493    0.000000\n",
       "          2130526  2017-08-31  128867494    0.000000\n",
       "          2130553  2017-08-31  128867495    0.000000\n",
       "          2131010  2017-08-31  128867496    0.000000\n",
       "          2131572  2017-08-31  128867497    0.000000\n",
       "          2131699  2017-08-31  128867498    0.000000\n",
       "          2132163  2017-08-31  128867499    0.000000\n",
       "          2132318  2017-08-31  128867500    0.000000\n",
       "          2132945  2017-08-31  128867501    0.000000\n",
       "          2132957  2017-08-31  128867502    0.000000\n",
       "          2134244  2017-08-31  128867503    0.000000\n",
       "\n",
       "[3370464 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on the work in this file: https://www.kaggle.com/vrtjso/lgbm-one-step-ahead\n",
    "\n",
    "This was apparently in the top 10% at one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Training and predicting models...\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryanfeeney/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.30191\tvalid_1's l2: 0.29409\n",
      "[200]\ttraining's l2: 0.298363\tvalid_1's l2: 0.292741\n",
      "[300]\ttraining's l2: 0.295918\tvalid_1's l2: 0.292337\n",
      "[400]\ttraining's l2: 0.293791\tvalid_1's l2: 0.2921\n",
      "[500]\ttraining's l2: 0.29199\tvalid_1's l2: 0.29195\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.29199\tvalid_1's l2: 0.29195\n",
      "mean_7_2017: 1882639.38\n",
      "mean_14_2017: 1229821.77\n",
      "promo_0: 104143.51\n",
      "day_1_2017: 89857.46\n",
      "mean_20_dow0_2017: 84245.48\n",
      "mean_3_2017: 76646.29\n",
      "mean_30_2017: 76583.57\n",
      "mean_4_dow0_2017: 58919.38\n",
      "mean_60_2017: 33035.18\n",
      "promo_14_2017: 28619.72\n",
      "promo_7: 9432.45\n",
      "mean_4_dow5_2017: 7417.05\n",
      "mean_140_2017: 7406.32\n",
      "promo_60_2017: 6740.72\n",
      "mean_20_dow4_2017: 5611.55\n",
      "promo_140_2017: 5493.72\n",
      "mean_4_dow6_2017: 4633.44\n",
      "mean_4_dow2_2017: 3813.74\n",
      "mean_20_dow2_2017: 3343.78\n",
      "mean_4_dow3_2017: 2824.66\n",
      "promo_9: 2814.25\n",
      "mean_4_dow1_2017: 2707.00\n",
      "mean_20_dow3_2017: 2642.58\n",
      "mean_20_dow1_2017: 2616.99\n",
      "mean_4_dow4_2017: 2601.73\n",
      "promo_14: 2554.27\n",
      "mean_20_dow6_2017: 2328.54\n",
      "mean_20_dow5_2017: 2100.97\n",
      "promo_15: 1496.63\n",
      "promo_1: 1221.01\n",
      "promo_11: 1192.51\n",
      "promo_13: 1006.62\n",
      "promo_2: 935.67\n",
      "promo_3: 893.47\n",
      "promo_4: 889.91\n",
      "promo_10: 383.97\n",
      "promo_6: 322.66\n",
      "promo_12: 298.58\n",
      "promo_5: 285.28\n",
      "promo_8: 141.86\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.326539\tvalid_1's l2: 0.327058\n",
      "[200]\ttraining's l2: 0.322922\tvalid_1's l2: 0.325592\n",
      "[300]\ttraining's l2: 0.320274\tvalid_1's l2: 0.325165\n",
      "[400]\ttraining's l2: 0.318019\tvalid_1's l2: 0.325026\n",
      "[500]\ttraining's l2: 0.316052\tvalid_1's l2: 0.324929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.316052\tvalid_1's l2: 0.324929\n",
      "mean_14_2017: 1448209.85\n",
      "mean_7_2017: 1034578.11\n",
      "mean_30_2017: 246570.90\n",
      "mean_20_dow1_2017: 76170.97\n",
      "mean_60_2017: 75746.98\n",
      "promo_1: 63650.65\n",
      "day_1_2017: 39350.00\n",
      "promo_14_2017: 23420.47\n",
      "mean_3_2017: 21665.46\n",
      "mean_4_dow1_2017: 21049.86\n",
      "mean_20_dow2_2017: 6729.53\n",
      "promo_60_2017: 6611.24\n",
      "mean_20_dow4_2017: 5631.01\n",
      "mean_140_2017: 5613.73\n",
      "mean_4_dow2_2017: 4690.02\n",
      "promo_0: 4369.95\n",
      "promo_140_2017: 4120.99\n",
      "mean_4_dow6_2017: 4081.87\n",
      "mean_4_dow0_2017: 3375.03\n",
      "mean_4_dow4_2017: 3221.22\n",
      "promo_3: 3191.82\n",
      "mean_4_dow5_2017: 2852.68\n",
      "mean_4_dow3_2017: 2762.14\n",
      "mean_20_dow0_2017: 2746.06\n",
      "mean_20_dow5_2017: 2731.84\n",
      "promo_4: 2695.93\n",
      "mean_20_dow6_2017: 2610.67\n",
      "mean_20_dow3_2017: 1957.73\n",
      "promo_2: 1709.55\n",
      "promo_5: 1504.46\n",
      "promo_7: 871.80\n",
      "promo_6: 664.72\n",
      "promo_14: 485.90\n",
      "promo_15: 428.90\n",
      "promo_13: 428.87\n",
      "promo_11: 412.48\n",
      "promo_9: 350.18\n",
      "promo_10: 258.84\n",
      "promo_8: 227.38\n",
      "promo_12: 202.90\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.329214\tvalid_1's l2: 0.341052\n",
      "[200]\ttraining's l2: 0.32491\tvalid_1's l2: 0.339451\n",
      "[300]\ttraining's l2: 0.322012\tvalid_1's l2: 0.33904\n",
      "[400]\ttraining's l2: 0.319586\tvalid_1's l2: 0.338643\n",
      "[500]\ttraining's l2: 0.317454\tvalid_1's l2: 0.338549\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.317454\tvalid_1's l2: 0.338549\n",
      "mean_14_2017: 1844336.16\n",
      "mean_7_2017: 870615.51\n",
      "mean_20_dow2_2017: 250002.09\n",
      "mean_30_2017: 233037.29\n",
      "mean_4_dow2_2017: 193065.36\n",
      "promo_2: 99012.98\n",
      "mean_60_2017: 27003.87\n",
      "promo_14_2017: 24648.98\n",
      "mean_3_2017: 21618.39\n",
      "day_1_2017: 11455.88\n",
      "promo_140_2017: 10046.38\n",
      "promo_60_2017: 9571.91\n",
      "mean_20_dow4_2017: 7756.05\n",
      "promo_9: 6415.80\n",
      "promo_3: 6290.96\n",
      "mean_4_dow0_2017: 5199.39\n",
      "mean_20_dow1_2017: 4937.92\n",
      "mean_4_dow1_2017: 4747.39\n",
      "mean_4_dow3_2017: 4469.99\n",
      "mean_20_dow5_2017: 4268.66\n",
      "promo_0: 4053.77\n",
      "promo_5: 3801.42\n",
      "promo_4: 3494.51\n",
      "promo_7: 3253.06\n",
      "mean_4_dow6_2017: 3084.02\n",
      "mean_4_dow4_2017: 2872.92\n",
      "mean_20_dow0_2017: 2843.14\n",
      "mean_20_dow3_2017: 2753.28\n",
      "mean_4_dow5_2017: 2698.22\n",
      "mean_20_dow6_2017: 2683.80\n",
      "mean_140_2017: 1969.18\n",
      "promo_11: 1916.54\n",
      "promo_1: 1565.68\n",
      "promo_15: 1453.37\n",
      "promo_14: 1262.02\n",
      "promo_10: 1052.03\n",
      "promo_6: 913.07\n",
      "promo_13: 468.25\n",
      "promo_12: 445.72\n",
      "promo_8: 196.02\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.352578\tvalid_1's l2: 0.35456\n",
      "[200]\ttraining's l2: 0.347807\tvalid_1's l2: 0.352866\n",
      "[300]\ttraining's l2: 0.344704\tvalid_1's l2: 0.35252\n",
      "[400]\ttraining's l2: 0.342312\tvalid_1's l2: 0.352494\n",
      "Early stopping, best iteration is:\n",
      "[356]\ttraining's l2: 0.343334\tvalid_1's l2: 0.352445\n",
      "mean_14_2017: 2193691.18\n",
      "mean_7_2017: 618595.48\n",
      "mean_30_2017: 551732.29\n",
      "mean_4_dow3_2017: 297032.53\n",
      "mean_20_dow3_2017: 151857.36\n",
      "mean_60_2017: 143905.27\n",
      "promo_3: 74878.51\n",
      "mean_3_2017: 41209.99\n",
      "mean_4_dow4_2017: 24200.55\n",
      "promo_14_2017: 20086.54\n",
      "day_1_2017: 7849.99\n",
      "promo_60_2017: 7545.86\n",
      "mean_140_2017: 6691.03\n",
      "promo_140_2017: 6578.59\n",
      "promo_5: 5016.34\n",
      "promo_4: 4576.47\n",
      "mean_4_dow2_2017: 4269.24\n",
      "mean_20_dow5_2017: 4133.29\n",
      "mean_20_dow0_2017: 4010.61\n",
      "promo_2: 3671.09\n",
      "promo_7: 3525.20\n",
      "mean_20_dow4_2017: 3435.74\n",
      "mean_20_dow6_2017: 3370.36\n",
      "mean_4_dow0_2017: 3253.79\n",
      "promo_0: 2755.67\n",
      "mean_20_dow2_2017: 2670.18\n",
      "promo_6: 2655.50\n",
      "mean_4_dow6_2017: 2643.84\n",
      "mean_4_dow1_2017: 2137.30\n",
      "promo_1: 1963.74\n",
      "mean_4_dow5_2017: 1929.19\n",
      "mean_20_dow1_2017: 1853.53\n",
      "promo_14: 1328.71\n",
      "promo_9: 1137.47\n",
      "promo_15: 626.27\n",
      "promo_8: 611.44\n",
      "promo_13: 493.24\n",
      "promo_10: 486.88\n",
      "promo_12: 260.55\n",
      "promo_11: 205.27\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.363248\tvalid_1's l2: 0.357485\n",
      "[200]\ttraining's l2: 0.357852\tvalid_1's l2: 0.355829\n",
      "[300]\ttraining's l2: 0.354392\tvalid_1's l2: 0.355065\n",
      "[400]\ttraining's l2: 0.351438\tvalid_1's l2: 0.354843\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's l2: 0.350333\tvalid_1's l2: 0.354789\n",
      "mean_14_2017: 1348136.20\n",
      "mean_4_dow4_2017: 1135127.96\n",
      "mean_7_2017: 628767.41\n",
      "mean_30_2017: 544794.74\n",
      "mean_3_2017: 291791.52\n",
      "mean_20_dow4_2017: 288550.61\n",
      "promo_4: 74505.10\n",
      "mean_60_2017: 44391.35\n",
      "promo_14_2017: 19804.80\n",
      "mean_4_dow3_2017: 18485.98\n",
      "promo_60_2017: 7875.35\n",
      "promo_3: 7643.88\n",
      "promo_5: 7253.32\n",
      "promo_140_2017: 7073.61\n",
      "promo_7: 6861.10\n",
      "day_1_2017: 5987.75\n",
      "mean_20_dow2_2017: 4998.05\n",
      "mean_20_dow1_2017: 4892.12\n",
      "mean_20_dow0_2017: 4735.39\n",
      "promo_6: 4409.29\n",
      "mean_140_2017: 4018.54\n",
      "promo_0: 3825.66\n",
      "promo_2: 3517.27\n",
      "mean_20_dow3_2017: 3413.62\n",
      "mean_4_dow0_2017: 3339.72\n",
      "mean_4_dow5_2017: 2941.74\n",
      "mean_20_dow6_2017: 2861.50\n",
      "mean_4_dow6_2017: 2847.72\n",
      "mean_4_dow2_2017: 2616.75\n",
      "promo_1: 2437.49\n",
      "mean_20_dow5_2017: 2370.19\n",
      "mean_4_dow1_2017: 2346.16\n",
      "promo_11: 2072.60\n",
      "promo_14: 1764.28\n",
      "promo_9: 1456.78\n",
      "promo_15: 918.80\n",
      "promo_10: 786.73\n",
      "promo_13: 699.22\n",
      "promo_8: 599.66\n",
      "promo_12: 548.07\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.356167\tvalid_1's l2: 0.361072\n",
      "[200]\ttraining's l2: 0.35175\tvalid_1's l2: 0.359722\n",
      "[300]\ttraining's l2: 0.348717\tvalid_1's l2: 0.35919\n",
      "[400]\ttraining's l2: 0.346237\tvalid_1's l2: 0.359004\n",
      "[500]\ttraining's l2: 0.343935\tvalid_1's l2: 0.358917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 0.343935\tvalid_1's l2: 0.358917\n",
      "mean_14_2017: 1303577.54\n",
      "mean_30_2017: 1131578.58\n",
      "mean_7_2017: 302367.52\n",
      "mean_3_2017: 250064.05\n",
      "mean_60_2017: 199236.34\n",
      "mean_20_dow5_2017: 83861.17\n",
      "promo_5: 80457.60\n",
      "mean_4_dow5_2017: 61891.13\n",
      "promo_14_2017: 19933.21\n",
      "promo_3: 11460.40\n",
      "mean_4_dow6_2017: 9766.39\n",
      "day_1_2017: 8574.87\n",
      "promo_60_2017: 8078.56\n",
      "promo_7: 7718.19\n",
      "mean_140_2017: 6770.88\n",
      "mean_20_dow6_2017: 6236.08\n",
      "promo_6: 5804.02\n",
      "promo_140_2017: 4630.49\n",
      "mean_4_dow0_2017: 4040.13\n",
      "mean_20_dow0_2017: 4017.73\n",
      "mean_20_dow3_2017: 3928.91\n",
      "mean_20_dow2_2017: 3831.69\n",
      "mean_4_dow2_2017: 3615.73\n",
      "mean_4_dow1_2017: 3322.85\n",
      "mean_4_dow4_2017: 3293.49\n",
      "mean_4_dow3_2017: 3278.24\n",
      "mean_20_dow4_2017: 3100.54\n",
      "mean_20_dow1_2017: 2860.49\n",
      "promo_0: 2825.76\n",
      "promo_4: 2754.35\n",
      "promo_2: 2413.23\n",
      "promo_9: 1986.25\n",
      "promo_14: 1224.92\n",
      "promo_1: 1187.60\n",
      "promo_13: 1029.54\n",
      "promo_12: 1027.71\n",
      "promo_8: 903.58\n",
      "promo_11: 683.05\n",
      "promo_10: 585.70\n",
      "promo_15: 583.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346219\tvalid_1's l2: 0.421254\n",
      "[200]\ttraining's l2: 0.341874\tvalid_1's l2: 0.420923\n",
      "[300]\ttraining's l2: 0.339035\tvalid_1's l2: 0.420617\n",
      "[400]\ttraining's l2: 0.336652\tvalid_1's l2: 0.420437\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's l2: 0.336799\tvalid_1's l2: 0.420378\n",
      "mean_14_2017: 1274004.42\n",
      "mean_30_2017: 842088.63\n",
      "mean_7_2017: 445757.89\n",
      "mean_20_dow6_2017: 152802.16\n",
      "mean_3_2017: 145241.24\n",
      "promo_6: 128192.88\n",
      "mean_4_dow6_2017: 127503.94\n",
      "mean_60_2017: 123326.90\n",
      "promo_14_2017: 21944.55\n",
      "day_1_2017: 13872.06\n",
      "promo_3: 11205.46\n",
      "promo_7: 9013.03\n",
      "mean_4_dow5_2017: 8533.91\n",
      "mean_20_dow5_2017: 8280.78\n",
      "promo_60_2017: 8112.57\n",
      "promo_140_2017: 6018.04\n",
      "mean_20_dow1_2017: 4884.13\n",
      "promo_5: 4487.41\n",
      "mean_140_2017: 4382.31\n",
      "promo_13: 3877.01\n",
      "mean_4_dow0_2017: 3650.61\n",
      "mean_20_dow0_2017: 3639.82\n",
      "mean_20_dow3_2017: 3507.37\n",
      "mean_4_dow1_2017: 3355.21\n",
      "mean_20_dow4_2017: 2943.12\n",
      "promo_4: 2784.87\n",
      "promo_0: 2663.62\n",
      "mean_20_dow2_2017: 2644.47\n",
      "mean_4_dow2_2017: 2643.06\n",
      "mean_4_dow3_2017: 2399.89\n",
      "promo_9: 2205.45\n",
      "promo_14: 1995.35\n",
      "mean_4_dow4_2017: 1944.32\n",
      "promo_2: 1500.32\n",
      "promo_1: 1481.22\n",
      "promo_15: 1358.07\n",
      "promo_11: 887.39\n",
      "promo_12: 561.75\n",
      "promo_8: 539.82\n",
      "promo_10: 490.10\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.332499\tvalid_1's l2: 0.3901\n",
      "[200]\ttraining's l2: 0.328261\tvalid_1's l2: 0.388965\n",
      "[300]\ttraining's l2: 0.325429\tvalid_1's l2: 0.388761\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttraining's l2: 0.326174\tvalid_1's l2: 0.388646\n",
      "mean_14_2017: 1106650.36\n",
      "mean_30_2017: 1087192.69\n",
      "mean_7_2017: 596975.54\n",
      "mean_20_dow0_2017: 196265.21\n",
      "promo_7: 180889.57\n",
      "mean_60_2017: 149108.93\n",
      "mean_4_dow0_2017: 59661.14\n",
      "promo_0: 24773.90\n",
      "mean_3_2017: 19984.01\n",
      "day_1_2017: 19142.77\n",
      "promo_60_2017: 12051.84\n",
      "promo_14_2017: 11689.01\n",
      "promo_14: 10283.65\n",
      "promo_140_2017: 8424.10\n",
      "mean_140_2017: 6395.53\n",
      "mean_20_dow2_2017: 5494.71\n",
      "promo_3: 5488.24\n",
      "mean_20_dow4_2017: 5169.59\n",
      "promo_5: 3575.89\n",
      "promo_6: 3298.34\n",
      "promo_9: 2789.02\n",
      "mean_20_dow1_2017: 2684.71\n",
      "mean_4_dow6_2017: 2653.59\n",
      "mean_4_dow5_2017: 2642.93\n",
      "mean_20_dow3_2017: 2642.15\n",
      "mean_4_dow2_2017: 2252.18\n",
      "promo_15: 2080.63\n",
      "mean_20_dow6_2017: 2018.39\n",
      "mean_4_dow1_2017: 1985.10\n",
      "mean_20_dow5_2017: 1841.53\n",
      "promo_4: 1812.55\n",
      "mean_4_dow3_2017: 1717.08\n",
      "mean_4_dow4_2017: 1650.89\n",
      "promo_2: 1599.33\n",
      "promo_10: 1283.18\n",
      "promo_13: 1050.84\n",
      "promo_8: 818.48\n",
      "promo_11: 786.91\n",
      "promo_1: 669.08\n",
      "promo_12: 425.68\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.342053\tvalid_1's l2: 0.380461\n",
      "[200]\ttraining's l2: 0.337877\tvalid_1's l2: 0.379403\n",
      "[300]\ttraining's l2: 0.335103\tvalid_1's l2: 0.379123\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's l2: 0.336014\tvalid_1's l2: 0.379038\n",
      "mean_30_2017: 1092411.90\n",
      "mean_14_2017: 753255.06\n",
      "mean_7_2017: 476090.43\n",
      "mean_60_2017: 246076.66\n",
      "mean_20_dow1_2017: 107659.48\n",
      "promo_8: 103259.44\n",
      "mean_4_dow1_2017: 19937.01\n",
      "promo_10: 18003.13\n",
      "promo_14_2017: 16924.71\n",
      "day_1_2017: 16452.21\n",
      "promo_60_2017: 11142.17\n",
      "mean_3_2017: 10494.91\n",
      "mean_20_dow2_2017: 8645.64\n",
      "promo_7: 8064.94\n",
      "mean_20_dow4_2017: 5020.41\n",
      "promo_140_2017: 4773.47\n",
      "promo_11: 4275.66\n",
      "promo_12: 3589.55\n",
      "mean_20_dow0_2017: 3160.99\n",
      "promo_13: 2958.70\n",
      "mean_140_2017: 2897.43\n",
      "mean_4_dow0_2017: 2787.90\n",
      "promo_9: 2689.16\n",
      "mean_4_dow2_2017: 2528.49\n",
      "mean_4_dow6_2017: 2503.01\n",
      "promo_0: 2205.36\n",
      "mean_20_dow6_2017: 2051.10\n",
      "mean_4_dow4_2017: 1838.41\n",
      "mean_4_dow5_2017: 1770.93\n",
      "mean_20_dow5_2017: 1756.49\n",
      "promo_3: 1621.72\n",
      "mean_4_dow3_2017: 1592.52\n",
      "promo_14: 1571.90\n",
      "mean_20_dow3_2017: 1467.83\n",
      "promo_6: 1083.55\n",
      "promo_4: 1073.11\n",
      "promo_2: 681.96\n",
      "promo_5: 494.89\n",
      "promo_15: 463.49\n",
      "promo_1: 419.76\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346249\tvalid_1's l2: 0.369277\n",
      "[200]\ttraining's l2: 0.341552\tvalid_1's l2: 0.368489\n",
      "[300]\ttraining's l2: 0.338254\tvalid_1's l2: 0.367977\n",
      "[400]\ttraining's l2: 0.335535\tvalid_1's l2: 0.367602\n",
      "Early stopping, best iteration is:\n",
      "[426]\ttraining's l2: 0.334919\tvalid_1's l2: 0.367499\n",
      "mean_30_2017: 1109135.07\n",
      "mean_14_2017: 898740.33\n",
      "mean_7_2017: 455556.40\n",
      "mean_20_dow2_2017: 370696.90\n",
      "mean_4_dow2_2017: 305486.76\n",
      "promo_9: 126542.69\n",
      "mean_60_2017: 69547.55\n",
      "promo_14_2017: 22015.36\n",
      "promo_10: 14619.81\n",
      "promo_140_2017: 12875.57\n",
      "promo_2: 11529.68\n",
      "promo_60_2017: 10979.04\n",
      "mean_3_2017: 10953.05\n",
      "promo_7: 9486.41\n",
      "day_1_2017: 7823.74\n",
      "mean_20_dow4_2017: 7736.48\n",
      "promo_8: 6789.34\n",
      "mean_20_dow1_2017: 6282.70\n",
      "mean_4_dow1_2017: 5402.74\n",
      "promo_14: 5226.53\n",
      "mean_20_dow5_2017: 4596.57\n",
      "mean_4_dow0_2017: 4021.87\n",
      "mean_4_dow3_2017: 3921.97\n",
      "promo_12: 3788.84\n",
      "mean_20_dow0_2017: 3780.37\n",
      "promo_11: 3143.47\n",
      "mean_20_dow3_2017: 3112.16\n",
      "mean_4_dow6_2017: 3027.64\n",
      "mean_140_2017: 3010.47\n",
      "mean_4_dow4_2017: 2729.70\n",
      "promo_13: 2729.64\n",
      "mean_20_dow6_2017: 2720.09\n",
      "mean_4_dow5_2017: 2430.24\n",
      "promo_6: 1390.16\n",
      "promo_4: 1204.69\n",
      "promo_0: 1123.38\n",
      "promo_1: 934.92\n",
      "promo_15: 901.80\n",
      "promo_3: 468.56\n",
      "promo_5: 299.24\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.374554\tvalid_1's l2: 0.37475\n",
      "[200]\ttraining's l2: 0.369094\tvalid_1's l2: 0.373093\n",
      "[300]\ttraining's l2: 0.3657\tvalid_1's l2: 0.372889\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's l2: 0.367225\tvalid_1's l2: 0.372871\n",
      "mean_30_2017: 1557331.99\n",
      "mean_14_2017: 731428.08\n",
      "mean_7_2017: 608635.02\n",
      "mean_60_2017: 369698.24\n",
      "mean_4_dow3_2017: 278647.67\n",
      "mean_20_dow3_2017: 194588.29\n",
      "promo_10: 106197.71\n",
      "mean_3_2017: 16427.10\n",
      "promo_14_2017: 15868.17\n",
      "mean_4_dow4_2017: 14618.03\n",
      "mean_4_dow2_2017: 10881.47\n",
      "promo_60_2017: 10271.67\n",
      "mean_140_2017: 7499.64\n",
      "promo_140_2017: 7024.09\n",
      "promo_14: 6975.73\n",
      "promo_9: 5837.04\n",
      "promo_7: 5810.41\n",
      "day_1_2017: 5059.51\n",
      "promo_12: 4976.80\n",
      "promo_11: 4931.67\n",
      "mean_20_dow0_2017: 4411.60\n",
      "mean_20_dow5_2017: 4364.08\n",
      "promo_13: 3983.01\n",
      "mean_20_dow2_2017: 3850.59\n",
      "mean_20_dow4_2017: 3281.31\n",
      "mean_4_dow0_2017: 3146.40\n",
      "mean_20_dow6_2017: 3026.25\n",
      "promo_8: 3004.82\n",
      "mean_20_dow1_2017: 2430.94\n",
      "mean_4_dow1_2017: 2023.36\n",
      "promo_3: 2009.26\n",
      "mean_4_dow6_2017: 1653.60\n",
      "mean_4_dow5_2017: 1564.46\n",
      "promo_6: 1205.97\n",
      "promo_0: 1141.93\n",
      "promo_15: 998.07\n",
      "promo_4: 774.89\n",
      "promo_2: 521.36\n",
      "promo_5: 477.40\n",
      "promo_1: 279.25\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.384726\tvalid_1's l2: 0.386245\n",
      "[200]\ttraining's l2: 0.379048\tvalid_1's l2: 0.384677\n",
      "[300]\ttraining's l2: 0.375455\tvalid_1's l2: 0.384401\n",
      "[400]\ttraining's l2: 0.372435\tvalid_1's l2: 0.384356\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's l2: 0.372056\tvalid_1's l2: 0.384323\n",
      "mean_4_dow4_2017: 1370672.62\n",
      "mean_30_2017: 1347811.60\n",
      "mean_14_2017: 519317.28\n",
      "mean_20_dow4_2017: 286536.47\n",
      "mean_60_2017: 203990.63\n",
      "mean_7_2017: 183990.03\n",
      "mean_3_2017: 105880.57\n",
      "promo_11: 94981.40\n",
      "mean_4_dow3_2017: 17981.50\n",
      "promo_14_2017: 15931.04\n",
      "promo_12: 13676.55\n",
      "promo_14: 11691.97\n",
      "promo_10: 9251.36\n",
      "promo_60_2017: 9175.17\n",
      "promo_140_2017: 8938.17\n",
      "mean_140_2017: 7198.99\n",
      "promo_13: 6796.57\n",
      "promo_9: 6049.79\n",
      "promo_4: 5491.69\n",
      "mean_20_dow0_2017: 5409.09\n",
      "day_1_2017: 4989.87\n",
      "promo_7: 4847.85\n",
      "mean_20_dow3_2017: 4446.33\n",
      "mean_20_dow1_2017: 4233.39\n",
      "mean_20_dow2_2017: 4034.11\n",
      "mean_20_dow6_2017: 3841.08\n",
      "mean_4_dow0_2017: 3452.07\n",
      "promo_8: 3367.92\n",
      "mean_20_dow5_2017: 3116.02\n",
      "mean_4_dow5_2017: 2736.23\n",
      "mean_4_dow6_2017: 2651.79\n",
      "mean_4_dow1_2017: 2500.66\n",
      "mean_4_dow2_2017: 2434.76\n",
      "promo_0: 1786.93\n",
      "promo_15: 1146.94\n",
      "promo_6: 1010.45\n",
      "promo_2: 829.46\n",
      "promo_3: 708.15\n",
      "promo_1: 546.59\n",
      "promo_5: 373.83\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.370343\tvalid_1's l2: 0.377148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's l2: 0.365615\tvalid_1's l2: 0.376333\n",
      "[300]\ttraining's l2: 0.362327\tvalid_1's l2: 0.376258\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's l2: 0.361236\tvalid_1's l2: 0.37609\n",
      "mean_30_2017: 1601076.04\n",
      "mean_14_2017: 588977.50\n",
      "mean_60_2017: 374936.35\n",
      "mean_7_2017: 305452.67\n",
      "mean_3_2017: 148957.18\n",
      "promo_12: 93518.03\n",
      "mean_20_dow5_2017: 85159.77\n",
      "mean_4_dow5_2017: 71638.34\n",
      "promo_13: 19595.91\n",
      "promo_14_2017: 16011.22\n",
      "promo_14: 13355.62\n",
      "promo_10: 11265.36\n",
      "mean_140_2017: 9927.43\n",
      "promo_60_2017: 8798.33\n",
      "day_1_2017: 7950.62\n",
      "mean_20_dow0_2017: 7544.02\n",
      "promo_140_2017: 6088.78\n",
      "mean_20_dow6_2017: 5888.75\n",
      "mean_4_dow6_2017: 4725.31\n",
      "promo_11: 4479.14\n",
      "mean_4_dow0_2017: 3756.38\n",
      "mean_20_dow3_2017: 3664.43\n",
      "promo_9: 3613.91\n",
      "mean_20_dow2_2017: 3341.99\n",
      "mean_4_dow2_2017: 2714.48\n",
      "mean_20_dow1_2017: 2701.22\n",
      "mean_4_dow3_2017: 2566.89\n",
      "mean_20_dow4_2017: 2531.39\n",
      "promo_15: 2495.30\n",
      "mean_4_dow1_2017: 2301.79\n",
      "mean_4_dow4_2017: 2274.90\n",
      "promo_7: 2189.77\n",
      "promo_0: 1734.63\n",
      "promo_8: 1699.81\n",
      "promo_5: 1614.77\n",
      "promo_6: 1073.19\n",
      "promo_3: 698.78\n",
      "promo_2: 632.31\n",
      "promo_4: 552.65\n",
      "promo_1: 360.10\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.359483\tvalid_1's l2: 0.362315\n",
      "[200]\ttraining's l2: 0.355317\tvalid_1's l2: 0.361333\n",
      "[300]\ttraining's l2: 0.352142\tvalid_1's l2: 0.36116\n",
      "Early stopping, best iteration is:\n",
      "[341]\ttraining's l2: 0.351057\tvalid_1's l2: 0.361093\n",
      "mean_30_2017: 1503900.26\n",
      "mean_14_2017: 474406.75\n",
      "mean_60_2017: 314928.82\n",
      "mean_7_2017: 302522.14\n",
      "mean_20_dow6_2017: 195214.67\n",
      "promo_13: 161942.26\n",
      "mean_3_2017: 85260.13\n",
      "mean_4_dow6_2017: 72570.04\n",
      "day_1_2017: 20138.75\n",
      "promo_14_2017: 16401.63\n",
      "mean_4_dow5_2017: 12323.03\n",
      "mean_140_2017: 10016.33\n",
      "promo_60_2017: 9711.48\n",
      "promo_14: 9682.72\n",
      "mean_20_dow5_2017: 9004.62\n",
      "promo_10: 8366.20\n",
      "mean_20_dow1_2017: 8346.93\n",
      "promo_140_2017: 6622.02\n",
      "mean_20_dow0_2017: 6016.06\n",
      "promo_12: 5934.91\n",
      "promo_6: 5761.74\n",
      "mean_4_dow0_2017: 3712.35\n",
      "promo_0: 3489.70\n",
      "mean_20_dow3_2017: 3159.65\n",
      "promo_9: 3117.09\n",
      "mean_4_dow1_2017: 3018.32\n",
      "mean_20_dow4_2017: 3011.37\n",
      "promo_11: 2944.78\n",
      "mean_4_dow3_2017: 2494.32\n",
      "mean_20_dow2_2017: 2399.85\n",
      "promo_15: 2280.65\n",
      "mean_4_dow4_2017: 2222.69\n",
      "mean_4_dow2_2017: 2216.53\n",
      "promo_7: 1696.63\n",
      "promo_8: 1501.73\n",
      "promo_2: 999.87\n",
      "promo_4: 820.73\n",
      "promo_1: 501.61\n",
      "promo_3: 407.76\n",
      "promo_5: 358.07\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.346946\tvalid_1's l2: 0.349058\n",
      "[200]\ttraining's l2: 0.342413\tvalid_1's l2: 0.348041\n",
      "[300]\ttraining's l2: 0.339349\tvalid_1's l2: 0.347827\n",
      "[400]\ttraining's l2: 0.336694\tvalid_1's l2: 0.347475\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's l2: 0.33672\tvalid_1's l2: 0.34747\n",
      "mean_30_2017: 1510783.19\n",
      "mean_14_2017: 661347.37\n",
      "mean_7_2017: 392564.07\n",
      "mean_20_dow0_2017: 270349.76\n",
      "promo_14: 195765.80\n",
      "mean_60_2017: 174312.36\n",
      "mean_4_dow0_2017: 66182.47\n",
      "day_1_2017: 16736.14\n",
      "promo_7: 16376.36\n",
      "promo_14_2017: 15451.42\n",
      "promo_0: 13747.98\n",
      "mean_3_2017: 13730.83\n",
      "promo_60_2017: 13529.07\n",
      "promo_140_2017: 11707.14\n",
      "promo_13: 9827.58\n",
      "mean_20_dow2_2017: 9398.45\n",
      "mean_140_2017: 8178.01\n",
      "mean_20_dow4_2017: 6067.88\n",
      "promo_12: 6001.85\n",
      "promo_10: 5328.53\n",
      "mean_4_dow2_2017: 4731.33\n",
      "mean_20_dow1_2017: 3872.20\n",
      "promo_15: 3755.41\n",
      "promo_9: 3747.19\n",
      "mean_4_dow6_2017: 3585.10\n",
      "mean_20_dow6_2017: 3221.57\n",
      "mean_4_dow5_2017: 3192.25\n",
      "mean_4_dow1_2017: 3056.25\n",
      "mean_20_dow3_2017: 2992.33\n",
      "mean_4_dow4_2017: 2629.42\n",
      "promo_2: 2543.41\n",
      "mean_20_dow5_2017: 2500.39\n",
      "mean_4_dow3_2017: 2457.65\n",
      "promo_11: 2145.44\n",
      "promo_6: 1194.59\n",
      "promo_8: 1055.05\n",
      "promo_4: 1027.53\n",
      "promo_3: 616.03\n",
      "promo_1: 480.42\n",
      "promo_5: 274.91\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's l2: 0.357487\tvalid_1's l2: 0.372593\n",
      "[200]\ttraining's l2: 0.353175\tvalid_1's l2: 0.371423\n",
      "[300]\ttraining's l2: 0.350209\tvalid_1's l2: 0.370966\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's l2: 0.349009\tvalid_1's l2: 0.370807\n",
      "mean_30_2017: 1454305.00\n",
      "mean_14_2017: 454926.74\n",
      "mean_60_2017: 383159.89\n",
      "mean_7_2017: 217745.33\n",
      "promo_15: 134065.70\n",
      "mean_20_dow1_2017: 109875.66\n",
      "mean_4_dow1_2017: 17102.93\n",
      "day_1_2017: 15830.99\n",
      "mean_20_dow2_2017: 15117.27\n",
      "promo_14_2017: 12513.41\n",
      "promo_60_2017: 11584.19\n",
      "mean_3_2017: 9211.26\n",
      "promo_14: 7912.86\n",
      "promo_140_2017: 7691.20\n",
      "mean_140_2017: 6309.34\n",
      "mean_20_dow4_2017: 5575.79\n",
      "mean_20_dow0_2017: 5231.27\n",
      "mean_4_dow0_2017: 3421.06\n",
      "promo_10: 3212.28\n",
      "mean_4_dow6_2017: 2855.52\n",
      "mean_4_dow2_2017: 2697.58\n",
      "mean_20_dow6_2017: 2494.24\n",
      "promo_13: 2474.50\n",
      "mean_4_dow3_2017: 2419.15\n",
      "mean_4_dow4_2017: 2402.11\n",
      "mean_20_dow5_2017: 2367.49\n",
      "mean_4_dow5_2017: 2280.71\n",
      "promo_12: 2128.19\n",
      "mean_20_dow3_2017: 2065.58\n",
      "promo_7: 1789.05\n",
      "promo_0: 1498.76\n",
      "promo_11: 1486.70\n",
      "promo_9: 1379.17\n",
      "promo_8: 992.07\n",
      "promo_6: 831.67\n",
      "promo_1: 700.04\n",
      "promo_2: 687.44\n",
      "promo_4: 642.91\n",
      "promo_3: 451.08\n",
      "promo_5: 326.33\n",
      "Validation mse: 0.3623709264044814\n",
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    TrainData, usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    TestData, usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    ItemsPath,\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "\n",
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        \"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        \"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 31)\n",
    "X_l, y_l = [], []\n",
    "for i in range(6):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n",
    "\n",
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 300,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 500\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=100\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n",
    "\n",
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 275.7862813287468\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    np.expm1(y_validate), np.expm1(np.array(validate_pred)).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.583123951777, 15.716233645501712)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(275), np.sqrt(247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
